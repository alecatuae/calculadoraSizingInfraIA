# CASOS DE USO DETALHADOS
# Sistema de Dimensionamento de InferÃªncia LLM

Este documento apresenta casos de uso reais e detalhados do sistema de dimensionamento.

---

## ğŸ“Œ CASO 1: Startup SaaS - Assistente IA Conversacional

### Contexto
- AplicaÃ§Ã£o SaaS B2B de assistente IA
- PrevisÃ£o: 10k usuÃ¡rios ativos simultÃ¢neos no pico
- Budget inicial limitado
- Precisa escalar com demanda

### Requisitos NFR
- ConcorrÃªncia: 1.000 sessÃµes simultÃ¢neas (fase 1)
- Contexto: 32k tokens (conversas de mÃ©dia duraÃ§Ã£o)
- SLA: 99.9% (sem N+1 na fase inicial)
- Custo: Otimizar TCO

### Comando
```bash
python3 sizing.py \
  --model opt-oss-20b \
  --server dgx200 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 32768 \
  --kv-precision fp8 \
  --kv-budget-ratio 0.70 \
  --runtime-overhead-gib 80 \
  --peak-headroom-ratio 0.20 \
  --ha none
```

### Resultado
- **KV por sessÃ£o:** 0.38 GiB
- **SessÃµes por nÃ³:** 1.740
- **NÃ³s necessÃ¡rios:** 1 nÃ³ DGX H200
- **Capacidade ociosa:** ~740 sessÃµes (42% headroom)

### RecomendaÃ§Ãµes
1. âœ… 1 nÃ³ DGX H200 suficiente para fase 1
2. âœ… FP8 ideal para custo-benefÃ­cio
3. âœ… Storage NVMe local para cold-start rÃ¡pido
4. âš ï¸ Planejar N+1 quando atingir 1.200+ sessÃµes
5. ğŸ“ˆ Escalar para 2 nÃ³s quando atingir 1.500+ sessÃµes

### Custo Estimado (ReferÃªncia)
- 1x DGX H200: ~$300k - $400k (CapEx)
- Sem N+1: Economia de $300k na fase inicial

---

## ğŸ“Œ CASO 2: Empresa Enterprise - AnÃ¡lise de Documentos

### Contexto
- Sistema de anÃ¡lise de contratos e documentos legais
- Documentos longos (50-100 pÃ¡ginas)
- Processamento batch + consultas ad-hoc
- Criticidade alta (dados sensÃ­veis)

### Requisitos NFR
- ConcorrÃªncia: 500 anÃ¡lises simultÃ¢neas
- Contexto: 131k tokens (documentos longos)
- SLA: 99.99% com N+1
- PrecisÃ£o: FP16 para anÃ¡lise precisa
- Storage: On-prem de alta performance

### Comando
```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 500 \
  --effective-context 131072 \
  --kv-precision fp16 \
  --kv-budget-ratio 0.65 \
  --runtime-overhead-gib 150 \
  --peak-headroom-ratio 0.30 \
  --ha n+1
```

### Resultado
- **KV por sessÃ£o:** 4.50 GiB (fp16 = 2x fp8)
- **SessÃµes por nÃ³:** 228
- **NÃ³s necessÃ¡rios:** 3 + 1 (N+1) = **4 nÃ³s DGX B300**

### RecomendaÃ§Ãµes
1. âœ… 4 nÃ³s DGX B300 com N+1 para HA
2. âš ï¸ FP16 dobra memÃ³ria - considerar validar se fp8 atende precisÃ£o
3. âœ… Storage NVMe local essencial para 131k tokens
4. ğŸ“Š Monitorar latÃªncia de prefill (131k = alto custo)
5. ğŸ’¡ Considerar chunking de documentos > 100 pÃ¡ginas

### AnÃ¡lise TCO
- **Com FP8:** 2 nÃ³s + N+1 = 3 nÃ³s (~$900k)
- **Com FP16:** 3 nÃ³s + N+1 = 4 nÃ³s (~$1.2M)
- **Economia potencial com FP8:** ~$300k (25%)

---

## ğŸ“Œ CASO 3: Provedor de API - ServiÃ§o Multi-Tenant

### Contexto
- API pÃºblica de inferÃªncia LLM (OpenAI-like)
- MÃºltiplos tenants com SLA diferenciados
- TrÃ¡fego variÃ¡vel (picos 2-3x normal)
- Precisa de elasticidade

### Requisitos NFR
- ConcorrÃªncia: 5.000 sessÃµes (carga normal)
- Contexto: 128k tokens
- SLA: 99.95% com N+1
- Headroom: 30% para picos de trÃ¡fego
- Storage: HÃ­brido (local + rede para checkpoints)

### Comando
```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 5000 \
  --effective-context 131072 \
  --kv-precision fp8 \
  --kv-budget-ratio 0.70 \
  --runtime-overhead-gib 120 \
  --peak-headroom-ratio 0.30 \
  --ha n+1
```

### Resultado
- **KV por sessÃ£o:** 2.25 GiB
- **SessÃµes por nÃ³:** 613
- **NÃ³s mÃ­nimos:** 9 (capacidade pura)
- **Com headroom (30%):** 11 nÃ³s
- **Com N+1:** **12 nÃ³s DGX B300**

### RecomendaÃ§Ãµes
1. âœ… 12 nÃ³s DGX B300 para 5k concurrent + picos + N+1
2. ğŸ“ˆ Implementar auto-scaling (adicionar nÃ³s sob demanda)
3. ğŸ’¾ Storage hÃ­brido:
   - NVMe local para KV cache e modelo ativo
   - Network SSD para checkpoints e modelo backups
4. ğŸ”„ Load balancing entre nÃ³s com awareness de capacidade
5. ğŸ“Š Monitorar:
   - UtilizaÃ§Ã£o HBM por nÃ³ (alertar se > 85%)
   - LatÃªncia P99 (< 500ms ideal)
   - Taxa de throttling

### Arquitetura
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Load Balancer  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”           â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
    â”‚ Pod 1 â”‚           â”‚ Pod 2 â”‚    ...    â”‚ Pod 4 â”‚
    â”‚ 3 nÃ³s â”‚           â”‚ 3 nÃ³s â”‚           â”‚ 3 nÃ³s â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Storage Pool   â”‚
                    â”‚  (NVMe + SSD)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Œ CASO 4: Pesquisa AcadÃªmica - Fine-Tuning e AvaliaÃ§Ã£o

### Contexto
- Lab de pesquisa em NLP
- Experimentos com diferentes configuraÃ§Ãµes
- Budget limitado (uso compartilhado)
- Foco em qualidade, nÃ£o em throughput

### Requisitos NFR
- ConcorrÃªncia: 50 sessÃµes simultÃ¢neas (pesquisadores)
- Contexto: 128k tokens (artigos cientÃ­ficos)
- PrecisÃ£o: FP16 para experimentos
- Sem requisito de HA

### Comando
```bash
python3 sizing.py \
  --model opt-oss-20b \
  --server dgx200 \
  --storage profile_network_ssd \
  --concurrency 50 \
  --effective-context 131072 \
  --kv-precision fp16 \
  --kv-budget-ratio 0.75 \
  --runtime-overhead-gib 60 \
  --peak-headroom-ratio 0.10 \
  --ha none
```

### Resultado
- **KV por sessÃ£o:** 2.82 GiB (fp16 + full attention em metade das camadas)
- **SessÃµes por nÃ³:** 227
- **NÃ³s necessÃ¡rios:** **1 nÃ³ DGX H200**

### RecomendaÃ§Ãµes
1. âœ… 1 nÃ³ DGX H200 suficiente (227 >> 50 sessÃµes)
2. âœ… FP16 adequado para pesquisa
3. âœ… Storage de rede OK (nÃ£o Ã© crÃ­tico para pesquisa)
4. ğŸ’¡ Shared allocation: tempo de GPU por pesquisador
5. ğŸ“Š Quotas recomendadas: 5 sessÃµes/pesquisador

---

## ğŸ“Œ CASO 5: Cloud Provider - ServiÃ§o Serverless

### Contexto
- Provider oferece "LLM as a Service" serverless
- Cold start crÃ­tico (< 5s)
- Auto-scaling agressivo
- MÃºltiplas regiÃµes

### Requisitos NFR
- ConcorrÃªncia: 2.000 sessÃµes/regiÃ£o
- Contexto: Mix (4k-128k, mÃ©dia 32k)
- SLA: 99.9% por regiÃ£o
- Cold start: < 5s
- Storage: Ultra-rÃ¡pido para loading

### Comando (dimensionamento por regiÃ£o)
```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 2000 \
  --effective-context 32768 \
  --kv-precision fp8 \
  --kv-budget-ratio 0.70 \
  --runtime-overhead-gib 100 \
  --peak-headroom-ratio 0.40 \
  --ha n+1
```

### Resultado
- **KV por sessÃ£o:** 0.56 GiB (contexto mÃ©dio menor)
- **SessÃµes por nÃ³:** 2.399
- **NÃ³s com headroom (40%):** 2
- **Com N+1:** **3 nÃ³s/regiÃ£o**

### RecomendaÃ§Ãµes
1. âœ… 3 nÃ³s DGX B300 por regiÃ£o
2. ğŸŒ Multi-regiÃ£o:
   - US-East: 3 nÃ³s
   - US-West: 3 nÃ³s
   - EU: 3 nÃ³s
   - Total: 9 nÃ³s
3. ğŸ’¾ Storage:
   - NVMe local obrigatÃ³rio (cold start < 5s)
   - Cache de modelo em RAM (2TB system memory)
4. ğŸ”„ Auto-scaling:
   - Scale-up: add nÃ³ quando utilizaÃ§Ã£o > 70%
   - Scale-down: remove nÃ³ quando < 30% por 10min
5. ğŸ“Š MÃ©tricas crÃ­ticas:
   - Cold start latency (P99 < 5s)
   - UtilizaÃ§Ã£o HBM por nÃ³
   - Taxa de scale events

---

## ğŸ“Š ComparaÃ§Ã£o de Casos

| Caso | Modelo | NÃ³s | Custo Aprox | Contexto | HA | Uso |
|------|--------|-----|-------------|----------|----|----|
| Startup SaaS | 20B | 1 | $300k | 32k | NÃ£o | Dev/Prod inicial |
| Enterprise | 120B | 4 | $1.2M | 131k | N+1 | Docs longos crÃ­ticos |
| API Provider | 120B | 12 | $3.6M | 131k | N+1 | Alta escala |
| Pesquisa | 20B | 1 | $300k | 131k | NÃ£o | Experimentos |
| Cloud Serverless | 120B | 9 | $2.7M | 32k | N+1 | Multi-regiÃ£o |

---

## ğŸ¯ LiÃ§Ãµes Aprendidas

### 1. PrecisÃ£o KV
- **FP8 vs FP16:** DiferenÃ§a de 2x em memÃ³ria
- **RecomendaÃ§Ã£o:** Sempre comeÃ§ar com FP8, validar qualidade
- **Quando usar FP16:** Apenas se FP8 nÃ£o atender requisitos de qualidade

### 2. Contexto
- **4k-32k:** Sweet spot para maioria dos casos
- **128k-131k:** Requer cuidado com memÃ³ria e I/O
- **Prefill:** Contextos > 100k pressionam I/O no cold start

### 3. HA (N+1)
- **Quando usar:** ProduÃ§Ã£o crÃ­tica, SLA > 99.9%
- **Custo:** +1 nÃ³ (pode ser 10-50% de overhead)
- **Trade-off:** Custo vs disponibilidade

### 4. Storage
- **NVMe local:** Sempre que possÃ­vel (cold start)
- **Network SSD:** OK para cargas nÃ£o crÃ­ticas
- **Cloud storage:** Evitar para inferÃªncia de produÃ§Ã£o

### 5. Headroom
- **10-20%:** Crescimento orgÃ¢nico
- **30-40%:** TrÃ¡fego sazonal/variÃ¡vel
- **> 50%:** Over-provisioning (desperdÃ­cio)

---

**VersÃ£o:** 1.0  
**Data:** 2026-02-07
