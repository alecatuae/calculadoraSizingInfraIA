#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
sizing.py - Dimensionamento Avan√ßado de Infer√™ncia de LLMs em GPU NVIDIA (DGX-class)
Autor: Sistema de Sizing de Infraestrutura IA
Data: 2026-02-08
Vers√£o: 2.0 - Com Racional de C√°lculo e 3 Cen√°rios

Calcula sizing baseado em mem√≥ria (KV cache) com explica√ß√µes detalhadas.
"""

import argparse
import json
import math
import sys
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple, Any


# ============================================================================
# CONSTANTES
# ============================================================================
GB_TO_GIB = 1e9 / (1024**3)  # Convers√£o de GB decimal para GiB

KV_PRECISION_BYTES = {
    "fp16": 2,
    "bf16": 2,
    "fp8": 1,
    "int8": 1,
}


# ============================================================================
# DATACLASSES
# ============================================================================
@dataclass
class Model:
    """Representa um modelo LLM com seus par√¢metros de arquitetura."""
    name: str
    num_layers: int
    num_key_value_heads: int
    head_dim: int
    max_position_embeddings: int
    attention_pattern: str  # "full", "sliding", "hybrid"
    hybrid_full_layers: Optional[int]
    hybrid_sliding_layers: Optional[int]
    sliding_window: Optional[int]
    default_kv_precision: str
    notes: str


@dataclass
class Server:
    """Representa um servidor GPU (n√≥ DGX-class)."""
    name: str
    gpus: int
    hbm_per_gpu_gb: float
    total_hbm_gb: float
    nvlink_bandwidth_tbps: Optional[float]
    system_memory_tb: Optional[float]
    rack_units_u: int
    power_kw_max: float
    heat_output_btu_hr_max: Optional[float]
    airflow_cfm: Optional[int]
    notes: str
    source: Optional[List[str]] = None


@dataclass
class StorageProfile:
    """Representa um perfil de storage com m√©tricas de I/O."""
    name: str
    type: str
    iops_read: int
    iops_write: int
    throughput_read_gbps: float
    throughput_write_gbps: float
    latency_read_ms_p50: float
    latency_read_ms_p99: float
    latency_write_ms_p50: float
    latency_write_ms_p99: float
    notes: str


@dataclass
class Rationale:
    """Racional de c√°lculo para um resultado."""
    formula: str
    inputs: Dict[str, Any]
    explanation: str


@dataclass
class ScenarioResult:
    """Resultado de um cen√°rio de dimensionamento."""
    name: str
    peak_headroom_ratio: float
    ha_mode: str
    ha_extra_nodes: int
    kv_budget_ratio: float
    
    kv_per_session_gib: float
    kv_total_gib: float
    kv_total_tib: float
    hbm_total_gib: float
    kv_budget_gib: float
    sessions_per_node: int
    nodes_capacity: int
    nodes_with_headroom: int
    nodes_final: int
    
    # Infraestrutura f√≠sica
    total_power_kw: float
    total_rack_u: int
    total_heat_btu_hr: Optional[float]
    
    rationale: Dict[str, Rationale]
    warnings: List[str]


# ============================================================================
# FUN√á√ïES DE CARREGAMENTO
# ============================================================================
def load_models(filepath: str = "models.json") -> Dict[str, Model]:
    """Carrega modelos do arquivo JSON."""
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    models = {}
    for m in data["models"]:
        model = Model(
            name=m["name"],
            num_layers=m["num_layers"],
            num_key_value_heads=m["num_key_value_heads"],
            head_dim=m["head_dim"],
            max_position_embeddings=m["max_position_embeddings"],
            attention_pattern=m["attention_pattern"],
            hybrid_full_layers=m.get("hybrid_full_layers"),
            hybrid_sliding_layers=m.get("hybrid_sliding_layers"),
            sliding_window=m.get("sliding_window"),
            default_kv_precision=m["default_kv_precision"],
            notes=m["notes"]
        )
        models[model.name] = model
    
    return models


def load_servers(filepath: str = "servers.json") -> Dict[str, Server]:
    """Carrega servidores do arquivo JSON."""
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    servers = {}
    for s in data["servers"]:
        total_hbm = s.get("total_hbm_gb")
        if total_hbm is None:
            total_hbm = s["gpus"] * s["hbm_per_gpu_gb"]
        
        server = Server(
            name=s["name"],
            gpus=s["gpus"],
            hbm_per_gpu_gb=s["hbm_per_gpu_gb"],
            total_hbm_gb=total_hbm,
            nvlink_bandwidth_tbps=s.get("nvlink_bandwidth_tbps"),
            system_memory_tb=s.get("system_memory_tb"),
            rack_units_u=s.get("rack_units_u", 10),  # Default 10U se n√£o especificado
            power_kw_max=s.get("power_kw_max", 0.0),
            heat_output_btu_hr_max=s.get("heat_output_btu_hr_max"),
            airflow_cfm=s.get("airflow_cfm"),
            notes=s["notes"],
            source=s.get("source")
        )
        servers[server.name] = server
    
    return servers


def load_storage_profiles(filepath: str = "storage.json") -> Dict[str, StorageProfile]:
    """Carrega perfis de storage do arquivo JSON."""
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    profiles = {}
    for p in data["profiles"]:
        profile = StorageProfile(
            name=p["name"],
            type=p["type"],
            iops_read=p["iops_read"],
            iops_write=p["iops_write"],
            throughput_read_gbps=p["throughput_read_gbps"],
            throughput_write_gbps=p["throughput_write_gbps"],
            latency_read_ms_p50=p["latency_read_ms_p50"],
            latency_read_ms_p99=p["latency_read_ms_p99"],
            latency_write_ms_p50=p["latency_write_ms_p50"],
            latency_write_ms_p99=p["latency_write_ms_p99"],
            notes=p["notes"]
        )
        profiles[profile.name] = profile
    
    return profiles


# ============================================================================
# DICION√ÅRIO DE PAR√ÇMETROS
# ============================================================================
def get_parameter_dictionary() -> Dict[str, Dict[str, str]]:
    """
    Retorna dicion√°rio explicativo de todos os par√¢metros usados no sizing.
    
    Para cada par√¢metro, fornece:
    - description: O que √©
    - source: De onde vem
    - importance: Por que √© importante
    - common_errors: Erros comuns
    """
    return {
        "num_layers": {
            "description": "N√∫mero total de camadas (layers) do transformer no modelo LLM. Cada camada possui seu pr√≥prio conjunto de tensores Key e Value no KV cache.",
            "source": "Par√¢metro fixo da arquitetura do modelo, definido em models.json. N√£o pode ser alterado em runtime.",
            "importance": "Impacta linearmente o tamanho do KV cache. Modelos com mais camadas (ex: 36 vs 24) consomem proporcionalmente mais mem√≥ria GPU para armazenar o hist√≥rico de aten√ß√£o.",
            "common_errors": "Erro comum: Confundir num_layers com num_hidden_layers ou contar apenas encoder/decoder. Deve ser o total de camadas que mant√™m KV cache."
        },
        "num_key_value_heads": {
            "description": "N√∫mero de cabe√ßas (heads) de aten√ß√£o para Key e Value. Em GQA (Grouped Query Attention), este valor pode ser menor que o n√∫mero de query heads.",
            "source": "Par√¢metro fixo da arquitetura do modelo (models.json). Modelos modernos usam GQA para reduzir KV cache.",
            "importance": "Impacta diretamente o tamanho do KV cache. Menos KV heads = menos mem√≥ria. GQA com 8 KV heads vs 32 representa redu√ß√£o de 4x na mem√≥ria de KV.",
            "common_errors": "Erro comum: Usar num_attention_heads (query heads) em vez de num_key_value_heads. Em GQA esses valores s√£o diferentes e isso causa superestima√ß√£o de 4-8x na mem√≥ria."
        },
        "head_dim": {
            "description": "Dimensionalidade de cada cabe√ßa de aten√ß√£o (ex: 64, 128). Tamanho do vetor de embedding por head.",
            "source": "Par√¢metro fixo da arquitetura do modelo (models.json). Geralmente 64 ou 128.",
            "importance": "Multiplica linearmente o tamanho do KV cache. head_dim=128 vs 64 dobra a mem√≥ria necess√°ria por head.",
            "common_errors": "Erro comum: Confundir head_dim com hidden_size. hidden_size = num_attention_heads √ó head_dim. Usar hidden_size diretamente causa erro massivo."
        },
        "max_position_embeddings": {
            "description": "Comprimento m√°ximo de contexto (em tokens) que o modelo foi treinado para suportar. Limite arquitetural do positional embedding.",
            "source": "Par√¢metro fixo da arquitetura do modelo (models.json). Definido no training.",
            "importance": "Define o limite superior para effective_context. Tentar usar contextos maiores causa comportamento indefinido (extrapola√ß√£o de posi√ß√µes).",
            "common_errors": "Erro comum: Ignorar este limite e usar effective_context > max_position_embeddings. Isso leva a resultados incorretos ou crashes em runtime."
        },
        "attention_pattern": {
            "description": "Padr√£o de aten√ß√£o usado pelo modelo: 'full' (todas camadas atendem contexto completo), 'sliding' (janela deslizante), ou 'hybrid' (mix de full e sliding).",
            "source": "Par√¢metro fixo da arquitetura do modelo (models.json). Define como o modelo processa contexto longo.",
            "importance": "Cr√≠tico para c√°lculo correto de KV cache. Sliding window pode reduzir KV cache drasticamente (ex: 128k context com window=128 usa 1000x menos mem√≥ria que full attention).",
            "common_errors": "Erro comum: Assumir 'full' para todos os modelos. Modelos modernos usam hybrid/sliding. Usar 'full' quando modelo √© 'sliding' superestima mem√≥ria em ordens de magnitude."
        },
        "sliding_window": {
            "description": "Tamanho da janela de aten√ß√£o deslizante (em tokens) para camadas com sliding attention. Apenas os √∫ltimos N tokens s√£o atendidos.",
            "source": "Par√¢metro fixo da arquitetura do modelo (models.json), aplic√°vel apenas se attention_pattern='sliding' ou 'hybrid'.",
            "importance": "Controla o tamanho do KV cache para camadas sliding. Sliding window pequeno (128) vs contexto longo (128k) reduz mem√≥ria por camada em 1000x.",
            "common_errors": "Erro comum: N√£o usar sliding_window para camadas sliding, assumindo contexto completo. Isso causa overestimation massiva de mem√≥ria e sizing incorreto."
        },
        "effective_context": {
            "description": "Tamanho de contexto (em tokens) que sua aplica√ß√£o efetivamente usar√° em runtime. Diferente de max_position_embeddings (limite do modelo).",
            "source": "NFR (Non-Functional Requirement) do produto/aplica√ß√£o. Voc√™ define baseado no use case (ex: 4k para chat, 128k para an√°lise de documentos).",
            "importance": "Impacta diretamente o tamanho do KV cache por sess√£o. Contexto maior = mais mem√≥ria = menos sess√µes por n√≥. Definir incorretamente causa over/under-provisioning.",
            "common_errors": "Erro comum: Usar max_position_embeddings como effective_context. Isso superestima mem√≥ria se aplica√ß√£o usa contextos menores, ou causa problemas se excede o limite do modelo."
        },
        "kv_precision": {
            "description": "Precis√£o num√©rica usada para armazenar tensores Key e Value: fp8/int8 (1 byte/elemento) ou fp16/bf16 (2 bytes/elemento).",
            "source": "Par√¢metro de runtime configur√°vel. fp8 √© recomendado para economia de mem√≥ria com m√≠nima perda de qualidade.",
            "importance": "Impacta diretamente (2x) o tamanho do KV cache. fp16 vs fp8 dobra a mem√≥ria necess√°ria e reduz pela metade o n√∫mero de sess√µes por n√≥.",
            "common_errors": "Erro comum: Usar fp16 por default sem testar fp8. Muitos casos fp8 tem qualidade equivalente, mas fp16 dobra o custo de infraestrutura desnecessariamente."
        },
        "concurrency": {
            "description": "N√∫mero de sess√µes/requisi√ß√µes simult√¢neas (concurrent users) que o sistema deve suportar. M√©trica de throughput.",
            "source": "NFR do produto, baseado em proje√ß√µes de tr√°fego e SLA. Pode vir de an√°lise de uso, teste de carga, ou requisitos de neg√≥cio.",
            "importance": "Define quantos n√≥s voc√™ precisa. Concurrency mal estimada causa: subdimensionamento (SLA quebrado, throttling) ou superdimensionamento (desperd√≠cio de capex).",
            "common_errors": "Erro comum: Confundir concurrency (sess√µes simult√¢neas) com RPS (requests per second). Concurrency = sess√µes ativas ao mesmo tempo. RPS considera lat√™ncia."
        },
        "kv_budget_ratio": {
            "description": "Fra√ß√£o da HBM total alocada para KV cache (ex: 0.70 = 70%). O restante √© para modelo, ativa√ß√µes, overhead de runtime.",
            "source": "Par√¢metro de tuning/configura√ß√£o. Default 0.70 √© conservador. Pode ser ajustado baseado em profiling real.",
            "importance": "Define quantas sess√µes cabem por n√≥. Budget muito alto (>0.80) causa fragmenta√ß√£o e instabilidade. Budget muito baixo (<0.50) desperdi√ßa HBM.",
            "common_errors": "Erro comum: Alocar 100% da HBM para KV cache, ignorando overhead do modelo, ativa√ß√µes, e buffers do runtime. Isso causa OOM (Out of Memory) em produ√ß√£o."
        },
        "runtime_overhead_gib": {
            "description": "Mem√≥ria GPU (GiB) reservada para modelo (pesos), ativa√ß√µes de computa√ß√£o, e buffers do runtime de infer√™ncia.",
            "source": "Estimativa baseada em tamanho do modelo e framework. Pode ser medido via profiling. Default conservador: 80-150 GiB para modelos grandes.",
            "importance": "Subtrai da HBM dispon√≠vel antes de calcular budget de KV. Subestimar causa OOM. Superestimar desperdi√ßa capacidade.",
            "common_errors": "Erro comum: Usar overhead muito baixo (<50 GiB) para modelos grandes (>100B par√¢metros). Modelo 120B em fp16 sozinho j√° ocupa ~240 GiB."
        },
        "peak_headroom_ratio": {
            "description": "Fra√ß√£o adicional de capacidade reservada para picos de tr√°fego (ex: 0.20 = 20% acima da concurrency nominal).",
            "source": "NFR de SRE, baseado em an√°lise de sazonalidade e requisitos de SLO. T√≠pico: 10-30%.",
            "importance": "Garante que sistema aguenta picos sem degrada√ß√£o de SLO. Sem headroom, qualquer pico causa throttling ou viola√ß√£o de SLA.",
            "common_errors": "Erro comum: N√£o ter headroom (0%) em produ√ß√£o. Tr√°fego sempre tem varia√ß√£o. Outro erro: headroom excessivo (>50%) que desperdi√ßa capex."
        },
        "ha_mode": {
            "description": "Modo de alta disponibilidade: 'none' (sem redund√¢ncia), 'n+1' (tolera falha de 1 n√≥), 'n+2' (tolera 2 n√≥s).",
            "source": "NFR de disponibilidade, baseado em SLA. Produ√ß√£o cr√≠tica geralmente requer no m√≠nimo N+1.",
            "importance": "Define quantos n√≥s extras alocar para redund√¢ncia. N+1 garante que falha de 1 n√≥ n√£o quebra SLA. Sem HA, falha de n√≥ causa degrada√ß√£o imediata.",
            "common_errors": "Erro comum: N√£o ter HA (none) em produ√ß√£o com SLA > 99%. Falha de hardware √© inevit√°vel. Outro erro: N+2 quando N+1 j√° atende, desperdi√ßando capex."
        }
    }


# ============================================================================
# FUN√á√ïES DE C√ÅLCULO COM RACIONAL
# ============================================================================
def calc_kv_per_session_with_rationale(
    model: Model,
    effective_context: int,
    kv_precision: str
) -> Tuple[float, Dict[str, Rationale], List[str]]:
    """
    Calcula KV cache por sess√£o (GiB) com racional detalhado.
    
    Returns:
        (kv_gib, rationale_dict, warnings)
    """
    warnings = []
    rationale = {}
    bytes_per_elem = KV_PRECISION_BYTES[kv_precision]
    
    # Validar e clampar effective_context
    original_context = effective_context
    if effective_context > model.max_position_embeddings:
        warnings.append(
            f"AVISO: effective_context={effective_context} excede "
            f"max_position_embeddings={model.max_position_embeddings}. "
            f"Clampado para {model.max_position_embeddings}."
        )
        effective_context = model.max_position_embeddings
    
    # Calcular baseado no padr√£o de aten√ß√£o
    total_bytes = 0
    formula_parts = []
    
    if model.attention_pattern == "full":
        seq_len = effective_context
        bytes_per_layer = 2 * seq_len * model.num_key_value_heads * model.head_dim * bytes_per_elem
        total_bytes = bytes_per_layer * model.num_layers
        
        formula_parts.append(f"Full attention: todas {model.num_layers} camadas")
        formula_parts.append(f"bytes_per_layer = 2 √ó {seq_len} √ó {model.num_key_value_heads} √ó {model.head_dim} √ó {bytes_per_elem}")
        formula_parts.append(f"total = {model.num_layers} √ó bytes_per_layer")
    
    elif model.attention_pattern == "sliding":
        seq_len = model.sliding_window
        bytes_per_layer = 2 * seq_len * model.num_key_value_heads * model.head_dim * bytes_per_elem
        total_bytes = bytes_per_layer * model.num_layers
        
        formula_parts.append(f"Sliding window: todas {model.num_layers} camadas com window={model.sliding_window}")
        formula_parts.append(f"bytes_per_layer = 2 √ó {seq_len} √ó {model.num_key_value_heads} √ó {model.head_dim} √ó {bytes_per_elem}")
        formula_parts.append(f"total = {model.num_layers} √ó bytes_per_layer")
    
    elif model.attention_pattern == "hybrid":
        # Full layers
        seq_full = effective_context
        bytes_full = 2 * seq_full * model.num_key_value_heads * model.head_dim * bytes_per_elem
        total_full = bytes_full * model.hybrid_full_layers
        
        # Sliding layers
        seq_sliding = model.sliding_window
        bytes_sliding = 2 * seq_sliding * model.num_key_value_heads * model.head_dim * bytes_per_elem
        total_sliding = bytes_sliding * model.hybrid_sliding_layers
        
        total_bytes = total_full + total_sliding
        
        formula_parts.append(f"Hybrid attention: {model.hybrid_full_layers} full + {model.hybrid_sliding_layers} sliding")
        formula_parts.append(f"Full: 2 √ó {seq_full} √ó {model.num_key_value_heads} √ó {model.head_dim} √ó {bytes_per_elem} √ó {model.hybrid_full_layers}")
        formula_parts.append(f"Sliding: 2 √ó {seq_sliding} √ó {model.num_key_value_heads} √ó {model.head_dim} √ó {bytes_per_elem} √ó {model.hybrid_sliding_layers}")
        formula_parts.append(f"total = full + sliding")
    
    kv_gib = total_bytes / (1024**3)
    
    # Criar racional
    rationale["kv_per_session_gib"] = Rationale(
        formula="\n".join(formula_parts),
        inputs={
            "model": model.name,
            "num_layers": model.num_layers,
            "num_kv_heads": model.num_key_value_heads,
            "head_dim": model.head_dim,
            "attention_pattern": model.attention_pattern,
            "effective_context": effective_context,
            "original_context": original_context if original_context != effective_context else None,
            "sliding_window": model.sliding_window if model.attention_pattern in ["sliding", "hybrid"] else None,
            "kv_precision": kv_precision,
            "bytes_per_element": bytes_per_elem,
            "total_bytes": total_bytes
        },
        explanation=(
            f"KV cache armazena tensores Key e Value de todas as camadas para o contexto da sess√£o. "
            f"Cada posi√ß√£o no contexto mant√©m {model.num_key_value_heads} heads √ó {model.head_dim} dims √ó {bytes_per_elem} bytes/elem = "
            f"{model.num_key_value_heads * model.head_dim * bytes_per_elem} bytes por posi√ß√£o (K+V separados, da√≠ fator 2). "
            f"Modelo com attention_pattern='{model.attention_pattern}' usa contexto efetivo diferente por camada. "
            f"Total de {kv_gib:.2f} GiB por sess√£o ativa."
        )
    )
    
    # Avisos adicionais
    if kv_precision in ["fp16", "bf16"]:
        warnings.append(
            f"AVISO: kv_precision={kv_precision} usa 2 bytes/elemento. "
            f"Considere fp8 (1 byte) para reduzir mem√≥ria pela metade com m√≠nima perda de qualidade."
        )
    
    return kv_gib, rationale, warnings


def calc_scenario_sizing(
    model: Model,
    server: Server,
    storage: StorageProfile,
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    kv_budget_ratio: float,
    runtime_overhead_gib: float,
    peak_headroom_ratio: float,
    ha_extra_nodes: int,
    scenario_name: str
) -> ScenarioResult:
    """
    Calcula sizing completo para um cen√°rio com racional detalhado.
    """
    warnings = []
    all_rationale = {}
    
    # 1) KV por sess√£o
    kv_per_session_gib, kv_rationale, kv_warnings = calc_kv_per_session_with_rationale(
        model, effective_context, kv_precision
    )
    all_rationale.update(kv_rationale)
    warnings.extend(kv_warnings)
    
    # 2) KV total
    kv_total_gib = kv_per_session_gib * concurrency
    kv_total_tib = kv_total_gib / 1024
    
    all_rationale["kv_total_gib"] = Rationale(
        formula=f"kv_total_gib = kv_per_session_gib √ó concurrency",
        inputs={
            "kv_per_session_gib": round(kv_per_session_gib, 4),
            "concurrency": concurrency
        },
        explanation=(
            f"Mem√≥ria total de KV cache necess√°ria para suportar {concurrency:,} sess√µes simult√¢neas. "
            f"Cada sess√£o precisa de {kv_per_session_gib:.2f} GiB, totalizando {kv_total_tib:.2f} TiB "
            f"distribu√≠dos entre os n√≥s do cluster."
        )
    )
    
    # 3) HBM total do servidor
    hbm_total_gib = server.total_hbm_gb * GB_TO_GIB
    
    all_rationale["hbm_total_gib"] = Rationale(
        formula=f"hbm_total_gib = total_hbm_gb √ó (10^9 / 2^30)",
        inputs={
            "server": server.name,
            "gpus": server.gpus,
            "hbm_per_gpu_gb": server.hbm_per_gpu_gb,
            "total_hbm_gb": server.total_hbm_gb,
            "gb_to_gib_factor": GB_TO_GIB
        },
        explanation=(
            f"Servidor {server.name} tem {server.gpus} GPUs √ó {server.hbm_per_gpu_gb} GB/GPU = "
            f"{server.total_hbm_gb} GB total. Convertido para GiB (bin√°rio): {hbm_total_gib:.1f} GiB. "
            f"Esta √© a mem√≥ria total dispon√≠vel por n√≥ para modelo, KV cache, ativa√ß√µes e buffers."
        )
    )
    
    # 4) Budget de KV por n√≥
    kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) * kv_budget_ratio)
    
    all_rationale["kv_budget_gib"] = Rationale(
        formula=f"kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) √ó kv_budget_ratio)",
        inputs={
            "hbm_total_gib": round(hbm_total_gib, 2),
            "runtime_overhead_gib": runtime_overhead_gib,
            "kv_budget_ratio": kv_budget_ratio,
            "available_after_overhead_gib": round(hbm_total_gib - runtime_overhead_gib, 2)
        },
        explanation=(
            f"De {hbm_total_gib:.1f} GiB de HBM, reservamos {runtime_overhead_gib} GiB para modelo+ativa√ß√µes. "
            f"Dos {hbm_total_gib - runtime_overhead_gib:.1f} GiB restantes, alocamos {kv_budget_ratio*100:.0f}% "
            f"({kv_budget_gib:.1f} GiB) para KV cache. O resto ({(1-kv_budget_ratio)*100:.0f}%) fica como buffer "
            f"para fragmenta√ß√£o e overhead de runtime."
        )
    )
    
    # 5) Sess√µes por n√≥
    if kv_budget_gib <= 0:
        sessions_per_node = 0
        warnings.append(
            f"ERRO: Budget de KV <= 0 (hbm_total={hbm_total_gib:.1f} GiB, overhead={runtime_overhead_gib} GiB). "
            f"Servidor n√£o tem mem√≥ria suficiente. Reduza overhead ou use servidor maior."
        )
    else:
        sessions_per_node = int(kv_budget_gib / kv_per_session_gib)
        
        if sessions_per_node == 0:
            warnings.append(
                f"ERRO: Sess√µes por n√≥ = 0. Uma √∫nica sess√£o precisa de {kv_per_session_gib:.2f} GiB mas budget √© {kv_budget_gib:.1f} GiB. "
                f"Solu√ß√µes: (1) Reduzir effective_context, (2) Usar fp8 em vez de fp16, (3) Reduzir runtime_overhead_gib, "
                f"(4) Aumentar kv_budget_ratio, ou (5) Usar servidor com mais HBM."
            )
    
    all_rationale["sessions_per_node"] = Rationale(
        formula=f"sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)",
        inputs={
            "kv_budget_gib": round(kv_budget_gib, 2),
            "kv_per_session_gib": round(kv_per_session_gib, 4)
        },
        explanation=(
            f"Com {kv_budget_gib:.1f} GiB dispon√≠veis para KV e cada sess√£o consumindo {kv_per_session_gib:.2f} GiB, "
            f"cada n√≥ pode suportar {sessions_per_node} sess√µes simult√¢neas. Este √© o limite de capacidade por n√≥ "
            f"baseado exclusivamente em mem√≥ria de KV cache."
        )
    )
    
    # 6) N√≥s necess√°rios
    if sessions_per_node > 0:
        nodes_capacity = math.ceil(concurrency / sessions_per_node)
        concurrency_with_headroom = concurrency * (1 + peak_headroom_ratio)
        nodes_with_headroom = math.ceil(concurrency_with_headroom / sessions_per_node)
    else:
        nodes_capacity = 0
        nodes_with_headroom = 0
    
    nodes_final = nodes_with_headroom + ha_extra_nodes
    
    all_rationale["nodes_capacity"] = Rationale(
        formula=f"nodes_capacity = ceil(concurrency / sessions_per_node)",
        inputs={
            "concurrency": concurrency,
            "sessions_per_node": sessions_per_node
        },
        explanation=(
            f"Para atender {concurrency:,} sess√µes simult√¢neas com {sessions_per_node} sess√µes/n√≥, "
            f"precisamos de no m√≠nimo {nodes_capacity} n√≥s. Este √© o dimensionamento de capacidade pura, "
            f"sem considerar headroom para picos ou redund√¢ncia para HA."
        )
    )
    
    all_rationale["nodes_with_headroom"] = Rationale(
        formula=f"nodes_with_headroom = ceil(concurrency √ó (1 + peak_headroom_ratio) / sessions_per_node)",
        inputs={
            "concurrency": concurrency,
            "peak_headroom_ratio": peak_headroom_ratio,
            "concurrency_with_headroom": round(concurrency * (1 + peak_headroom_ratio), 1),
            "sessions_per_node": sessions_per_node
        },
        explanation=(
            f"Adicionando {peak_headroom_ratio*100:.0f}% de headroom para picos de tr√°fego, precisamos suportar "
            f"{concurrency * (1 + peak_headroom_ratio):.0f} sess√µes simult√¢neas, resultando em {nodes_with_headroom} n√≥s. "
            f"Headroom garante que o sistema aguenta varia√ß√µes de carga sem degrada√ß√£o de SLO."
        )
    )
    
    all_rationale["nodes_final"] = Rationale(
        formula=f"nodes_final = nodes_with_headroom + ha_extra_nodes",
        inputs={
            "nodes_with_headroom": nodes_with_headroom,
            "ha_extra_nodes": ha_extra_nodes,
            "ha_mode": "n+2" if ha_extra_nodes == 2 else ("n+1" if ha_extra_nodes == 1 else "none")
        },
        explanation=(
            f"Adicionando {ha_extra_nodes} n√≥(s) para alta disponibilidade, total final √© {nodes_final} n√≥s. "
            f"{'Sem HA: qualquer falha de n√≥ causa degrada√ß√£o imediata.' if ha_extra_nodes == 0 else ''}"
            f"{'Com N+1: sistema tolera falha de 1 n√≥ mantendo SLO.' if ha_extra_nodes == 1 else ''}"
            f"{'Com N+2: sistema tolera falha de 2 n√≥s mantendo SLO.' if ha_extra_nodes == 2 else ''}"
        )
    )
    
    # Avisos adicionais
    if effective_context >= 128000:
        warnings.append(
            f"ALERTA: Contexto longo ({effective_context:,} tokens) aumenta TTFT (Time To First Token) e pressiona I/O de storage "
            f"durante prefill. Storage: {storage.name} ({storage.throughput_read_gbps} GB/s read, P99={storage.latency_read_ms_p99} ms)."
        )
    
    if kv_budget_ratio > 0.75:
        warnings.append(
            f"ALERTA: kv_budget_ratio={kv_budget_ratio} √© alto (>75%). Risco de fragmenta√ß√£o de mem√≥ria e instabilidade. "
            f"Considere reduzir para 0.65-0.70 ou usar servidor com mais HBM."
        )
    
    if runtime_overhead_gib < 50:
        warnings.append(
            f"ALERTA: runtime_overhead_gib={runtime_overhead_gib} parece baixo (<50 GiB). "
            f"Modelos grandes (>50B par√¢metros) tipicamente precisam de 80-150 GiB. Verifique se n√£o est√° subestimado."
        )
    
    # 7) Infraestrutura F√≠sica
    # Energia total
    total_power_kw = nodes_final * server.power_kw_max
    
    all_rationale["total_power_kw"] = Rationale(
        formula=f"total_power_kw = nodes_final √ó power_kw_max",
        inputs={
            "nodes_final": nodes_final,
            "power_kw_max": server.power_kw_max,
            "server": server.name
        },
        explanation=(
            f"Consumo total de energia para {nodes_final} n√≥s √ó {server.power_kw_max} kW/n√≥ = {total_power_kw} kW. "
            f"Este √© o dimensionamento de energia m√°xima do sistema, impactando PDU (Power Distribution Unit), "
            f"capacidade de UPS, e contrato de energia do data center. Considere tamb√©m efici√™ncia de cooling (PUE ~1.3-1.5x)."
        )
    )
    
    # Espa√ßo em rack
    total_rack_u = nodes_final * server.rack_units_u
    
    all_rationale["total_rack_u"] = Rationale(
        formula=f"total_rack_u = nodes_final √ó rack_units_u",
        inputs={
            "nodes_final": nodes_final,
            "rack_units_u": server.rack_units_u,
            "server": server.name
        },
        explanation=(
            f"Espa√ßo total de rack necess√°rio: {nodes_final} n√≥s √ó {server.rack_units_u}U/n√≥ = {total_rack_u}U. "
            f"Considerando racks padr√£o de 42U, isto equivale a {total_rack_u/42:.1f} racks. "
            f"Impacta densidade de implanta√ß√£o e capacidade f√≠sica do data center. "
            f"Adicione ~20% para switches, PDUs e espa√ßo de ventila√ß√£o."
        )
    )
    
    # Heat output (se dispon√≠vel)
    total_heat_btu_hr = None
    if server.heat_output_btu_hr_max is not None:
        total_heat_btu_hr = nodes_final * server.heat_output_btu_hr_max
        
        all_rationale["total_heat_btu_hr"] = Rationale(
            formula=f"total_heat_btu_hr = nodes_final √ó heat_output_btu_hr_max",
            inputs={
                "nodes_final": nodes_final,
                "heat_output_btu_hr_max": server.heat_output_btu_hr_max,
                "server": server.name
            },
            explanation=(
                f"Dissipa√ß√£o t√©rmica total: {nodes_final} n√≥s √ó {server.heat_output_btu_hr_max:,.0f} BTU/hr/n√≥ = "
                f"{total_heat_btu_hr:,.0f} BTU/hr. Isto define a capacidade de refrigera√ß√£o (cooling capacity) necess√°ria. "
                f"BTU/hr pode ser convertido em toneladas de refrigera√ß√£o (1 ton = 12,000 BTU/hr): "
                f"{total_heat_btu_hr/12000:.1f} tons. Impacta HVAC e COP (Coefficient of Performance) do data center."
            )
        )
    
    # Criar resultado
    result = ScenarioResult(
        name=scenario_name,
        peak_headroom_ratio=peak_headroom_ratio,
        ha_mode="n+2" if ha_extra_nodes == 2 else ("n+1" if ha_extra_nodes == 1 else "none"),
        ha_extra_nodes=ha_extra_nodes,
        kv_budget_ratio=kv_budget_ratio,
        kv_per_session_gib=kv_per_session_gib,
        kv_total_gib=kv_total_gib,
        kv_total_tib=kv_total_tib,
        hbm_total_gib=hbm_total_gib,
        kv_budget_gib=kv_budget_gib,
        sessions_per_node=sessions_per_node,
        nodes_capacity=nodes_capacity,
        nodes_with_headroom=nodes_with_headroom,
        nodes_final=nodes_final,
        total_power_kw=total_power_kw,
        total_rack_u=total_rack_u,
        total_heat_btu_hr=total_heat_btu_hr,
        rationale=all_rationale,
        warnings=warnings
    )
    
    return result


# ============================================================================
# FUN√á√ÉO PRINCIPAL DE SIZING (3 CEN√ÅRIOS)
# ============================================================================
def calculate_sizing_all_scenarios(
    model: Model,
    server: Server,
    storage: StorageProfile,
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    kv_budget_ratio: float,
    runtime_overhead_gib: float,
    peak_headroom_ratio: float,
    verbose: bool = False
) -> Dict[str, ScenarioResult]:
    """
    Calcula sizing para os 3 cen√°rios obrigat√≥rios: M√çNIMO, RECOMENDADO, IDEAL.
    """
    scenarios = {}
    
    # CEN√ÅRIO M√çNIMO
    scenarios["minimum"] = calc_scenario_sizing(
        model=model,
        server=server,
        storage=storage,
        concurrency=concurrency,
        effective_context=effective_context,
        kv_precision=kv_precision,
        kv_budget_ratio=kv_budget_ratio,
        runtime_overhead_gib=runtime_overhead_gib,
        peak_headroom_ratio=0.0,  # Sem headroom
        ha_extra_nodes=0,  # Sem HA
        scenario_name="M√çNIMO"
    )
    
    # CEN√ÅRIO RECOMENDADO
    scenarios["recommended"] = calc_scenario_sizing(
        model=model,
        server=server,
        storage=storage,
        concurrency=concurrency,
        effective_context=effective_context,
        kv_precision=kv_precision,
        kv_budget_ratio=kv_budget_ratio,
        runtime_overhead_gib=runtime_overhead_gib,
        peak_headroom_ratio=peak_headroom_ratio,  # Headroom configurado
        ha_extra_nodes=1,  # N+1
        scenario_name="RECOMENDADO"
    )
    
    # CEN√ÅRIO IDEAL
    # IDEAL √© mais conservador: headroom m√≠nimo de 30%, N+2, budget ratio mais conservador
    ideal_headroom = max(peak_headroom_ratio, 0.30)
    ideal_budget_ratio = min(kv_budget_ratio, 0.65)
    
    scenarios["ideal"] = calc_scenario_sizing(
        model=model,
        server=server,
        storage=storage,
        concurrency=concurrency,
        effective_context=effective_context,
        kv_precision=kv_precision,
        kv_budget_ratio=ideal_budget_ratio,  # Mais conservador
        runtime_overhead_gib=runtime_overhead_gib,
        peak_headroom_ratio=ideal_headroom,  # M√≠nimo 30%
        ha_extra_nodes=2,  # N+2
        scenario_name="IDEAL"
    )
    
    return scenarios


# ============================================================================
# FORMATA√á√ÉO DE SA√çDA
# ============================================================================
def format_report(
    model: Model,
    server: Server,
    storage: StorageProfile,
    scenarios: Dict[str, ScenarioResult],
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    verbose: bool = False
) -> str:
    """Formata relat√≥rio completo em texto."""
    lines = []
    lines.append("=" * 100)
    lines.append("RELAT√ìRIO DE DIMENSIONAMENTO AVAN√áADO DE INFER√äNCIA LLM")
    lines.append("Sistema de Sizing com Racional de C√°lculo e An√°lise de Cen√°rios")
    lines.append("=" * 100)
    lines.append("")
    
    # ========================================================================
    # SE√á√ÉO 1: ENTRADAS
    # ========================================================================
    lines.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    lines.append("‚îÇ" + " SE√á√ÉO 1: ENTRADAS (Modelo / Servidor / Storage / NFR)".ljust(98) + "‚îÇ")
    lines.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    lines.append("")
    
    lines.append("MODELO:")
    lines.append(f"  Nome: {model.name}")
    lines.append(f"  Camadas: {model.num_layers}")
    lines.append(f"  KV Heads: {model.num_key_value_heads}")
    lines.append(f"  Head Dim: {model.head_dim}")
    lines.append(f"  Max Position Embeddings: {model.max_position_embeddings:,}")
    lines.append(f"  Padr√£o de Aten√ß√£o: {model.attention_pattern}")
    if model.attention_pattern == "hybrid":
        lines.append(f"    ‚Ä¢ Full Layers: {model.hybrid_full_layers}")
        lines.append(f"    ‚Ä¢ Sliding Layers: {model.hybrid_sliding_layers}")
        lines.append(f"    ‚Ä¢ Sliding Window: {model.sliding_window}")
    elif model.attention_pattern == "sliding":
        lines.append(f"    ‚Ä¢ Sliding Window: {model.sliding_window}")
    lines.append(f"  Precis√£o KV Padr√£o: {model.default_kv_precision}")
    lines.append("")
    
    lines.append("SERVIDOR:")
    lines.append(f"  Nome: {server.name}")
    lines.append(f"  GPUs: {server.gpus}")
    lines.append(f"  HBM por GPU: {server.hbm_per_gpu_gb} GB")
    lines.append(f"  HBM Total: {server.total_hbm_gb} GB ({server.total_hbm_gb * GB_TO_GIB:.1f} GiB)")
    if server.nvlink_bandwidth_tbps:
        lines.append(f"  NVLink Bandwidth: {server.nvlink_bandwidth_tbps} TB/s")
    lines.append("")
    
    lines.append("STORAGE:")
    lines.append(f"  Perfil: {storage.name}")
    lines.append(f"  Tipo: {storage.type}")
    lines.append(f"  IOPS: {storage.iops_read:,} read / {storage.iops_write:,} write")
    lines.append(f"  Throughput: {storage.throughput_read_gbps} GB/s read / {storage.throughput_write_gbps} GB/s write")
    lines.append(f"  Lat√™ncia P99: {storage.latency_read_ms_p99} ms read / {storage.latency_write_ms_p99} ms write")
    lines.append("")
    
    lines.append("NFR (Non-Functional Requirements):")
    lines.append(f"  Concorr√™ncia Alvo: {concurrency:,} sess√µes simult√¢neas")
    lines.append(f"  Contexto Efetivo: {effective_context:,} tokens")
    lines.append(f"  Precis√£o KV: {kv_precision}")
    lines.append("")
    
    # ========================================================================
    # SE√á√ÉO 2: DICION√ÅRIO DE PAR√ÇMETROS
    # ========================================================================
    lines.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    lines.append("‚îÇ" + " SE√á√ÉO 2: DICION√ÅRIO DE PAR√ÇMETROS (Explica√ß√£o e Import√¢ncia)".ljust(98) + "‚îÇ")
    lines.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    lines.append("")
    
    param_dict = get_parameter_dictionary()
    
    # Mostrar apenas par√¢metros mais relevantes no relat√≥rio texto (todos v√£o pro JSON)
    key_params = [
        "num_layers", "num_key_value_heads", "head_dim", "attention_pattern",
        "effective_context", "kv_precision", "concurrency", "kv_budget_ratio",
        "runtime_overhead_gib", "peak_headroom_ratio", "ha_mode"
    ]
    
    for param_name in key_params:
        if param_name in param_dict:
            p = param_dict[param_name]
            lines.append(f"„Äê{param_name}„Äë")
            lines.append(f"  O que √©: {p['description']}")
            lines.append(f"  Origem: {p['source']}")
            lines.append(f"  Import√¢ncia: {p['importance']}")
            lines.append(f"  Erro comum: {p['common_errors']}")
            lines.append("")
    
    lines.append("(Veja JSON para dicion√°rio completo de todos os par√¢metros)")
    lines.append("")
    
    # ========================================================================
    # SE√á√ÉO 3: RESULTADOS POR CEN√ÅRIO
    # ========================================================================
    lines.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    lines.append("‚îÇ" + " SE√á√ÉO 3: RESULTADOS POR CEN√ÅRIO (M√çNIMO / RECOMENDADO / IDEAL)".ljust(98) + "‚îÇ")
    lines.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    lines.append("")
    
    for scenario_key in ["minimum", "recommended", "ideal"]:
        scenario = scenarios[scenario_key]
        lines.append("=" * 100)
        lines.append(f"CEN√ÅRIO: {scenario.name}")
        lines.append("=" * 100)
        lines.append(f"  ‚Ä¢ Peak Headroom: {scenario.peak_headroom_ratio * 100:.0f}%")
        lines.append(f"  ‚Ä¢ HA Mode: {scenario.ha_mode}")
        lines.append(f"  ‚Ä¢ KV Budget Ratio: {scenario.kv_budget_ratio * 100:.0f}%")
        lines.append("")
        
        # Resultados com racional
        results_to_show = [
            ("kv_per_session_gib", f"{scenario.kv_per_session_gib:.2f} GiB"),
            ("kv_total_gib", f"{scenario.kv_total_tib:.2f} TiB ({scenario.kv_total_gib:.2f} GiB)"),
            ("hbm_total_gib", f"{scenario.hbm_total_gib:.1f} GiB"),
            ("kv_budget_gib", f"{scenario.kv_budget_gib:.1f} GiB"),
            ("sessions_per_node", f"{scenario.sessions_per_node:,} sess√µes"),
            ("nodes_capacity", f"{scenario.nodes_capacity} n√≥s"),
            ("nodes_with_headroom", f"{scenario.nodes_with_headroom} n√≥s"),
            ("nodes_final", f"{scenario.nodes_final} n√≥s"),
        ]
        
        for key, value in results_to_show:
            lines.append(f"‚ñ∏ {key.replace('_', ' ').title()}: {value}")
            
            if key in scenario.rationale:
                rat = scenario.rationale[key]
                lines.append("")
                lines.append("  Racional:")
                lines.append(f"    F√≥rmula:")
                for formula_line in rat.formula.split('\n'):
                    lines.append(f"      {formula_line}")
                lines.append(f"    Inputs:")
                for input_key, input_val in rat.inputs.items():
                    if input_val is not None:
                        lines.append(f"      ‚Ä¢ {input_key}: {input_val}")
                lines.append(f"    Interpreta√ß√£o:")
                # Quebrar explanation em linhas de no m√°ximo 90 chars
                explanation_words = rat.explanation.split()
                current_line = "      "
                for word in explanation_words:
                    if len(current_line) + len(word) + 1 <= 96:
                        current_line += word + " "
                    else:
                        lines.append(current_line.rstrip())
                        current_line = "      " + word + " "
                if current_line.strip():
                    lines.append(current_line.rstrip())
                lines.append("")
        
        # Avisos do cen√°rio
        if scenario.warnings:
            lines.append("  ‚ö†Ô∏è  AVISOS DESTE CEN√ÅRIO:")
            for i, warning in enumerate(scenario.warnings, 1):
                lines.append(f"    [{i}] {warning}")
            lines.append("")
    
    # ========================================================================
    # SE√á√ÉO 4: ALERTAS E RISCOS
    # ========================================================================
    lines.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    lines.append("‚îÇ" + " SE√á√ÉO 4: ALERTAS E RISCOS OPERACIONAIS".ljust(98) + "‚îÇ")
    lines.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    lines.append("")
    
    # Coletar todos os avisos √∫nicos de todos os cen√°rios
    all_warnings = set()
    for scenario in scenarios.values():
        all_warnings.update(scenario.warnings)
    
    if all_warnings:
        for i, warning in enumerate(sorted(all_warnings), 1):
            lines.append(f"[{i}] {warning}")
    else:
        lines.append("Nenhum alerta cr√≠tico detectado.")
    
    lines.append("")
    lines.append("=" * 100)
    lines.append("FIM DO RELAT√ìRIO")
    lines.append("=" * 100)
    
    return "\n".join(lines)


def format_report_markdown(
    model: Model,
    server: Server,
    storage: StorageProfile,
    scenarios: Dict[str, ScenarioResult],
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    verbose: bool = False
) -> str:
    """Formata relat√≥rio completo em Markdown."""
    lines = []
    
    # T√≠tulo
    lines.append("# Relat√≥rio de Dimensionamento de Infer√™ncia LLM")
    lines.append("")
    lines.append("**Sistema de Sizing com Racional de C√°lculo e An√°lise de Cen√°rios**")
    lines.append("")
    lines.append(f"**Data:** {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Se√ß√£o 1: Entradas
    lines.append("## üìã Se√ß√£o 1: Entradas")
    lines.append("")
    
    lines.append("### Modelo")
    lines.append("")
    lines.append(f"- **Nome:** {model.name}")
    lines.append(f"- **Camadas:** {model.num_layers}")
    lines.append(f"- **KV Heads:** {model.num_key_value_heads}")
    lines.append(f"- **Head Dim:** {model.head_dim}")
    lines.append(f"- **Max Position Embeddings:** {model.max_position_embeddings:,}")
    lines.append(f"- **Padr√£o de Aten√ß√£o:** {model.attention_pattern}")
    if model.attention_pattern == "hybrid":
        lines.append(f"  - Full Layers: {model.hybrid_full_layers}")
        lines.append(f"  - Sliding Layers: {model.hybrid_sliding_layers}")
        lines.append(f"  - Sliding Window: {model.sliding_window}")
    elif model.attention_pattern == "sliding":
        lines.append(f"  - Sliding Window: {model.sliding_window}")
    lines.append(f"- **Precis√£o KV Padr√£o:** {model.default_kv_precision}")
    lines.append("")
    
    lines.append("### Servidor")
    lines.append("")
    lines.append(f"- **Nome:** {server.name}")
    lines.append(f"- **GPUs:** {server.gpus}")
    lines.append(f"- **HBM por GPU:** {server.hbm_per_gpu_gb} GB")
    lines.append(f"- **HBM Total:** {server.total_hbm_gb} GB ({server.total_hbm_gb * GB_TO_GIB:.1f} GiB)")
    if server.nvlink_bandwidth_tbps:
        lines.append(f"- **NVLink Bandwidth:** {server.nvlink_bandwidth_tbps} TB/s")
    lines.append("")
    
    lines.append("### Storage")
    lines.append("")
    lines.append(f"- **Perfil:** {storage.name}")
    lines.append(f"- **Tipo:** {storage.type}")
    lines.append(f"- **IOPS:** {storage.iops_read:,} read / {storage.iops_write:,} write")
    lines.append(f"- **Throughput:** {storage.throughput_read_gbps} GB/s read / {storage.throughput_write_gbps} GB/s write")
    lines.append(f"- **Lat√™ncia P99:** {storage.latency_read_ms_p99} ms read / {storage.latency_write_ms_p99} ms write")
    lines.append("")
    
    lines.append("### NFR (Non-Functional Requirements)")
    lines.append("")
    lines.append(f"- **Concorr√™ncia Alvo:** {concurrency:,} sess√µes simult√¢neas")
    lines.append(f"- **Contexto Efetivo:** {effective_context:,} tokens")
    lines.append(f"- **Precis√£o KV:** {kv_precision}")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Se√ß√£o 2: Dicion√°rio de Par√¢metros (resumido)
    lines.append("## üìö Se√ß√£o 2: Dicion√°rio de Par√¢metros")
    lines.append("")
    lines.append("Principais par√¢metros utilizados no dimensionamento:")
    lines.append("")
    
    param_dict = get_parameter_dictionary()
    key_params = [
        "num_layers", "num_key_value_heads", "effective_context", 
        "kv_precision", "kv_budget_ratio", "ha_mode"
    ]
    
    for param_name in key_params:
        if param_name in param_dict:
            p = param_dict[param_name]
            lines.append(f"### `{param_name}`")
            lines.append("")
            lines.append(f"**O que √©:** {p['description']}")
            lines.append("")
            lines.append(f"**Import√¢ncia:** {p['importance']}")
            lines.append("")
            lines.append(f"**Erro comum:** {p['common_errors']}")
            lines.append("")
    
    lines.append("> ‚ÑπÔ∏è Veja JSON para dicion√°rio completo de todos os par√¢metros")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Se√ß√£o 3: Resultados por Cen√°rio
    lines.append("## üéØ Se√ß√£o 3: Resultados por Cen√°rio")
    lines.append("")
    
    # Tabela comparativa
    lines.append("### Compara√ß√£o R√°pida")
    lines.append("")
    lines.append("| M√©trica | M√çNIMO | RECOMENDADO | IDEAL |")
    lines.append("|---------|--------|-------------|-------|")
    
    min_sc = scenarios["minimum"]
    rec_sc = scenarios["recommended"]
    ideal_sc = scenarios["ideal"]
    
    lines.append(f"| **Headroom** | {min_sc.peak_headroom_ratio*100:.0f}% | {rec_sc.peak_headroom_ratio*100:.0f}% | {ideal_sc.peak_headroom_ratio*100:.0f}% |")
    lines.append(f"| **HA** | {min_sc.ha_mode} | {rec_sc.ha_mode} | {ideal_sc.ha_mode} |")
    lines.append(f"| **Budget KV** | {min_sc.kv_budget_ratio*100:.0f}% | {rec_sc.kv_budget_ratio*100:.0f}% | {ideal_sc.kv_budget_ratio*100:.0f}% |")
    lines.append(f"| **KV/Sess√£o** | {min_sc.kv_per_session_gib:.2f} GiB | {rec_sc.kv_per_session_gib:.2f} GiB | {ideal_sc.kv_per_session_gib:.2f} GiB |")
    lines.append(f"| **Sess√µes/N√≥** | {min_sc.sessions_per_node} | {rec_sc.sessions_per_node} | {ideal_sc.sessions_per_node} |")
    lines.append(f"| **N√≥s Finais** | **{min_sc.nodes_final}** | **{rec_sc.nodes_final}** ‚úÖ | **{ideal_sc.nodes_final}** |")
    lines.append("")
    lines.append("> ‚úÖ **RECOMENDADO** √© o cen√°rio ideal para produ√ß√£o")
    lines.append("")
    
    # Detalhamento por cen√°rio
    for scenario_key in ["minimum", "recommended", "ideal"]:
        scenario = scenarios[scenario_key]
        
        emoji = "üî¥" if scenario_key == "minimum" else ("üü¢" if scenario_key == "recommended" else "üîµ")
        lines.append(f"### {emoji} Cen√°rio: {scenario.name}")
        lines.append("")
        
        lines.append("**Configura√ß√£o:**")
        lines.append("")
        lines.append(f"- Peak Headroom: {scenario.peak_headroom_ratio * 100:.0f}%")
        lines.append(f"- HA Mode: {scenario.ha_mode}")
        lines.append(f"- KV Budget Ratio: {scenario.kv_budget_ratio * 100:.0f}%")
        lines.append("")
        
        lines.append("**Resultados:**")
        lines.append("")
        
        results_data = [
            ("KV por Sess√£o", f"{scenario.kv_per_session_gib:.2f} GiB"),
            ("KV Total", f"{scenario.kv_total_tib:.2f} TiB"),
            ("HBM Total", f"{scenario.hbm_total_gib:.1f} GiB"),
            ("KV Budget", f"{scenario.kv_budget_gib:.1f} GiB"),
            ("Sess√µes por N√≥", f"{scenario.sessions_per_node:,}"),
            ("N√≥s (Capacidade)", f"{scenario.nodes_capacity}"),
            ("N√≥s (com Headroom)", f"{scenario.nodes_with_headroom}"),
            ("**N√≥s Finais**", f"**{scenario.nodes_final}**"),
        ]
        
        for label, value in results_data:
            lines.append(f"- {label}: {value}")
        
        lines.append("")
        
        # Racional resumido para n√≥s finais
        if "nodes_final" in scenario.rationale:
            rat = scenario.rationale["nodes_final"]
            lines.append("<details>")
            lines.append(f"<summary><b>üìä Racional: N√≥s Finais</b></summary>")
            lines.append("")
            lines.append("**F√≥rmula:**")
            lines.append("")
            lines.append("```")
            lines.append(rat.formula)
            lines.append("```")
            lines.append("")
            lines.append("**Interpreta√ß√£o:**")
            lines.append("")
            lines.append(rat.explanation)
            lines.append("")
            lines.append("</details>")
            lines.append("")
        
        # Avisos do cen√°rio
        if scenario.warnings:
            lines.append("**‚ö†Ô∏è Avisos:**")
            lines.append("")
            for i, warning in enumerate(scenario.warnings, 1):
                lines.append(f"{i}. {warning}")
            lines.append("")
        
        lines.append("---")
        lines.append("")
    
    # Se√ß√£o 4: Alertas e Riscos
    lines.append("## ‚ö†Ô∏è Se√ß√£o 4: Alertas e Riscos")
    lines.append("")
    
    all_warnings = set()
    for scenario in scenarios.values():
        all_warnings.update(scenario.warnings)
    
    if all_warnings:
        for i, warning in enumerate(sorted(all_warnings), 1):
            lines.append(f"{i}. {warning}")
    else:
        lines.append("‚úÖ Nenhum alerta cr√≠tico detectado.")
    
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Footer
    lines.append("## üìù Observa√ß√µes")
    lines.append("")
    lines.append("- Este relat√≥rio foi gerado automaticamente pelo sistema de sizing v2.0")
    lines.append("- Para an√°lise completa, consulte tamb√©m o JSON output")
    lines.append("- Use o **CEN√ÅRIO RECOMENDADO** para produ√ß√£o (N+1, balanceado)")
    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("*Gerado por: Sistema de Sizing de Infraestrutura IA*")
    
    return "\n".join(lines)


def format_executive_report(
    model: Model,
    server: Server,
    storage: StorageProfile,
    scenarios: Dict[str, ScenarioResult],
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    kv_budget_ratio: float,
    runtime_overhead_gib: float,
    verbose: bool = False
) -> str:
    """
    Formata relat√≥rio executivo para diretoria e l√≠deres de tecnologia.
    Foco em consumo f√≠sico de datacenter, consumo unit√°rio e decis√£o executiva.
    """
    lines = []
    
    # Header
    lines.append("# RELAT√ìRIO EXECUTIVO")
    lines.append("## Dimensionamento de Infraestrutura de Infer√™ncia LLM")
    lines.append("")
    lines.append(f"**Data:** {__import__('datetime').datetime.now().strftime('%d/%m/%Y')}")
    lines.append(f"**Modelo Analisado:** {model.name}")
    lines.append(f"**Carga Operacional:** {concurrency:,} sess√µes simult√¢neas √ó {effective_context:,} tokens/contexto")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 1. SUM√ÅRIO EXECUTIVO
    # =======================================================================
    lines.append("## 1. Sum√°rio Executivo")
    lines.append("")
    
    rec = scenarios["recommended"]
    
    lines.append(f"Este relat√≥rio dimensiona a infraestrutura necess√°ria para operar o modelo **{model.name}** em produ√ß√£o, "
                 f"sustentando **{concurrency:,} sess√µes simult√¢neas** com contexto de **{effective_context:,} tokens**. "
                 f"O principal limitador da opera√ß√£o √© a **mem√≥ria de GPU (HBM)**, especificamente o **KV cache** que mant√©m o contexto conversacional ativo.")
    lines.append("")
    
    lines.append(f"A an√°lise identifica impacto direto em tr√™s dimens√µes cr√≠ticas:")
    lines.append(f"- **Servidores**: {rec.nodes_final} n√≥s DGX {server.name} (cen√°rio recomendado)")
    lines.append(f"- **Energia**: {rec.total_power_kw:.1f} kW de consumo cont√≠nuo")
    lines.append(f"- **Datacenter**: {rec.total_rack_u}U de espa√ßo em rack ({rec.total_rack_u/42:.1f} racks padr√£o)")
    lines.append("")
    
    lines.append(f"**Para sustentar a carga avaliada com estabilidade operacional, "
                 f"a plataforma exige m√∫ltiplos n√≥s DGX, com impacto direto em energia ({rec.total_power_kw:.1f} kW) "
                 f"e densidade de rack ({rec.total_rack_u}U).**")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 2. CEN√ÅRIOS AVALIADOS (APRESENTAR PRIMEIRO)
    # =======================================================================
    lines.append("## 2. Cen√°rios Avaliados")
    lines.append("")
    
    lines.append("### Tabela ‚Äì Vis√£o Geral dos Cen√°rios")
    lines.append("")
    lines.append("| Cen√°rio | Objetivo | Toler√¢ncia a Falhas | Risco Operacional |")
    lines.append("|---------|----------|---------------------|-------------------|")
    lines.append("| **M√≠nimo** | Atender no limite | Nenhuma | **Alto** ‚Äî Falha causa indisponibilidade imediata |")
    lines.append("| **Recomendado** | Produ√ß√£o est√°vel | Falha simples (N+1) | **M√©dio** ‚Äî Degrada√ß√£o gerenci√°vel |")
    lines.append("| **Ideal** | Alta resili√™ncia | Falhas m√∫ltiplas (N+2) | **Baixo** ‚Äî Sistema mant√©m SLA sob adversidades |")
    lines.append("")
    
    lines.append("Os tr√™s cen√°rios representam diferentes n√≠veis de **investimento** versus **risco operacional**. "
                 "O cen√°rio **M√≠nimo** minimiza capex mas exp√µe a opera√ß√£o a risco de indisponibilidade n√£o gerenci√°vel. "
                 "O cen√°rio **Recomendado** equilibra custo e resili√™ncia, adequado para produ√ß√£o com SLA 99.9%. "
                 "O cen√°rio **Ideal** maximiza disponibilidade, indicado para cargas cr√≠ticas com requisitos de SLA > 99.95%.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 3. INFORMA√á√ïES DO MODELO AVALIADO
    # =======================================================================
    lines.append("## 3. Informa√ß√µes do Modelo Avaliado")
    lines.append("")
    
    lines.append("### Tabela ‚Äì Perfil do Modelo")
    lines.append("")
    lines.append("| Item | Valor |")
    lines.append("|------|-------|")
    lines.append(f"| **Modelo** | {model.name} |")
    lines.append(f"| **N√∫mero de camadas** | {model.num_layers} |")
    lines.append(f"| **KV heads** | {model.num_key_value_heads} |")
    lines.append(f"| **Contexto m√°ximo** | {model.max_position_embeddings:,} tokens |")
    lines.append(f"| **Contexto efetivo usado** | {effective_context:,} tokens |")
    lines.append(f"| **Padr√£o de aten√ß√£o** | {model.attention_pattern.capitalize()} |")
    lines.append(f"| **Precis√£o do KV cache** | {kv_precision.upper()} ({KV_PRECISION_BYTES[kv_precision]} byte/elemento) |")
    lines.append("")
    
    lines.append(f"O modelo {model.name} consome **mem√≥ria viva** durante a opera√ß√£o para armazenar o **KV cache** ‚Äî "
                 f"tensores Key e Value que mant√™m o contexto conversacional. Este consumo √© proporcional ao **contexto efetivo** "
                 f"({effective_context:,} tokens) e √† **concorr√™ncia** ({concurrency:,} sess√µes), dominando a capacidade de infraestrutura necess√°ria. "
                 f"Diferente dos pesos do modelo (fixos), o KV cache escala linearmente com o n√∫mero de sess√µes ativas.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 4. CONSUMO UNIT√ÅRIO DO MODELO (VIS√ÉO FUNDAMENTAL)
    # =======================================================================
    lines.append("## 4. Consumo Unit√°rio do Modelo")
    lines.append("")
    
    kv_per_session = rec.kv_per_session_gib
    hbm_percent_per_session = (kv_per_session / rec.kv_budget_gib) * 100 if rec.kv_budget_gib > 0 else 0
    power_per_session_w = (server.power_kw_max * 1000) / rec.sessions_per_node if rec.sessions_per_node > 0 else 0
    
    lines.append("### Tabela ‚Äì Consumo por Sess√£o")
    lines.append("")
    lines.append("| Recurso | Consumo por Sess√£o | Significado Operacional |")
    lines.append("|---------|-------------------|------------------------|")
    lines.append(f"| **KV cache** | {kv_per_session:.2f} GiB | Mem√≥ria GPU ocupada enquanto a sess√£o est√° ativa |")
    lines.append(f"| **GPU HBM (%)** | {hbm_percent_per_session:.1f}% de um n√≥ | Fra√ß√£o da capacidade de um servidor consumida |")
    lines.append(f"| **Energia estimada** | {power_per_session_w:.0f} W | Impacto incremental por sess√£o ativa (aproximado) |")
    lines.append(f"| **Rack** | N/A | Sess√£o n√£o consome rack diretamente; n√≥ sim ({server.rack_units_u}U/n√≥) |")
    lines.append("")
    
    lines.append(f"**Cada sess√£o ativa \"reserva\" {kv_per_session:.2f} GiB de HBM ({hbm_percent_per_session:.1f}% do budget do n√≥).** "
                 f"A soma dessas reservas define o **limite f√≠sico** do servidor: com {rec.kv_budget_gib:.1f} GiB dispon√≠veis para KV, "
                 f"cada n√≥ suporta no m√°ximo **{rec.sessions_per_node} sess√µes simult√¢neas**. "
                 f"Exceder este limite causa recusa de novas conex√µes ou degrada√ß√£o de performance.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 5. CONSUMO AGREGADO DO MODELO (TODAS AS SESS√ïES)
    # =======================================================================
    lines.append("## 5. Consumo Agregado da Plataforma")
    lines.append("")
    
    lines.append("### Tabela ‚Äì Consumo Total (Cen√°rio Recomendado)")
    lines.append("")
    lines.append("| Recurso | Total Consumido |")
    lines.append("|---------|----------------|")
    lines.append(f"| **Sess√µes simult√¢neas** | {concurrency:,} |")
    lines.append(f"| **KV total** | {rec.kv_total_tib:.2f} TiB ({rec.kv_total_gib:,.1f} GiB) |")
    lines.append(f"| **N√≥s DGX** | {rec.nodes_final} |")
    lines.append(f"| **Energia total** | {rec.total_power_kw:.1f} kW ({rec.total_power_kw * 8.76:.0f} MWh/ano) |")
    lines.append(f"| **Espa√ßo em rack** | {rec.total_rack_u}U ({rec.total_rack_u/42:.1f} racks) |")
    if rec.total_heat_btu_hr:
        lines.append(f"| **Dissipa√ß√£o t√©rmica** | {rec.total_heat_btu_hr:,.0f} BTU/hr ({rec.total_heat_btu_hr/12000:.1f} tons) |")
    lines.append("")
    
    lines.append(f"O **consumo agregado** demonstra a diferen√ßa entre consumo unit√°rio e impacto total: "
                 f"enquanto uma sess√£o consome {kv_per_session:.2f} GiB, {concurrency:,} sess√µes simult√¢neas consomem "
                 f"{rec.kv_total_tib:.2f} TiB distribu√≠dos entre {rec.nodes_final} n√≥s. "
                 f"**O crescimento de usu√°rios impacta linearmente a infraestrutura**: dobrar concorr√™ncia para {concurrency*2:,} sess√µes "
                 f"dobraria energia para {rec.total_power_kw*2:.1f} kW e rack para {rec.total_rack_u*2}U.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 6. RESULTADOS POR CEN√ÅRIO (COM ENERGIA E RACK)
    # =======================================================================
    lines.append("## 6. Resultados por Cen√°rio")
    lines.append("")
    
    for scenario_key, scenario_label in [("minimum", "M√çNIMO"), ("recommended", "RECOMENDADO"), ("ideal", "IDEAL")]:
        sc = scenarios[scenario_key]
        
        lines.append(f"### Cen√°rio {scenario_label}")
        lines.append("")
        
        lines.append("| M√©trica | Valor |")
        lines.append("|---------|-------|")
        lines.append(f"| **N√≥s DGX** | {sc.nodes_final} |")
        lines.append(f"| **Sess√µes por n√≥** | {sc.sessions_per_node} |")
        lines.append(f"| **KV por sess√£o** | {sc.kv_per_session_gib:.2f} GiB |")
        lines.append(f"| **KV total** | {sc.kv_total_tib:.2f} TiB |")
        lines.append(f"| **Energia total** | **{sc.total_power_kw:.1f} kW** ({sc.total_power_kw * 8.76:.0f} MWh/ano) |")
        lines.append(f"| **Espa√ßo em rack** | **{sc.total_rack_u}U** ({sc.total_rack_u/42:.1f} racks) |")
        if sc.total_heat_btu_hr:
            lines.append(f"| **Dissipa√ß√£o t√©rmica** | {sc.total_heat_btu_hr:,.0f} BTU/hr ({sc.total_heat_btu_hr/12000:.1f} tons) |")
        lines.append(f"| **Arquitetura** | {sc.ha_mode.upper() if sc.ha_mode != 'none' else 'Sem redund√¢ncia'} |")
        lines.append(f"| **Headroom para picos** | {sc.peak_headroom_ratio*100:.0f}% |")
        lines.append("")
        
        # Par√°grafo executivo espec√≠fico por cen√°rio
        if scenario_key == "minimum":
            lines.append(f"**Significado Operacional:** Este cen√°rio dimensiona a infraestrutura no limite absoluto ({sc.nodes_final} n√≥s, {sc.total_power_kw:.1f} kW, {sc.total_rack_u}U). "
                         f"**Sem toler√¢ncia a falhas**: qualquer evento de manuten√ß√£o ou falha de hardware resulta em indisponibilidade imediata. "
                         f"**Sem headroom**: picos de tr√°fego causam throttling ou recusa de conex√µes. "
                         f"**Impacto f√≠sico m√≠nimo** mas **risco operacional alto**. Adequado apenas para PoC ou ambientes de desenvolvimento.")
        
        elif scenario_key == "recommended":
            lines.append(f"**Significado Operacional:** Dimensionado para produ√ß√£o com resili√™ncia ({sc.nodes_final} n√≥s, {sc.total_power_kw:.1f} kW, {sc.total_rack_u}U). "
                         f"**Tolera falha de 1 n√≥** sem perda de capacidade cr√≠tica. Headroom de {sc.peak_headroom_ratio*100:.0f}% absorve picos de demanda. "
                         f"**Impacto f√≠sico:** {sc.total_power_kw:.1f} kW requer PDU com capacidade adequada e UPS dimensionado; "
                         f"{sc.total_rack_u}U equivale a {sc.total_rack_u/42:.1f} racks, gerenci√°vel em datacenter padr√£o. "
                         f"**Recomendado para produ√ß√£o com SLA 99.9%**.")
        
        else:  # ideal
            lines.append(f"**Significado Operacional:** M√°xima resili√™ncia operacional ({sc.nodes_final} n√≥s, {sc.total_power_kw:.1f} kW, {sc.total_rack_u}U). "
                         f"**Tolera falhas simult√¢neas de at√© 2 n√≥s**, cen√°rio raro mas poss√≠vel em eventos de rack ou rede. "
                         f"Headroom de {sc.peak_headroom_ratio*100:.0f}% e budget conservador ({sc.kv_budget_ratio*100:.0f}% HBM) garantem estabilidade m√°xima. "
                         f"**Impacto f√≠sico significativo:** {sc.total_power_kw:.1f} kW pode exigir upgrade de PDU/UPS; "
                         f"{sc.total_rack_u}U requer planejamento de densidade de rack. "
                         f"Indicado para cargas de miss√£o cr√≠tica (financeiro, healthcare, SLA > 99.95%).")
        
        lines.append("")
        lines.append("---")
        lines.append("")
    
    # =======================================================================
    # 7. RACIONAL DE C√ÅLCULO (FORMATO OBRIGAT√ìRIO)
    # =======================================================================
    lines.append("## 7. Racional de C√°lculo")
    lines.append("")
    
    lines.append("### Tabela ‚Äì Metodologia de Dimensionamento")
    lines.append("")
    lines.append("| Resultado | F√≥rmula | Par√¢metros do C√°lculo | Suposi√ß√£o Aplicada | Significado Operacional |")
    lines.append("|-----------|---------|----------------------|-------------------|------------------------|")
    
    # KV por sess√£o
    if model.attention_pattern == "hybrid":
        formula_kv = "2 √ó [(full_layers √ó context) + (sliding_layers √ó window)] √ó kv_heads √ó head_dim √ó bytes"
    elif model.attention_pattern == "sliding":
        formula_kv = "2 √ó window √ó num_layers √ó kv_heads √ó head_dim √ó bytes"
    else:
        formula_kv = "2 √ó context √ó num_layers √ó kv_heads √ó head_dim √ó bytes"
    
    lines.append(f"| **KV por sess√£o** | {formula_kv} | "
                 f"Camadas: {model.num_layers}, Context: {effective_context:,}, KV heads: {model.num_key_value_heads}, Precis√£o: {kv_precision} | "
                 f"Padr√£o '{model.attention_pattern}' determina seq_length por camada | "
                 f"Mem√≥ria reservada por sess√£o; subdimensionar causa OOM |")
    
    # Sess√µes por n√≥
    lines.append(f"| **Sess√µes por n√≥** | floor(Budget_KV / KV_per_session) | "
                 f"Budget: {rec.kv_budget_gib:.1f} GiB, KV/sess√£o: {rec.kv_per_session_gib:.2f} GiB | "
                 f"Budget = (HBM - overhead) √ó ratio; limitado por mem√≥ria | "
                 f"Capacidade m√°xima do servidor; exceder causa recusa de conex√µes |")
    
    # N√≥s necess√°rios
    lines.append(f"| **N√≥s DGX** | ceil(concurrency √ó (1 + headroom) / sess√µes_per_n√≥) + HA | "
                 f"Concorr√™ncia: {concurrency:,}, Headroom: {rec.peak_headroom_ratio*100:.0f}%, Sess√µes/n√≥: {rec.sessions_per_node}, HA: +{rec.ha_extra_nodes} | "
                 f"Headroom para picos; HA garante continuidade em falhas | "
                 f"N√∫mero de servidores a provisionar; define capex e opex |")
    
    # Energia total
    lines.append(f"| **Energia (kW)** | nodes_final √ó power_kw_max | "
                 f"N√≥s: {rec.nodes_final}, Power/n√≥: {server.power_kw_max} kW | "
                 f"Consumo m√°ximo cont√≠nuo do sistema | "
                 f"Dimensiona PDU, UPS, contrato de energia; considerar PUE (~1.4x) |")
    
    # Rack total
    lines.append(f"| **Rack (U)** | nodes_final √ó rack_units_u | "
                 f"N√≥s: {rec.nodes_final}, U/n√≥: {server.rack_units_u}U | "
                 f"Cada servidor ocupa {server.rack_units_u}U; racks padr√£o = 42U | "
                 f"Define densidade e capacidade f√≠sica; adicionar ~20% para infra |")
    
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 8. COMPARA√á√ÉO EXECUTIVA DOS CEN√ÅRIOS
    # =======================================================================
    lines.append("## 8. Compara√ß√£o Executiva dos Cen√°rios")
    lines.append("")
    
    min_sc = scenarios["minimum"]
    ideal_sc = scenarios["ideal"]
    
    lines.append("### Tabela ‚Äì Comparativo")
    lines.append("")
    lines.append("| Crit√©rio | M√≠nimo | Recomendado | Ideal |")
    lines.append("|----------|--------|-------------|-------|")
    lines.append(f"| **N√≥s DGX** | {min_sc.nodes_final} | {rec.nodes_final} | {ideal_sc.nodes_final} |")
    lines.append(f"| **Energia (kW)** | {min_sc.total_power_kw:.1f} | {rec.total_power_kw:.1f} | {ideal_sc.total_power_kw:.1f} |")
    lines.append(f"| **Rack (U)** | {min_sc.total_rack_u} | {rec.total_rack_u} | {ideal_sc.total_rack_u} |")
    lines.append(f"| **Toler√¢ncia a falhas** | Nenhuma | 1 n√≥ (N+1) | 2 n√≥s (N+2) |")
    lines.append(f"| **Headroom** | 0% | {rec.peak_headroom_ratio*100:.0f}% | {ideal_sc.peak_headroom_ratio*100:.0f}% |")
    lines.append(f"| **Risco operacional** | Alto | M√©dio | Baixo |")
    lines.append(f"| **CapEx relativo** | Baseline | +{int((rec.nodes_final/min_sc.nodes_final - 1) * 100)}% | +{int((ideal_sc.nodes_final/min_sc.nodes_final - 1) * 100)}% |")
    lines.append(f"| **Energia relativa** | Baseline | +{int((rec.total_power_kw/min_sc.total_power_kw - 1) * 100)}% | +{int((ideal_sc.total_power_kw/min_sc.total_power_kw - 1) * 100)}% |")
    lines.append("")
    
    lines.append(f"**O cen√°rio RECOMENDADO oferece o melhor equil√≠brio custo √ó risco.** Com {rec.nodes_final} n√≥s (+{int((rec.nodes_final/min_sc.nodes_final - 1) * 100)}% vs M√≠nimo), "
                 f"garante opera√ß√£o est√°vel, tolerando falhas e picos. **O impacto f√≠sico muda significativamente entre cen√°rios:** "
                 f"M√≠nimo usa {min_sc.total_power_kw:.1f} kW, Recomendado {rec.total_power_kw:.1f} kW (+{int((rec.total_power_kw/min_sc.total_power_kw - 1) * 100)}%), "
                 f"Ideal {ideal_sc.total_power_kw:.1f} kW (+{int((ideal_sc.total_power_kw/min_sc.total_power_kw - 1) * 100)}%). "
                 f"A escolha deve considerar n√£o apenas servidores, mas capacidade el√©trica e densidade de datacenter.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 9. RECOMENDA√á√ÉO FINAL
    # =======================================================================
    lines.append("## 9. Recomenda√ß√£o Final")
    lines.append("")
    
    lines.append(f"**Recomenda-se o cen√°rio RECOMENDADO**, que equilibra capacidade, consumo energ√©tico e toler√¢ncia a falhas sem sobrecarregar o datacenter.")
    lines.append("")
    
    lines.append(f"**Justificativa:**")
    lines.append(f"- **Estabilidade:** {rec.nodes_final} n√≥s com N+1 toleram falha de 1 servidor mantendo {rec.sessions_per_node * (rec.nodes_final - 1):,} sess√µes (suficiente para carga nominal)")
    lines.append(f"- **Energia:** {rec.total_power_kw:.1f} kW requer PDU/UPS padr√£o de datacenter; PUE 1.4x = {rec.total_power_kw * 1.4:.1f} kW total facility")
    lines.append(f"- **Datacenter:** {rec.total_rack_u}U ({rec.total_rack_u/42:.1f} racks) √© gerenci√°vel e n√£o exige reconfigura√ß√£o f√≠sica")
    lines.append(f"- **Risco:** M√©dio, com degrada√ß√£o gerenci√°vel em falhas; adequado para produ√ß√£o com SLA 99.9%")
    lines.append("")
    
    lines.append(f"**Premissas sob governan√ßa:**")
    lines.append(f"- Limite de contexto: {effective_context:,} tokens (n√£o liberar contexto m√°ximo sem valida√ß√£o)")
    lines.append(f"- Monitoramento: Alertas quando concorr√™ncia ultrapassar {int(rec.sessions_per_node * rec.nodes_final * 0.8):,} sess√µes (80% capacidade)")
    lines.append(f"- Precis√£o KV: Manter {kv_precision.upper()} (mudan√ßa para FP16 dobraria energia e rack)")
    lines.append("")
    
    lines.append("---")
    lines.append("")
    
    # =======================================================================
    # 10. DICION√ÅRIO DE PAR√ÇMETROS (NO FINAL)
    # =======================================================================
    lines.append("## 10. Dicion√°rio de Par√¢metros")
    lines.append("")
    
    lines.append("### Tabela ‚Äì Dicion√°rio")
    lines.append("")
    lines.append("| Par√¢metro | Origem | Descri√ß√£o | Import√¢ncia |")
    lines.append("|-----------|--------|-----------|------------|")
    
    # Par√¢metros do modelo
    lines.append(f"| **num_layers** | Arquitetura do Modelo | N√∫mero de camadas do transformer ({model.num_layers}) | Impacta linearmente o KV cache |")
    lines.append(f"| **num_key_value_heads** | Arquitetura do Modelo | Cabe√ßas de aten√ß√£o para K/V ({model.num_key_value_heads}) | Redu√ß√£o via GQA economiza mem√≥ria |")
    lines.append(f"| **attention_pattern** | Arquitetura do Modelo | Padr√£o de aten√ß√£o: {model.attention_pattern} | Cr√≠tico para c√°lculo correto de KV |")
    
    # Par√¢metros do servidor
    lines.append(f"| **total_hbm_gb** | Hardware do Servidor | HBM total do servidor ({server.total_hbm_gb} GB) | Define capacidade bruta de mem√≥ria |")
    lines.append(f"| **power_kw_max** | Hardware do Servidor | Consumo m√°ximo ({server.power_kw_max} kW) | Define impacto el√©trico por n√≥ |")
    lines.append(f"| **rack_units_u** | Hardware do Servidor | Espa√ßo em rack ({server.rack_units_u}U) | Define densidade f√≠sica |")
    
    # Par√¢metros de NFR
    lines.append(f"| **concurrency** | NFR do Produto | Sess√µes simult√¢neas ({concurrency:,}) | Define escala e n√∫mero de n√≥s |")
    lines.append(f"| **effective_context** | NFR do Produto | Contexto efetivo ({effective_context:,} tokens) | Impacta KV por sess√£o linearmente |")
    lines.append(f"| **kv_precision** | Configura√ß√£o de Runtime | Precis√£o do KV ({kv_precision.upper()}) | FP8=1 byte, FP16=2 bytes (dobra mem√≥ria) |")
    lines.append(f"| **peak_headroom_ratio** | NFR de Resili√™ncia | Folga para picos ({rec.peak_headroom_ratio*100:.0f}%) | Garante absor√ß√£o de varia√ß√µes de carga |")
    lines.append(f"| **ha_mode** | NFR de Disponibilidade | Alta disponibilidade ({rec.ha_mode.upper()}) | N+1 tolera 1 falha; N+2 tolera 2 falhas |")
    
    lines.append("")
    lines.append("**Nota:** Par√¢metros de modelo e servidor s√£o fixos. Par√¢metros de NFR e runtime s√£o ajust√°veis conforme requisitos de neg√≥cio.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Footer
    lines.append("## Informa√ß√µes do Relat√≥rio")
    lines.append("")
    lines.append(f"- **Sistema:** Sizing de Infraestrutura IA v2.0")
    lines.append(f"- **Data de Gera√ß√£o:** {__import__('datetime').datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    lines.append(f"- **Metodologia:** Dimensionamento baseado em mem√≥ria GPU (KV cache) com impacto f√≠sico de datacenter")
    lines.append(f"- **Servidor de Refer√™ncia:** {server.name} ({server.gpus} GPUs, {server.total_hbm_gb} GB HBM, {server.power_kw_max} kW, {server.rack_units_u}U)")
    lines.append("")
    lines.append("*Este relat√≥rio foi gerado automaticamente. Decis√µes de investimento devem ser revisadas por arquitetos de infraestrutura e finance.*")
    
    return "\n".join(lines)


def scenarios_to_dict(
    model: Model,
    server: Server,
    storage: StorageProfile,
    scenarios: Dict[str, ScenarioResult],
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    kv_budget_ratio: float,
    runtime_overhead_gib: float,
    peak_headroom_ratio: float
) -> dict:
    """Converte resultados para dicion√°rio JSON."""
    
    def rationale_to_dict(r: Rationale) -> dict:
        return {
            "formula": r.formula,
            "inputs": r.inputs,
            "explanation": r.explanation
        }
    
    def scenario_to_dict(s: ScenarioResult) -> dict:
        return {
            "name": s.name,
            "configuration": {
                "peak_headroom_ratio": s.peak_headroom_ratio,
                "ha_mode": s.ha_mode,
                "ha_extra_nodes": s.ha_extra_nodes,
                "kv_budget_ratio": s.kv_budget_ratio
            },
            "results": {
                "kv_per_session_gib": round(s.kv_per_session_gib, 4),
                "kv_total_gib": round(s.kv_total_gib, 2),
                "kv_total_tib": round(s.kv_total_tib, 4),
                "hbm_total_gib": round(s.hbm_total_gib, 2),
                "kv_budget_gib": round(s.kv_budget_gib, 2),
                "sessions_per_node": s.sessions_per_node,
                "nodes_capacity": s.nodes_capacity,
                "nodes_with_headroom": s.nodes_with_headroom,
                "nodes_final": s.nodes_final
            },
            "rationale": {k: rationale_to_dict(v) for k, v in s.rationale.items()},
            "warnings": s.warnings
        }
    
    return {
        "inputs": {
            "model": {
                "name": model.name,
                "num_layers": model.num_layers,
                "num_key_value_heads": model.num_key_value_heads,
                "head_dim": model.head_dim,
                "max_position_embeddings": model.max_position_embeddings,
                "attention_pattern": model.attention_pattern,
                "hybrid_full_layers": model.hybrid_full_layers,
                "hybrid_sliding_layers": model.hybrid_sliding_layers,
                "sliding_window": model.sliding_window,
                "default_kv_precision": model.default_kv_precision
            },
            "server": {
                "name": server.name,
                "gpus": server.gpus,
                "hbm_per_gpu_gb": server.hbm_per_gpu_gb,
                "total_hbm_gb": server.total_hbm_gb,
                "total_hbm_gib": round(server.total_hbm_gb * GB_TO_GIB, 2),
                "nvlink_bandwidth_tbps": server.nvlink_bandwidth_tbps,
                "system_memory_tb": server.system_memory_tb
            },
            "storage": {
                "name": storage.name,
                "type": storage.type,
                "iops_read": storage.iops_read,
                "iops_write": storage.iops_write,
                "throughput_read_gbps": storage.throughput_read_gbps,
                "throughput_write_gbps": storage.throughput_write_gbps,
                "latency_read_ms_p99": storage.latency_read_ms_p99,
                "latency_write_ms_p99": storage.latency_write_ms_p99
            },
            "nfr": {
                "concurrency": concurrency,
                "effective_context": effective_context,
                "kv_precision": kv_precision,
                "kv_budget_ratio": kv_budget_ratio,
                "runtime_overhead_gib": runtime_overhead_gib,
                "peak_headroom_ratio": peak_headroom_ratio
            }
        },
        "parameter_dictionary": get_parameter_dictionary(),
        "scenarios": {
            "minimum": scenario_to_dict(scenarios["minimum"]),
            "recommended": scenario_to_dict(scenarios["recommended"]),
            "ideal": scenario_to_dict(scenarios["ideal"])
        },
        "alerts": list(set([w for s in scenarios.values() for w in s.warnings]))
    }


# ============================================================================
# CLI
# ============================================================================
def parse_args():
    """Parse argumentos CLI."""
    parser = argparse.ArgumentParser(
        description="Dimensionamento Avan√ßado de Infer√™ncia LLM com Racional de C√°lculo",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # Sele√ß√£o
    parser.add_argument("--model", required=True, help="Nome do modelo")
    parser.add_argument("--server", required=True, help="Nome do servidor")
    parser.add_argument("--storage", required=True, help="Perfil de storage")
    
    # NFRs
    parser.add_argument("--concurrency", type=int, required=True, help="Sess√µes simult√¢neas")
    parser.add_argument("--effective-context", type=int, required=True, help="Contexto efetivo (tokens)")
    parser.add_argument("--kv-precision", choices=["fp8", "fp16", "bf16", "int8"], default="fp8")
    parser.add_argument("--kv-budget-ratio", type=float, default=0.70)
    parser.add_argument("--runtime-overhead-gib", type=float, default=120)
    parser.add_argument("--peak-headroom-ratio", type=float, default=0.20)
    
    # Arquivos
    parser.add_argument("--models-file", default="models.json")
    parser.add_argument("--servers-file", default="servers.json")
    parser.add_argument("--storage-file", default="storage.json")
    
    # Output
    parser.add_argument("--output-json-file", help="Salvar JSON em arquivo")
    parser.add_argument("--output-markdown-file", help="Salvar relat√≥rio em Markdown (.md)")
    parser.add_argument("--executive-report", action="store_true", help="Gerar relat√≥rio executivo (para diretoria)")
    parser.add_argument("--verbose", action="store_true")
    parser.add_argument("--json-only", action="store_true")
    parser.add_argument("--markdown-only", action="store_true", help="Gerar apenas relat√≥rio Markdown (sem JSON no stdout)")
    
    return parser.parse_args()


def print_executive_summary(
    model: Model,
    server: Server,
    scenarios: Dict[str, Any],
    concurrency: int,
    effective_context: int,
    kv_precision: str
) -> None:
    """Imprime resumo executivo no terminal (sa√≠da interativa)."""
    
    print("=" * 80)
    print("RESUMO EXECUTIVO - SIZING DE INFER√äNCIA LLM")
    print("=" * 80)
    print()
    
    # Cabe√ßalho
    print(f"Modelo:              {model.name}")
    print(f"Servidor:            {server.name}")
    print(f"Contexto Efetivo:    {effective_context:,} tokens")
    print(f"Concorr√™ncia Alvo:   {concurrency:,} sess√µes simult√¢neas")
    print(f"Precis√£o KV Cache:   {kv_precision.upper()}")
    print()
    
    # Tabela resumida
    print("-" * 100)
    print(f"{'Cen√°rio':<15} {'N√≥s DGX':>10} {'Energia (kW)':>14} {'Rack (U)':>12} {'Sess√µes/N√≥':>12} {'KV/Sess√£o (GiB)':>16}")
    print("-" * 100)
    
    for scenario_key, scenario_label in [("minimum", "M√çNIMO"), ("recommended", "RECOMENDADO"), ("ideal", "IDEAL")]:
        sc = scenarios[scenario_key]
        
        print(f"{scenario_label:<15} {sc.nodes_final:>10} {sc.total_power_kw:>14.1f} {sc.total_rack_u:>12} {sc.sessions_per_node:>12} {sc.kv_per_session_gib:>16.2f}")
    
    print("-" * 100)
    print()
    
    # Status final
    rec = scenarios["recommended"]
    if rec.sessions_per_node == 0:
        print("‚ö†Ô∏è  ERRO: N√£o cabe nem 1 sess√£o por n√≥. Ajuste contexto, precis√£o ou servidor.")
    elif rec.nodes_final <= 3:
        print(f"‚úì Cen√°rio RECOMENDADO ({rec.nodes_final} n√≥s, {rec.total_power_kw:.1f} kW, {rec.total_rack_u}U) atende os requisitos com toler√¢ncia a falhas (N+1).")
    elif rec.nodes_final <= 10:
        print(f"‚úì Cen√°rio RECOMENDADO ({rec.nodes_final} n√≥s, {rec.total_power_kw:.1f} kW, {rec.total_rack_u}U) atende os requisitos. Considere otimiza√ß√µes para grandes cargas.")
    else:
        print(f"‚ö†Ô∏è  Cen√°rio RECOMENDADO requer {rec.nodes_final} n√≥s ({rec.total_power_kw:.1f} kW, {rec.total_rack_u}U). Revise NFRs ou considere modelo menor.")
    
    print()
    
    # Alertas cr√≠ticos (apenas os mais importantes)
    critical_alerts = []
    for sc in scenarios.values():
        for warning in sc.warnings:
            if "excede" in warning or "ERRO" in warning or "dobra" in warning:
                if warning not in critical_alerts:
                    critical_alerts.append(warning)
    
    if critical_alerts:
        print("ALERTAS CR√çTICOS:")
        for alert in critical_alerts[:3]:  # M√°ximo 3 alertas
            print(f"  ‚Ä¢ {alert}")
        print()
    
    print("=" * 80)


def save_reports(
    model: Model,
    server: Server,
    storage: StorageProfile,
    scenarios: Dict[str, Any],
    concurrency: int,
    effective_context: int,
    kv_precision: str,
    kv_budget_ratio: float,
    runtime_overhead_gib: float,
    peak_headroom_ratio: float,
    verbose: bool = False
) -> Tuple[str, str]:
    """
    Salva relat√≥rios completos em arquivos.
    
    Returns:
        (caminho_txt, caminho_json)
    """
    # Criar diret√≥rio relatorios/ se n√£o existir
    os.makedirs("relatorios", exist_ok=True)
    
    # Gerar timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Nomes dos arquivos
    filename_base = f"sizing_{model.name}_{server.name}_{timestamp}"
    txt_path = os.path.join("relatorios", f"{filename_base}.txt")
    json_path = os.path.join("relatorios", f"{filename_base}.json")
    
    # Gerar relat√≥rio completo em texto
    report_text = format_report(
        model=model,
        server=server,
        storage=storage,
        scenarios=scenarios,
        concurrency=concurrency,
        effective_context=effective_context,
        kv_precision=kv_precision,
        verbose=verbose
    )
    
    # Gerar JSON completo
    json_output = scenarios_to_dict(
        model=model,
        server=server,
        storage=storage,
        scenarios=scenarios,
        concurrency=concurrency,
        effective_context=effective_context,
        kv_precision=kv_precision,
        kv_budget_ratio=kv_budget_ratio,
        runtime_overhead_gib=runtime_overhead_gib,
        peak_headroom_ratio=peak_headroom_ratio
    )
    
    # Salvar arquivos
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(report_text)
    
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_output, f, indent=2, ensure_ascii=False)
    
    return txt_path, json_path


# ============================================================================
# MAIN
# ============================================================================
def main():
    """Fun√ß√£o principal."""
    args = parse_args()
    
    # Carregar dados
    try:
        models = load_models(args.models_file)
        servers = load_servers(args.servers_file)
        storage_profiles = load_storage_profiles(args.storage_file)
    except FileNotFoundError as e:
        print(f"ERRO: Arquivo n√£o encontrado: {e}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"ERRO: JSON inv√°lido: {e}", file=sys.stderr)
        sys.exit(1)
    
    # Validar sele√ß√µes
    if args.model not in models:
        print(f"ERRO: Modelo '{args.model}' n√£o encontrado.", file=sys.stderr)
        print(f"Dispon√≠veis: {', '.join(models.keys())}", file=sys.stderr)
        sys.exit(1)
    
    if args.server not in servers:
        print(f"ERRO: Servidor '{args.server}' n√£o encontrado.", file=sys.stderr)
        print(f"Dispon√≠veis: {', '.join(servers.keys())}", file=sys.stderr)
        sys.exit(1)
    
    if args.storage not in storage_profiles:
        print(f"ERRO: Storage '{args.storage}' n√£o encontrado.", file=sys.stderr)
        print(f"Dispon√≠veis: {', '.join(storage_profiles.keys())}", file=sys.stderr)
        sys.exit(1)
    
    # Calcular sizing (3 cen√°rios)
    scenarios = calculate_sizing_all_scenarios(
        model=models[args.model],
        server=servers[args.server],
        storage=storage_profiles[args.storage],
        concurrency=args.concurrency,
        effective_context=args.effective_context,
        kv_precision=args.kv_precision,
        kv_budget_ratio=args.kv_budget_ratio,
        runtime_overhead_gib=args.runtime_overhead_gib,
        peak_headroom_ratio=args.peak_headroom_ratio,
        verbose=args.verbose
    )
    
    # Salvar relat√≥rios completos automaticamente
    txt_path, json_path = save_reports(
        model=models[args.model],
        server=servers[args.server],
        storage=storage_profiles[args.storage],
        scenarios=scenarios,
        concurrency=args.concurrency,
        effective_context=args.effective_context,
        kv_precision=args.kv_precision,
        kv_budget_ratio=args.kv_budget_ratio,
        runtime_overhead_gib=args.runtime_overhead_gib,
        peak_headroom_ratio=args.peak_headroom_ratio,
        verbose=args.verbose
    )
    
    # Imprimir resumo executivo no terminal
    print_executive_summary(
        model=models[args.model],
        server=servers[args.server],
        scenarios=scenarios,
        concurrency=args.concurrency,
        effective_context=args.effective_context,
        kv_precision=args.kv_precision
    )
    
    # Mensagem final indicando onde est√£o os relat√≥rios
    print(f"üìÑ Relat√≥rios completos salvos em:")
    print(f"   ‚Ä¢ Texto:  {txt_path}")
    print(f"   ‚Ä¢ JSON:   {json_path}")
    print()
    
    # Manter compatibilidade com flags legadas (se usu√°rio explicitamente pedir arquivos espec√≠ficos)
    if args.output_markdown_file:
        markdown_report = format_report_markdown(
            model=models[args.model],
            server=servers[args.server],
            storage=storage_profiles[args.storage],
            scenarios=scenarios,
            concurrency=args.concurrency,
            effective_context=args.effective_context,
            kv_precision=args.kv_precision,
            verbose=args.verbose
        )
        with open(args.output_markdown_file, "w", encoding="utf-8") as f:
            f.write(markdown_report)
        print(f"   ‚Ä¢ Markdown: {args.output_markdown_file}")
    
    if args.executive_report:
        executive_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        executive_filename = f"relatorios/executive_{models[args.model].name}_{servers[args.server].name}_{executive_timestamp}.md"
        
        executive_report = format_executive_report(
            model=models[args.model],
            server=servers[args.server],
            storage=storage_profiles[args.storage],
            scenarios=scenarios,
            concurrency=args.concurrency,
            effective_context=args.effective_context,
            kv_precision=args.kv_precision,
            kv_budget_ratio=args.kv_budget_ratio,
            runtime_overhead_gib=args.runtime_overhead_gib,
            verbose=args.verbose
        )
        
        with open(executive_filename, "w", encoding="utf-8") as f:
            f.write(executive_report)
        
        print(f"   ‚Ä¢ Executivo: {executive_filename}")
        print()


if __name__ == "__main__":
    main()
