# Prompts da Calculadora de Sizing

Este diret√≥rio cont√©m prompts estruturados para desenvolvimento de funcionalidades adicionais da Calculadora de Sizing de Infraestrutura para Infer√™ncia.

## üìÅ Prompts Dispon√≠veis

### 1. An√°lise Comparativa de Modelos
**Arquivo**: `analise_comparativa_modelos.md`  
**Objetivo**: Gerar script Python que compara m√∫ltiplos relat√≥rios de sizing e identifica o modelo mais eficiente em diferentes dimens√µes.

### 2. Response Time SLO
**Arquivo**: `response_time_slo.md`  
**Objetivo**: Integrar valida√ß√£o de tempo de resposta (lat√™ncia) no sistema de sizing, permitindo definir e validar SLOs de performance.

**Principais funcionalidades**:
- ‚úÖ Ranking de efici√™ncia de KV cache
- ‚úÖ Comparativo de infraestrutura (n√≥s, VRAM, energia, rack)
- ‚úÖ An√°lise de custo-benef√≠cio (TCO 3 anos)
- ‚úÖ Breakdown de VRAM (modelo fixo vs KV cache vs overhead)
- ‚úÖ Compara√ß√£o de storage (volumetria, IOPS, throughput)
- ‚úÖ Recomenda√ß√µes executivas por caso de uso
- ‚úÖ Sa√≠da em Markdown e JSON

**Casos de uso**:
- Escolher qual modelo LLM adotar para produ√ß√£o
- Avaliar trade-offs entre efici√™ncia de KV e tamanho do modelo
- Estimar TCO para diferentes arquiteturas
- Justificar decis√µes de infraestrutura para lideran√ßa executiva

**Exemplo de uso**:
```bash
python analise_comparativa.py --models "DeepSeek-V3.2,opt-oss-120b" --scenario recommended
```

### 2. Response Time SLO
**Arquivo**: `response_time_slo.md`  
**Objetivo**: Integrar par√¢metro `--responsetime` (em millisegundos) para validar se a infraestrutura consegue atender SLOs de lat√™ncia.

**Principais funcionalidades**:
- ‚úÖ Novo par√¢metro `--responsetime` (tempo de resposta alvo em ms)
- ‚úÖ C√°lculo de lat√™ncia end-to-end (network + prefill + decode + queuing)
- ‚úÖ Breakdown detalhado de componentes de lat√™ncia
- ‚úÖ Valida√ß√£o autom√°tica contra SLO definido (P50 e P99)
- ‚úÖ Identifica√ß√£o de gargalos (network, compute, queuing)
- ‚úÖ Recomenda√ß√µes acion√°veis para atingir SLO
- ‚úÖ Alertas com impacto quantitativo
- ‚úÖ Nova se√ß√£o em relat√≥rios t√©cnico e executivo
- ‚úÖ Integra√ß√£o com dados de performance em `models.json`

**Casos de uso**:
- Validar se infraestrutura atende requisitos de lat√™ncia (ex: 200ms P50)
- Identificar gargalos de performance (rede, compute, fila)
- Dimensionar infraestrutura baseada em SLO de lat√™ncia
- Calcular quantos n√≥s adicionais s√£o necess√°rios para atingir SLO
- Comparar modelos por tempo de resposta esperado

**Exemplo de uso**:
```bash
# Validar se consegue atender 1000 requisi√ß√µes com 200ms de resposta
python main.py --model DeepSeek-V3.2 --server dgx-b300 \
  --storage netapp_a_series --concurrency 1000 \
  --effective-context 131072 --kv-precision fp8 \
  --responsetime 200 --responsetime-p99 500
```

**Output esperado**:
```
‚ö†Ô∏è  ALERTA: SLO de Response Time N√ÉO ATENDIDO [RECOMENDADO]

üìä M√âTRICA: Response Time P50
   ‚Ä¢ SLO definido: 200 ms
   ‚Ä¢ Esperado: 225 ms
   ‚Ä¢ D√©ficit: 25 ms (+12.5% acima do SLO)

üîç BREAKDOWN DE LAT√äNCIA:
   ‚Ä¢ Network Latency P50: 10 ms
   ‚Ä¢ Prefill Time: 80 ms
   ‚Ä¢ Decode Time: 120 ms
   ‚Ä¢ Queuing Delay P50: 15 ms
   ‚Ä¢ Utiliza√ß√£o: 62.5%

üéØ GARGALO IDENTIFICADO: DECODE_COMPUTE

üí° A√á√ÉO RECOMENDADA:
   Considerar modelo com decode mais r√°pido ou ajustar SLO para 250ms.
```

---

## üöÄ Como Usar os Prompts

1. **Leia o prompt completo**: Cada arquivo `.md` cont√©m especifica√ß√µes detalhadas
2. **Use como entrada para LLM**: Copie o conte√∫do e forne√ßa a um modelo de linguagem (GPT-4, Claude, etc.)
3. **Revise o c√≥digo gerado**: Valide a implementa√ß√£o e adapte conforme necess√°rio
4. **Teste extensivamente**: Execute os testes sugeridos no pr√≥prio prompt
5. **Integre ao projeto**: Adicione o script ao reposit√≥rio e documente no README principal

---

## üéØ Boas Pr√°ticas

### Ao Criar Novos Prompts

1. **Estrutura Clara**:
   - Objetivo (O qu√™?)
   - Contexto (Por qu√™?)
   - Requisitos funcionais (Como?)
   - Exemplos de entrada/sa√≠da
   - Casos de uso

2. **Especifica√ß√µes T√©cnicas**:
   - Linguagem e depend√™ncias
   - Arquitetura do c√≥digo (m√≥dulos, fun√ß√µes)
   - Valida√ß√µes obrigat√≥rias
   - Formato de sa√≠da (JSON schema)

3. **Testes e Valida√ß√£o**:
   - Casos de teste obrigat√≥rios
   - Casos de erro esperados
   - Exemplos de execu√ß√£o

4. **Restri√ß√µes**:
   - O que N√ÉO fazer
   - Limita√ß√µes conhecidas
   - Trade-offs de design

### Ao Implementar a Partir de Prompts

1. ‚úÖ **Valide o prompt**: Certifique-se de que est√° completo e sem ambiguidades
2. ‚úÖ **Gere incrementalmente**: N√£o tente implementar tudo de uma vez
3. ‚úÖ **Teste cada m√≥dulo**: Valide fun√ß√µes individuais antes de integrar
4. ‚úÖ **Documente diverg√™ncias**: Se precisar adaptar, documente o motivo
5. ‚úÖ **Atualize o prompt**: Se encontrar melhorias, atualize o prompt original

---

## üìã Backlog de Prompts Futuros

Ideias para pr√≥ximos prompts:

### 3. Dashboard Web Interativo
- Interface web para visualizar relat√≥rios de sizing
- Filtros din√¢micos (modelo, servidor, cen√°rio)
- Gr√°ficos comparativos (Chart.js)
- Exporta√ß√£o de relat√≥rios personalizados

### 4. Benchmark de Lat√™ncia Integrado
- Script para executar benchmarks de TTFT/TPOT
- Integra√ß√£o com vLLM, TensorRT-LLM, TGI
- Correla√ß√£o entre sizing e performance real
- Valida√ß√£o de premissas da calculadora

### 5. CI/CD para Valida√ß√£o de Modelos
- Pipeline automatizado para testar novos modelos
- Valida√ß√£o de schema do `models.json`
- Sizing autom√°tico em m√∫ltiplos servidores
- Gera√ß√£o de relat√≥rio de compatibilidade

### 6. Estimador de Custo Cloud
- Tradu√ß√£o de sizing on-premise para cloud (AWS, GCP, Azure)
- Compara√ß√£o de custos entre provedores
- Recomenda√ß√£o de inst√¢ncias (p5.48xlarge, etc.)
- TCO on-prem vs cloud

### 7. Otimizador de Configura√ß√£o
- Algoritmo para encontrar melhor combina√ß√£o (TP, PP, batch, context)
- Maximizar throughput ou minimizar lat√™ncia
- Considerar restri√ß√µes de or√ßamento
- Sugerir ajustes de `parameters.json`

### 8. Gerador de Relat√≥rios Executivos Personalizados
- Templates customiz√°veis por organiza√ß√£o
- Branded reports (logo, cores)
- Se√ß√µes opcionais (incluir/excluir m√©tricas)
- Exporta√ß√£o em PDF

### 9. API REST para Sizing
- Endpoint HTTP para sizing via API
- Autentica√ß√£o e rate limiting
- Cache de resultados
- Documenta√ß√£o OpenAPI/Swagger

---

## ü§ù Contribuindo com Novos Prompts

Se voc√™ criar um novo prompt, siga este template:

```markdown
# PROMPT: <Nome Descritivo>

## OBJETIVO
[O que o script/feature deve fazer]

## CONTEXTO
[Por que isso √© necess√°rio]

## REQUISITOS FUNCIONAIS
[Especifica√ß√µes detalhadas]

## REQUISITOS T√âCNICOS
[Linguagem, depend√™ncias, arquitetura]

## ESTRUTURA DO C√ìDIGO
[M√≥dulos, fun√ß√µes principais]

## VALIDA√á√ïES OBRIGAT√ìRIAS
[Testes e casos de erro]

## CASOS DE USO
[Exemplos de uso]

## RESULTADO ESPERADO
[Output esperado]

## RESTRI√á√ïES
[O que N√ÉO fazer]
```

Depois, adicione uma entrada neste README e envie um PR.

---

## üìö Recursos Adicionais

- **README Principal**: `/README.md`
- **Documenta√ß√£o de Schemas**: `/README_SCHEMAS.md`
- **Arquitetura do Sistema**: `/ARCHITECTURE.md`
- **Guia de In√≠cio R√°pido**: `/QUICKSTART.md`
- **Schema de Servidores**: `/servers.schema.md`

---

**√öltima atualiza√ß√£o**: 2026-02-13
