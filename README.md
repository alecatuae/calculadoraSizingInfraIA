# Calculadora de Sizing de Infraestrutura para Infer√™ncia

Sistema profissional de dimensionamento de infraestrutura para infer√™ncia de Large Language Models (LLMs) em GPUs NVIDIA DGX-class, com foco em capacity planning, resili√™ncia operacional e otimiza√ß√£o de custo.

---

## Vis√£o Geral

### O Problema

Dimensionar infraestrutura para infer√™ncia de LLMs √© fundamentalmente diferente de treinar modelos. Durante a infer√™ncia, o principal gargalo n√£o √© compute (FLOPs), mas **mem√≥ria de GPU (HBM)**, especialmente para armazenar o **KV cache** ‚Äî estruturas de dados que mant√™m o contexto conversacional.

Um erro comum √© dimensionar baseado apenas no tamanho do modelo (par√¢metros). Na pr√°tica, para modelos modernos com contextos longos (32k‚Äì200k tokens), a mem√≥ria necess√°ria para KV cache pode **exceder em 5‚Äì10x a mem√≥ria dos pesos do modelo**.

### Para Quem Este Projeto Foi Feito

- **Arquitetos de Infraestrutura**: Planejamento de capacidade e CapEx
- **Engenheiros SRE/Platform**: Defini√ß√£o de SLOs, HA e headroom
- **L√≠deres de FinOps**: An√°lise de custo por sess√£o e TCO
- **CTOs/Diretoria**: Decis√µes de investimento baseadas em cen√°rios de risco

### O Que o Projeto Resolve

Este projeto calcula quantos **n√≥s DGX** s√£o necess√°rios para sustentar uma carga de infer√™ncia, considerando:

- Concorr√™ncia alvo (sess√µes simult√¢neas)
- Tamanho do contexto efetivo
- Precis√£o do KV cache (fp8, fp16, bf16, int8)
- Toler√¢ncia a falhas (HA: none, N+1, N+2)
- Headroom para picos de tr√°fego
- **‚ú® NOVO (v3.0):** Dimensionamento completo de **storage** (volumetria, IOPS, throughput)

E avalia **3 cen√°rios** automaticamente:
1. **M√çNIMO**: Atende no limite, sem folga (risco alto)
2. **RECOMENDADO**: Produ√ß√£o com HA e headroom (risco m√©dio)
3. **IDEAL**: M√°xima resili√™ncia e estabilidade (risco baixo)

**Storage** √© dimensionado por cen√°rio, considerando:
- Pesos do modelo (checkpoints, shards, versionamento)
- Cache de runtime (engine compilado, artefatos)
- Logs, m√©tricas e auditoria (reten√ß√£o vari√°vel)
- Dados operacionais (configura√ß√µes, metadados)

---

## Conceitos-Chave

### O Que √© KV Cache?

Durante a gera√ß√£o de texto, transformers mant√™m tensores **Key** e **Value** para cada token processado, em cada camada de aten√ß√£o. Esses tensores formam o **KV cache**, permitindo que o modelo "lembre" o contexto sem recomputar tudo a cada token.

**Caracter√≠sticas operacionais:**
- Cresce linearmente com o tamanho do contexto (tokens)
- Cresce linearmente com o n√∫mero de camadas do modelo
- Persiste em HBM durante toda a sess√£o
- **N√£o** pode ser offloaded para CPU sem degradar lat√™ncia drasticamente

### Por Que Contexto e Concorr√™ncia Dominam o Custo

**Exemplo pr√°tico:**
- Modelo: opt-oss-120b (36 camadas, 8 KV heads, fp8)
- Contexto: 128k tokens
- **KV por sess√£o**: ~2.25 GiB

Para **1000 sess√µes simult√¢neas**:
- KV total: 2.25 TiB
- Servidor DGX B300: 2.3 TiB HBM total
- **Budget efetivo**: ~70% HBM ‚Üí ~1.4 TiB us√°vel para KV por n√≥
- **Resultado**: 2 n√≥s (m√≠nimo), 3 n√≥s (com N+1)

Se o contexto dobrar para 256k tokens:
- KV por sess√£o dobra (~4.5 GiB)
- N√≥s necess√°rios **dobram**

### Diferen√ßa Entre Pesos do Modelo e Mem√≥ria Viva (KV)

| Aspecto | Pesos do Modelo | KV Cache |
|---------|----------------|----------|
| **Tamanho** | Fixo (ex.: 120B param = ~240 GB fp16) | Vari√°vel (contexto √ó concorr√™ncia) |
| **Escala com** | Arquitetura do modelo | Carga de infer√™ncia |
| **Reuso** | Compartilhado entre sess√µes | 1 c√≥pia por sess√£o |
| **Impacto no sizing** | Overhead fixo (~80‚Äì150 GiB) | Principal limitador de capacidade |

**Implica√ß√£o pr√°tica:** Aumentar concorr√™ncia de 100 para 1000 sess√µes (10x) **n√£o** aumenta a mem√≥ria de pesos (permanece constante), mas aumenta KV cache em 10x.

### Por Que Storage √© Cr√≠tico (N√£o Apenas "Onde o Modelo Fica")

Embora o KV cache resida em HBM (mem√≥ria GPU), **storage** √© um recurso operacional cr√≠tico para:

#### 1. Opera√ß√£o Cont√≠nua
- **Pesos do modelo** (checkpoints/shards): Necess√°rios para startup, restart, scale-out
- **Cache de runtime** (engine compilado TensorRT-LLM/NIM): Reduz tempo de inicializa√ß√£o de ~10min para ~30s
- **Logs e m√©tricas**: Essenciais para debugging, auditoria, conformidade

#### 2. Resili√™ncia e Tempo de Recupera√ß√£o
- **Restart de n√≥s**: Storage subdimensionado aumenta tempo de recupera√ß√£o de minutos para horas
- **Scale-out**: IOPS insuficientes criam gargalo ao adicionar n√≥s simultaneamente
- **Versionamento**: Rollback r√°pido requer m√∫ltiplas vers√µes de checkpoints

#### 3. Governan√ßa e Conformidade
- **Reten√ß√£o de logs**: Auditoria e troubleshooting exigem reten√ß√£o adequada (7‚Äì90 dias)
- **M√©tricas de infer√™ncia**: SLO tracking, billing, capacity planning
- **Traces distribu√≠dos**: Diagn√≥stico de lat√™ncia e comportamento an√¥malo

**Dimensionamento por Cen√°rio:**
- **M√çNIMO**: Apenas opera√ß√£o steady-state (reten√ß√£o 7 dias, sem margem para picos)
- **RECOMENDADO**: Suporta picos e restart de 25% dos n√≥s (reten√ß√£o 30 dias)
- **IDEAL**: M√°xima resili√™ncia, falhas em cascata, reten√ß√£o estendida (90 dias)

**Exemplo Pr√°tico (opt-oss-120b, 1000 sess√µes, 3 n√≥s):**
- Storage RECOMENDADO: **~7.8 TB** (2.5 TB modelo + 3 TB cache + 1.8 TB logs + 0.5 TB ops)
- IOPS pico: **187,500 leitura** (restart de 25% dos n√≥s) / **3,000 escrita** (flush de logs)
- Throughput pico: **6.9 GB/s leitura** (modelo < 60s) / **0.7 GB/s escrita**

---

## Arquitetura da Solu√ß√£o

### main.py + /sizing/ (Arquitetura Modular)

**‚ú® NOVO (v2.0):** Projeto refatorado para arquitetura modular!

**main.py** orquestra o fluxo completo:
1. Parse CLI (sizing/cli.py)
2. Carrega configura√ß√µes (sizing/config_loader.py)
3. Calcula KV cache (sizing/calc_kv.py)
4. Calcula VRAM real (sizing/calc_vram.py)
5. Calcula storage (sizing/calc_storage.py) **‚Üê NOVO v3.0**
6. Avalia 3 cen√°rios (sizing/calc_scenarios.py)
7. Gera relat√≥rios (sizing/report_full.py, sizing/report_exec.py)
8. Salva arquivos (sizing/writer.py)

**Caracter√≠sticas t√©cnicas:**
- Python 3.8+ (stdlib only, zero depend√™ncias externas)
- M√≥dulos especializados (~200 linhas cada)
- Fun√ß√µes puras para c√°lculos core
- CLI via argparse, extens√≠vel
- F√°cil manuten√ß√£o e testes

### models.json (Par√¢metros de Modelos LLM)

Define caracter√≠sticas arquiteturais **fixas** de cada modelo:

```json
{
  "name": "opt-oss-120b",
  "num_layers": 36,
  "num_key_value_heads": 8,
  "head_dim": 64,
  "max_position_embeddings": 131072,
  "attention_pattern": "hybrid",
  "default_kv_precision": "fp8"
}
```

**Campos cr√≠ticos:**
- `num_layers`: Impacta linearmente o tamanho do KV
- `num_key_value_heads`: Define n√∫mero de heads de aten√ß√£o (GQA/MQA)
- `attention_pattern`: full (contexto completo), sliding (janela), hybrid (misto)
- `max_position_embeddings`: Limite m√°ximo de contexto do modelo

### servers.json (Hardware de Infer√™ncia)

Define especifica√ß√µes de servidores DGX:

```json
{
  "name": "dgx300",
  "gpus": 8,
  "hbm_per_gpu_gb": 288,
  "total_hbm_gb": 2304,
  "nvlink_bandwidth_tbps": 14.4
}
```

**Campos cr√≠ticos:**
- `total_hbm_gb`: Mem√≥ria total de GPU (determinante da capacidade)
- `gpus`: N√∫mero de GPUs (informativo)
- `nvlink_bandwidth_tbps`: Opcional, para an√°lise de throughput

### storage.json (Perfis de Storage)

Define caracter√≠sticas completas de storage para dimensionamento e valida√ß√µes:

```json
{
  "name": "profile_default",
  "type": "nvme_local",
  "capacity_total_tb": 61.44,
  "usable_capacity_tb": 56.0,
  "iops_read_max": 1000000,
  "iops_write_max": 800000,
  "throughput_read_gbps": 28,
  "throughput_write_gbps": 25,
  "latency_read_ms_p50": 0.08,
  "latency_read_ms_p99": 0.15,
  "latency_write_ms_p50": 0.10,
  "latency_write_ms_p99": 0.20
}
```

**‚ú® NOVO (v3.0):** Storage agora √© dimensionado ativamente:
- **Volumetria calculada**: Pesos, cache, logs, dados operacionais
- **IOPS por cen√°rio**: Steady-state vs. pico (restart, scale-out)
- **Throughput por cen√°rio**: Otimizado para tempo de recupera√ß√£o < 60s
- **Alertas autom√°ticos**: Se requisitos excedem capacidade do perfil

**Uso:** Gera alertas se contexto longo puder pressionar I/O (prefill, cold-start). **N√£o** √© usado no c√°lculo de KV cache (que reside em HBM).

### O Que √© Fixo vs Vari√°vel

| Par√¢metro | Tipo | Origem | Exemplo |
|-----------|------|--------|---------|
| `num_layers` | Fixo | Arquitetura do modelo | 36 |
| `attention_pattern` | Fixo | Arquitetura do modelo | hybrid |
| `total_hbm_gb` | Fixo | Hardware do servidor | 2304 GB |
| `concurrency` | Vari√°vel | NFR do produto | 1000 |
| `effective_context` | Vari√°vel | NFR do produto | 128k |
| `kv_precision` | Vari√°vel | Configura√ß√£o de runtime | fp8 |
| `peak_headroom_ratio` | Vari√°vel | Pol√≠tica de resili√™ncia | 20% |

---

## Arquitetura Data-Driven e Schemas

### Princ√≠pios Fundamentais

Este projeto segue uma **arquitetura data-driven**, onde todos os valores usados nos c√°lculos v√™m exclusivamente dos arquivos JSON:

- `models.json` ‚Üí par√¢metros arquiteturais de LLMs
- `servers.json` ‚Üí especifica√ß√µes de hardware de servidores GPU
- `storage.json` ‚Üí perfis de storage (IOPS, throughput, block size)

**Nenhum valor hardcoded** no c√≥digo. Isso permite:
- ‚úÖ Adicionar novos modelos/servidores/storages sem editar c√≥digo
- ‚úÖ Evolu√ß√£o cont√≠nua via incremento de JSON
- ‚úÖ Valida√ß√£o autom√°tica de schemas e constraints
- ‚úÖ Governan√ßa e auditoria

---

### Como Adicionar Novos Modelos/Servidores/Storages

#### A) Onde ficam os arquivos

Todos os arquivos JSON est√£o na raiz do projeto:
```
calculadoraSizingInfraIA/
‚îú‚îÄ‚îÄ models.json     # Modelos de LLM
‚îú‚îÄ‚îÄ servers.json    # Servidores GPU
‚îú‚îÄ‚îÄ storage.json    # Perfis de storage
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ sizing/
```

#### B) Passos para adicionar um novo item

1. **Copie um item existente** do arquivo JSON relevante
2. **Altere o `name`** (deve ser √∫nico, case-insensitive)
3. **Preencha os campos obrigat√≥rios** (veja schemas abaixo)
4. **Execute valida√ß√£o:**
   ```bash
   python3 main.py --validate-only
   ```
5. **Se v√°lido, execute um sizing de teste:**
   ```bash
   python3 main.py --model <seu-modelo> --server <seu-servidor> --storage profile_default --concurrency 100 --effective-context 32768
   ```

---

### Schema Completo: `models.json`

| Campo | Tipo | Obrigat√≥rio? | Descri√ß√£o | Unidade/Enum | Exemplo |
|-------|------|--------------|-----------|--------------|---------|
| `name` | str | ‚úÖ Sim | Nome √∫nico do modelo | - | `"opt-oss-120b"` |
| `num_layers` | int | ‚úÖ Sim | N√∫mero total de camadas do transformer | layers | `96` |
| `num_key_value_heads` | int | ‚úÖ Sim | N√∫mero de cabe√ßas KV (GQA/MQA/MHA) | heads | `8` |
| `head_dim` | int | ‚úÖ Sim | Dimens√£o de cada cabe√ßa de aten√ß√£o | dims | `128` |
| `max_position_embeddings` | int | ‚úÖ Sim | Contexto m√°ximo suportado pelo modelo | tokens | `131072` |
| `attention_pattern` | str | ‚úÖ Sim | Padr√£o de aten√ß√£o | enum: `full` \| `sliding` \| `hybrid` | `"full"` |
| `hybrid_full_layers` | int | ‚ö†Ô∏è Se `hybrid` | N√∫mero de camadas com aten√ß√£o full (hybrid) | layers | `48` |
| `hybrid_sliding_layers` | int | ‚ö†Ô∏è Se `hybrid` | N√∫mero de camadas com aten√ß√£o sliding (hybrid) | layers | `48` |
| `sliding_window` | int | ‚ö†Ô∏è Se `sliding`/`hybrid` | Tamanho da janela de aten√ß√£o sliding | tokens | `4096` |
| `default_kv_precision` | str | ‚úÖ Sim | Precis√£o padr√£o do KV cache | enum: `fp16` \| `bf16` \| `fp8` \| `int8` | `"fp8"` |
| `total_params_b` | float\|null | ‚ùå N√£o | Par√¢metros totais (bilh√µes) | B | `120.5` |
| `active_params_b` | float\|null | ‚ùå N√£o | Par√¢metros ativos (MoE) | B | `13.0` |
| `weights_memory_gib_fp16` | float\|null | ‚ùå N√£o | Mem√≥ria dos pesos em FP16 | GiB | `224.4` |
| `weights_memory_gib_bf16` | float\|null | ‚ùå N√£o | Mem√≥ria dos pesos em BF16 | GiB | `224.4` |
| `weights_memory_gib_fp8` | float\|null | ‚ùå N√£o | Mem√≥ria dos pesos em FP8 | GiB | `112.2` |
| `weights_memory_gib_int8` | float\|null | ‚ùå N√£o | Mem√≥ria dos pesos em INT8 | GiB | `112.2` |
| `weights_memory_gib_int4` | float\|null | ‚ùå N√£o | Mem√≥ria dos pesos em INT4 | GiB | `56.1` |
| `default_weights_precision` | str | ‚ùå N√£o | Precis√£o padr√£o dos pesos | enum: `fp16` \| `bf16` \| `fp8` \| `int8` \| `int4` | `"fp8"` |
| `model_artifact_size_gib` | float\|null | ‚ùå N√£o | Tamanho do artefato para warmup/storage | GiB | `230.0` |
| `notes` | str | ‚ùå N√£o | Notas e observa√ß√µes | - | `"Modelo open-source..."` |

**Constraints:**
- Todos os valores num√©ricos devem ser > 0
- Se `attention_pattern = "hybrid"`: `hybrid_full_layers + hybrid_sliding_layers` deve ser igual a `num_layers`
- Se `attention_pattern = "sliding"` ou `"hybrid"`: `sliding_window` √© obrigat√≥rio

---

### Schema Completo: `servers.json` (Estrutura Hier√°rquica)

**‚ú® NOVO (v2.0):** `servers.json` usa estrutura **hier√°rquica (nested)** para organizar componentes logicamente.

**Documenta√ß√£o completa:** [`servers.schema.md`](servers.schema.md)

#### Estrutura Nested

```json
{
  "servers": [
    {
      "name": "dgx-b300",
      "manufacturer": "NVIDIA",
      "form_factor": "Rackmount",
      "rack_units_u": 10,
      
      "cpu": { ... },
      "system_memory": { ... },
      "gpu": { ... },        // Obrigat√≥rio
      "power": { ... },      // Obrigat√≥rio
      "thermal": { ... },
      "cooling": { ... },
      "storage": { ... },
      "networking": { ... },
      "software": { ... },
      "physical": { ... },
      
      "notes": "...",
      "source": [ ... ]
    }
  ]
}
```

#### Campos Obrigat√≥rios (M√≠nimo)

| Campo | Tipo | Descri√ß√£o | Usado no C√°lculo? |
|-------|------|-----------|-------------------|
| `name` | string | Nome √∫nico do servidor | ‚úÖ Identifica√ß√£o |
| `rack_units_u` | integer | Espa√ßo em rack (U) | ‚úÖ **Rack total** |
| `gpu.count` | integer | N√∫mero de GPUs por n√≥ | ‚úÖ **HBM total e paralelismo** |
| `gpu.model` | string | Modelo da GPU | ‚úÖ Identifica√ß√£o |
| `gpu.hbm_per_gpu_gb` | float | HBM por GPU (GB) | ‚úÖ **Capacidade cr√≠tica** |
| `power.power_kw_max` | float | Consumo m√°ximo (kW) | ‚úÖ **Energia total** |

#### Campos Opcionais Importantes

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `gpu.total_hbm_gb` | float | HBM total (validado automaticamente) |
| `thermal.heat_output_btu_hr_max` | float | Dissipa√ß√£o t√©rmica (BTU/hr) |
| `source` | array[string] | Links de documenta√ß√£o oficial |

**Constraints:**
- `rack_units_u > 0`
- `gpu.count > 0`
- `gpu.hbm_per_gpu_gb > 0`
- `power.power_kw_max > 0`
- Se `gpu.total_hbm_gb` presente: valida√ß√£o autom√°tica de consist√™ncia (toler√¢ncia 1%)

#### Exemplo de Adi√ß√£o de Servidor

**Passo 1:** Edite `servers.json` e adicione:

```json
{
  "name": "dgx-h200",
  "rack_units_u": 10,
  "gpu": {
    "count": 8,
    "model": "NVIDIA H200",
    "hbm_per_gpu_gb": 141.0,
    "total_hbm_gb": 1128.0
  },
  "power": {
    "power_kw_max": 10.2
  },
  "thermal": {
    "heat_output_btu_hr_max": 34800.0
  },
  "notes": "DGX H200 com 8x H200 (141GB HBM3 cada)",
  "source": [
    "https://docs.nvidia.com/dgx/dgxh200-user-guide/"
  ]
}
```

**Passo 2:** Validar:
```bash
python3 main.py --validate-only
```

**Passo 3:** Testar:
```bash
python3 main.py --model opt-oss-120b --server dgx-h200 --storage profile_default --concurrency 1000 --effective-context 131072
```

**Checklist:**
- [ ] Nome √∫nico
- [ ] Se√ß√µes `gpu` e `power` preenchidas
- [ ] Campos obrigat√≥rios: `gpu.count`, `gpu.hbm_per_gpu_gb`, `power.power_kw_max`
- [ ] Valores > 0
- [ ] Se `gpu.total_hbm_gb`: consist√™ncia validada
- [ ] `python3 main.py --validate-only` ‚Üí ‚úÖ OK

**Documenta√ß√£o detalhada:** Consulte [`servers.schema.md`](servers.schema.md) para schema completo com todos os campos, se√ß√µes opcionais e exemplos

---

### Schema Completo: `storage.json`

| Campo | Tipo | Obrigat√≥rio? | Descri√ß√£o | Unidade/Enum | Exemplo |
|-------|------|--------------|-----------|--------------|---------|
| `name` | str | ‚úÖ Sim | Nome √∫nico do perfil de storage | - | `"profile_default"` |
| `type` | str | ‚úÖ Sim | Tipo de storage | - | `"nvme_local"` |
| `capacity_total_tb` | float | ‚úÖ Sim | Capacidade total bruta | TB | `61.44` |
| `usable_capacity_tb` | float | ‚úÖ Sim | Capacidade utiliz√°vel | TB | `56.0` |
| `iops_read_max` | int | ‚úÖ Sim | IOPS m√°ximo de leitura | IOPS | `1000000` |
| `iops_write_max` | int | ‚úÖ Sim | IOPS m√°ximo de escrita | IOPS | `800000` |
| `throughput_read_mbps` | float | ‚úÖ Sim | Throughput m√°ximo de leitura | MB/s (decimal) | `3500.0` |
| `throughput_write_mbps` | float | ‚úÖ Sim | Throughput m√°ximo de escrita | MB/s (decimal) | `3125.0` |
| `block_size_kb_read` | float | ‚úÖ Sim | Tamanho de bloco t√≠pico leitura | KB | `3.584` |
| `block_size_kb_write` | float | ‚úÖ Sim | Tamanho de bloco t√≠pico escrita | KB | `4.0` |
| `latency_read_ms_p50` | float\|null | ‚ùå N√£o | Lat√™ncia leitura (percentil 50) | ms | `0.08` |
| `latency_read_ms_p99` | float\|null | ‚ùå N√£o | Lat√™ncia leitura (percentil 99) | ms | `0.15` |
| `latency_write_ms_p50` | float\|null | ‚ùå N√£o | Lat√™ncia escrita (percentil 50) | ms | `0.10` |
| `latency_write_ms_p99` | float\|null | ‚ùå N√£o | Lat√™ncia escrita (percentil 99) | ms | `0.20` |
| `rack_units_u` | int | ‚ùå N√£o | Espa√ßo ocupado em rack | U | `2` |
| `power_kw` | float | ‚ùå N√£o | Consumo el√©trico | kW | `0.5` |
| `notes` | str | ‚ùå N√£o | Notas e observa√ß√µes | - | `"Perfil padr√£o..."` |

**Constraints:**
- Todos os valores num√©ricos devem ser > 0
- `usable_capacity_tb` ‚â§ `capacity_total_tb`
- **CR√çTICO:** `Throughput(MB/s) = (IOPS √ó BlockSize(KB)) / 1024`
  - Se diverg√™ncia > 25%: **ERRO (bloqueia relat√≥rio)**
  - Se diverg√™ncia 10-25%: **WARNING**
  - Se diverg√™ncia < 10%: **OK**

---

### Valida√ß√£o Autom√°tica de Storage (F√≠sica)

O script valida automaticamente a **consist√™ncia f√≠sica** entre IOPS, Throughput e Block Size usando a f√≥rmula:

```
Throughput(MB/s) = (IOPS √ó BlockSize(KB)) / 1024
```

**Exemplo de valida√ß√£o OK:**
```json
{
  "iops_read_max": 1000000,
  "block_size_kb_read": 3.584,
  "throughput_read_mbps": 3500.0
}
```
C√°lculo: `(1000000 √ó 3.584) / 1024 = 3500.0` ‚úÖ

**Exemplo de erro (diverg√™ncia > 25%):**
```json
{
  "iops_read_max": 100000,
  "block_size_kb_read": 4.0,
  "throughput_read_mbps": 5000.0  ‚ùå ERRADO (deveria ser ~390 MB/s)
}
```

---

### Exemplo Completo: Adicionar Novo Modelo

**Passo 1:** Edite `models.json` e adicione:

```json
{
  "name": "llama-4-70b",
  "num_layers": 80,
  "num_key_value_heads": 8,
  "head_dim": 128,
  "max_position_embeddings": 131072,
  "attention_pattern": "full",
  "default_kv_precision": "fp8",
  "total_params_b": 70.0,
  "weights_memory_gib_fp16": 130.2,
  "weights_memory_gib_fp8": 65.1,
  "default_weights_precision": "fp8",
  "model_artifact_size_gib": 140.0,
  "notes": "LLaMA 4 70B com suporte a 128K context"
}
```

**Passo 2:** Validar:
```bash
python3 main.py --validate-only
```

**Passo 3:** Testar sizing:
```bash
python3 main.py \
  --model llama-4-70b \
  --server dgx-b300 \
  --storage profile_default \
  --concurrency 500 \
  --effective-context 65536 \
  --kv-precision fp8
```

---

### Exemplo Completo: Adicionar Novo Servidor

**Passo 1:** Edite `servers.json` e adicione:

```json
{
  "name": "dgx-h200",
  "gpus": 8,
  "hbm_per_gpu_gb": 141.0,
  "rack_units_u": 10,
  "power_kw_max": 10.2,
  "heat_output_btu_hr_max": 34800.0,
  "notes": "NVIDIA DGX H200 com 8x H200 (141GB HBM3 cada)"
}
```

**Passo 2:** Validar:
```bash
python3 main.py --validate-only
```

**Passo 3:** Testar sizing:
```bash
python3 main.py \
  --model opt-oss-120b \
  --server dgx-h200 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 131072
```

---

### Exemplo Completo: Adicionar Novo Storage

**Passo 1:** Edite `storage.json` e adicione:

```json
{
  "name": "profile_enterprise_ssd",
  "type": "enterprise_ssd_array",
  "capacity_total_tb": 200.0,
  "usable_capacity_tb": 180.0,
  "iops_read_max": 750000,
  "iops_write_max": 600000,
  "throughput_read_mbps": 2400.0,
  "throughput_write_mbps": 2000.0,
  "block_size_kb_read": 3.2,
  "block_size_kb_write": 3.413,
  "latency_read_ms_p50": 0.12,
  "latency_read_ms_p99": 0.25,
  "latency_write_ms_p50": 0.15,
  "latency_write_ms_p99": 0.30,
  "rack_units_u": 4,
  "power_kw": 1.5,
  "notes": "Array SSD enterprise com 24x SSD NVMe em JBOD"
}
```

**IMPORTANTE:** Validar consist√™ncia f√≠sica:
- Read: `(750000 √ó 3.2) / 1024 = 2343.75` ‚âà `2400.0` ‚úÖ (2.4% diverg√™ncia)
- Write: `(600000 √ó 3.413) / 1024 = 2000.0` ‚úÖ (0% diverg√™ncia)

**Passo 2:** Validar:
```bash
python3 main.py --validate-only
```

---

### Checklist R√°pido

Antes de commitar novos itens:

- [ ] Nome √© √∫nico (case-insensitive)
- [ ] Todos os campos obrigat√≥rios preenchidos
- [ ] Unidades est√£o corretas (GiB vs GB, MB/s, etc.)
- [ ] Enums est√£o com valores v√°lidos
- [ ] Para `hybrid`: `hybrid_full_layers + hybrid_sliding_layers = num_layers`
- [ ] Para `storage`: IOPS/Throughput/BlockSize s√£o fisicamente consistentes (< 10% diverg√™ncia)
- [ ] Rodar `python3 main.py --validate-only` ‚Üí ‚úÖ OK
- [ ] Rodar um sizing simples de teste ‚Üí relat√≥rios gerados

---

### Comando de Valida√ß√£o

Para validar todos os arquivos JSON sem executar sizing:

```bash
python3 main.py --validate-only
```

**O que √© validado:**
- ‚úÖ Schema de todos os modelos, servidores e storages
- ‚úÖ Campos obrigat√≥rios presentes
- ‚úÖ Tipos corretos
- ‚úÖ Valores em enums v√°lidos
- ‚úÖ Constraints (ex.: soma de layers, valores > 0)
- ‚úÖ Nomes √∫nicos
- ‚úÖ Consist√™ncia f√≠sica de storage (IOPS/Throughput/BlockSize)

**Sa√≠da esperada (se tudo OK):**
```
====================================================================================================
VALIDA√á√ÉO DE STORAGE (Consist√™ncia F√≠sica IOPS/Throughput/BlockSize)
====================================================================================================
[... tabelas de valida√ß√£o ...]

====================================================================================================
VALIDA√á√ÉO DE SCHEMAS E CONSTRAINTS
====================================================================================================

‚úÖ Todos os arquivos de configura√ß√£o s√£o v√°lidos.
====================================================================================================
```

---

## Metodologia de C√°lculo

### Vis√£o Geral do Processo

1. **KV por Sess√£o (GiB)**
   - Calcula mem√≥ria necess√°ria para armazenar Key e Value de uma √∫nica sess√£o
   - Depende de: contexto efetivo, arquitetura do modelo, precis√£o (fp8/fp16)

2. **KV Total (TiB)**
   - Multiplica KV por sess√£o pela concorr√™ncia alvo
   - Representa demanda agregada do cluster

3. **Budget de HBM por N√≥ (GiB)**
   - Subtrai overhead fixo (modelo, ativa√ß√µes) da HBM total
   - Aplica fator de budget (ex.: 70%) para evitar fragmenta√ß√£o
   - Define quanto de HBM est√° dispon√≠vel para KV cache

4. **Sess√µes por N√≥**
   - Divide budget de KV pela mem√≥ria de KV por sess√£o
   - Determina capacidade efetiva de cada n√≥

5. **N√≥s Necess√°rios**
   - Calcula n√≥s para atender concorr√™ncia
   - Aplica headroom para picos
   - Adiciona n√≥s extras para HA (N+1, N+2)

### Aten√ß√£o Pattern e Seu Impacto

**Full Attention:**
- Todas as camadas atendem ao contexto completo
- KV cresce linearmente com `effective_context`
- Exemplo: GPT-3, LLaMA (camadas iniciais)

**Sliding Window Attention:**
- Camadas atendem apenas a uma janela fixa (ex.: 128 tokens)
- KV **n√£o** cresce com contexto al√©m da janela
- Reduz drasticamente mem√≥ria para contextos longos
- Exemplo: Mistral, algumas camadas de modelos h√≠bridos

**Hybrid Attention:**
- Mistura de full e sliding por camada
- Exemplo: 18 camadas full + 18 sliding
- Balanceia qualidade e efici√™ncia de mem√≥ria

### Budget de HBM e Overhead

**Overhead t√≠pico (por n√≥):**
- Pesos do modelo: 80‚Äì150 GiB (dependendo do modelo e quantiza√ß√£o)
- Ativa√ß√µes de computa√ß√£o: 10‚Äì30 GiB
- Buffers de runtime: 10‚Äì20 GiB
- **Total conservador**: 120 GiB

**Budget ratio t√≠pico:**
- 70%: Padr√£o balanceado
- 65%: Conservador (cen√°rio IDEAL), reduz risco de fragmenta√ß√£o
- 75%: Agressivo, pode causar instabilidade em runtime

**C√°lculo:**
```
HBM_total = 2304 GB √ó (10^9 / 2^30) = 2145.8 GiB
HBM_disponivel = 2145.8 - 120 = 2025.8 GiB
KV_budget = 2025.8 √ó 0.70 = 1418.0 GiB
```

### Racional Operacional

**Por que n√£o usar 100% da HBM?**
- Fragmenta√ß√£o de mem√≥ria ao longo do tempo
- Varia√ß√£o no tamanho real de contexto por sess√£o
- Buffers para opera√ß√µes tempor√°rias (ex.: beam search)

**Por que headroom para picos?**
- Tr√°fego raramente √© constante
- Eventos (lan√ßamentos, promo√ß√µes) causam spikes
- Manuten√ß√µes planejadas reduzem capacidade temporariamente

**Por que N+1 ou N+2?**
- Hardware falha (GPUs, NVLink, alimenta√ß√£o)
- Manuten√ß√£o preventiva exige rota√ß√£o de n√≥s
- N+1: Tolera 1 falha sem degrada√ß√£o
- N+2: Tolera 2 falhas ou 1 falha durante manuten√ß√£o

---

## Cen√°rios Avaliados

O script **sempre** calcula 3 cen√°rios automaticamente. Isso permite avaliar trade-offs entre custo, risco e resili√™ncia.

### 1. M√çNIMO (Bare Minimum)

**Objetivo:** Atender requisitos no limite absoluto

**Configura√ß√£o:**
- `peak_headroom_ratio = 0%` (sem folga para picos)
- `ha_mode = none` (sem redund√¢ncia)
- `kv_budget_ratio = configurado` (default 70%)

**Caracter√≠stica operacional:**
- M√°xima efici√™ncia de capital (menor n√∫mero de n√≥s)
- **Risco alto**: Falha de hardware causa indisponibilidade imediata
- Picos de tr√°fego causam throttling ou recusa de conex√µes
- Manuten√ß√£o planejada exige downtime

**Uso t√≠pico:**
- PoC, alpha, ambientes de desenvolvimento
- Estimativa de custo m√≠nimo absoluto
- Workloads com tr√°fego est√°vel e previs√≠vel

### 2. RECOMENDADO (Production Ready)

**Objetivo:** Opera√ß√£o est√°vel em produ√ß√£o com resili√™ncia

**Configura√ß√£o:**
- `peak_headroom_ratio = 20%` (configur√°vel)
- `ha_mode = n+1` (tolera 1 falha)
- `kv_budget_ratio = configurado` (default 70%)

**Caracter√≠stica operacional:**
- Equil√≠brio entre custo e resili√™ncia
- **Risco m√©dio**: Sistema tolera 1 falha de n√≥ sem perda de capacidade cr√≠tica
- Absorve picos de at√© 20% acima da carga nominal
- Permite manuten√ß√£o rotativa (rolling updates)

**Uso t√≠pico:**
- **Produ√ß√£o padr√£o** (SLA 99.9%)
- APIs comerciais, SaaS, enterprise
- Workloads com variabilidade moderada

### 3. IDEAL (Enterprise Grade)

**Objetivo:** M√°xima disponibilidade e performance

**Configura√ß√£o:**
- `peak_headroom_ratio = max(configurado, 30%)` (m√≠nimo 30%)
- `ha_mode = n+2` (tolera 2 falhas)
- `kv_budget_ratio = min(configurado, 65%)` (mais conservador)

**Caracter√≠stica operacional:**
- M√°xima resili√™ncia operacional
- **Risco baixo**: Sistema tolera 2 falhas simult√¢neas de n√≥s
- Budget conservador (65%) reduz risco de fragmenta√ß√£o
- Headroom m√≠nimo de 30% para picos e imprevistos

**Uso t√≠pico:**
- Produ√ß√£o cr√≠tica (SLA 99.99%+)
- Financeiro, healthcare, governo
- Workloads com alta imprevisibilidade
- Ambientes com hist√≥rico de falhas m√∫ltiplas

### Compara√ß√£o R√°pida

| Crit√©rio | M√≠nimo | Recomendado | Ideal |
|----------|--------|-------------|-------|
| **CapEx** | Baseline | +30‚Äì50% | +80‚Äì150% |
| **Toler√¢ncia a falhas** | 0 n√≥s | 1 n√≥ | 2 n√≥s |
| **Headroom** | 0% | 20% | 30%+ |
| **Risco de indisponibilidade** | Alto | M√©dio | Baixo |
| **SLA t√≠pico** | < 99% | 99.9% | 99.99%+ |

---

## Sa√≠das do Script

### 1. Resumo Executivo no Terminal (stdout)

Sa√≠da resumida para valida√ß√£o r√°pida e decis√£o inicial:

**Formato da Tabela:**

```
================================================================================
RESUMO EXECUTIVO - SIZING DE INFRAESTRUTURA PARA INFER√äNCIA
================================================================================

Modelo:              opt-oss-120b
Servidor:            dgx-b300
Contexto Efetivo:    131,072 tokens
Concorr√™ncia Alvo:   1,000 sess√µes simult√¢neas
Precis√£o KV Cache:   FP8

--------------------------------------------------------------------------------
Cen√°rio          N√≥s     kW      Rack    Storage (TB)   Sess√µes/N√≥  KV/Sess√£o (GiB)
------------------------------------------------------------------------------------------------------------------------
M√çNIMO             2    29.0      20          4.2              629             2.25
RECOMENDADO        3    43.5      30          7.8              629             2.25
IDEAL              5    72.5      50         15.6              584             2.25
------------------------------------------------------------------------------------------------------------------------

‚úì Cen√°rio RECOMENDADO (3 n√≥s, 43.5 kW, 30U, 7.8 TB storage) atende os requisitos com 
  toler√¢ncia a falhas (N+1).

================================================================================
üìÑ Relat√≥rios completos salvos em:
   ‚Ä¢ Texto:  relatorios/sizing_<model>_<server>_<timestamp>.txt
   ‚Ä¢ JSON:   relatorios/sizing_<model>_<server>_<timestamp>.json
   ‚Ä¢ Executivo: relatorios/executive_<model>_<server>_<timestamp>.md
```

**Inclui:**
- **Energia (kW)**: Consumo el√©trico total por cen√°rio (impacto em PDU/UPS)
- **Rack (U)**: Espa√ßo f√≠sico em rack necess√°rio (densidade de datacenter)
- **Status final**: Valida√ß√£o de viabilidade operacional

### 2. Relat√≥rio Completo em Texto (relatorios/*.txt)

Artefato formal detalhado em 4 se√ß√µes:

**SE√á√ÉO 1: Entradas**
- Par√¢metros do modelo (lidos de models.json)
- Par√¢metros do servidor (lidos de servers.json, **incluindo energia e rack**)
- Par√¢metros de storage (lidos de storage.json)
- NFRs configurados (concorr√™ncia, contexto, precis√£o, etc.)

**SE√á√ÉO 2: Dicion√°rio de Par√¢metros**
- Explica√ß√£o detalhada de cada par√¢metro usado
- Origem (modelo, hardware, NFR, runtime)
- Import√¢ncia para o sizing
- Erros comuns

**SE√á√ÉO 3: Resultados por Cen√°rio**

Para cada cen√°rio (M√çNIMO, RECOMENDADO, IDEAL):
- KV per session (GiB)
- KV total (TiB)
- Budget de HBM por n√≥ (GiB)
- Sess√µes por n√≥
- N√≥s necess√°rios (capacidade, com headroom, final com HA)
- **Energia total (kW)** e consumo anual (MWh)
- **Espa√ßo em rack (U)** e equivalente em racks padr√£o (42U)
- **Dissipa√ß√£o t√©rmica (BTU/hr)** e tons de refrigera√ß√£o
- **‚ú® NOVO v3.0: Storage por cen√°rio**
  - Volumetria total (TB): modelo + cache + logs + operacional
  - IOPS (pico e steady-state): leitura e escrita
  - Throughput (pico e steady-state): leitura e escrita
  - Alertas se requisitos excedem capacidade do perfil

E para cada resultado, um **Racional** explicando:
- F√≥rmula usada
- Inputs do c√°lculo
- Interpreta√ß√£o operacional
- **Impacto f√≠sico no datacenter**

**SE√á√ÉO 4: Alertas e Riscos**
- Valida√ß√µes autom√°ticas (ex.: contexto excede max, precis√£o fp16 dobra mem√≥ria)
- Impactos operacionais
- Recomenda√ß√µes
- Alertas sobre capacidade el√©trica e densidade de rack

### 3. JSON Estruturado (relatorios/*.json)

```json
{
  "inputs": {
    "model": {...},
    "server": {...},
    "storage": {...},
    "nfr": {
      "concurrency": 1000,
      "effective_context": 131072,
      "kv_precision": "fp8",
      ...
    }
  },
  "parameter_dictionary": {
    "num_layers": {
      "description": "...",
      "source": "...",
      "importance": "...",
      "common_errors": "..."
    },
    ...
  },
  "scenarios": {
    "minimum": {
      "name": "M√çNIMO",
      "configuration": {...},
      "results": {
        "kv_per_session_gib": 2.25,
        "kv_total_tib": 2.2,
        "nodes_final": 2,
        ...
      },
      "rationale": {
        "kv_per_session_gib": {
          "formula": "...",
          "inputs": {...},
          "explanation": "..."
        },
        ...
      },
      "warnings": [...]
    },
    "recommended": {...},
    "ideal": {...}
  },
  "alerts": [...]
}
```

**Uso do JSON:**
- Integra√ß√£o com pipelines de IaC (Terraform, Ansible)
- Dashboards de capacity planning
- An√°lise program√°tica de cen√°rios
- Export para planilhas (FinOps)

### 4. Relat√≥rio Executivo (relatorios/executive_*.md)

Com flag `--executive-report`, gera relat√≥rio especializado para diretoria em Markdown:

**Estrutura Executiva Obrigat√≥ria:**

1. **Sum√°rio Executivo**: Problema, modelo, carga, impacto em servidores/energia/datacenter
2. **Cen√°rios Avaliados**: Tabela comparativa (M√≠nimo/Recomendado/Ideal) com objetivos e riscos
3. **Informa√ß√µes do Modelo**: Perfil t√©cnico simplificado
4. **Consumo Unit√°rio**: KV/sess√£o, % HBM por sess√£o, energia estimada por sess√£o
5. **Consumo Agregado**: Total de KV, energia (kW + MWh/ano), rack (U), t√©rmica (BTU/hr)
6. **Resultados por Cen√°rio**: Tabelas individuais com **energia**, **rack** e significado operacional
7. **Racional de C√°lculo**: Tabela com f√≥rmulas, par√¢metros, suposi√ß√µes e significado operacional (incluindo energia e rack)
8. **Compara√ß√£o Executiva**: Tabela comparativa incluindo CapEx relativo, energia relativa
9. **Recomenda√ß√£o Final**: Decis√£o clara com justificativa baseada em estabilidade, energia, datacenter e risco
10. **Dicion√°rio de Par√¢metros**: Tabela com par√¢metros f√≠sicos (power_kw_max, rack_units_u)

**Foco Executivo:**
- Linguagem estrat√©gica (n√£o acad√™mica)
- Todas as m√©tricas em tabelas
- **Impacto f√≠sico expl√≠cito**: Energia (kW, MWh/ano), Rack (U, racks), T√©rmica (BTU/hr, tons)
- Decis√£o baseada em custo impl√≠cito, densidade e resili√™ncia
- Consumo unit√°rio vs agregado claramente separado

**Uso:** 
- Apresenta√ß√µes para comit√™ de investimento, CFO, CTO
- Decis√µes de datacenter (capacidade el√©trica, densidade de rack, cooling)
- An√°lise de TCO (incluindo OpEx el√©trico)

---

## Como Interpretar os Resultados

### Campos-Chave para Capacity Planning

**`nodes_final` (por cen√°rio)**
- N√∫mero de n√≥s DGX a provisionar
- Multiplicar por custo unit√°rio do servidor para CapEx
- Comparar M√çNIMO vs RECOMENDADO vs IDEAL para an√°lise de custo-benef√≠cio

**`total_power_kw` (por cen√°rio)**
- Consumo el√©trico total cont√≠nuo
- Dimensiona PDU, UPS, contrato de energia
- Considerar PUE (~1.4x) para cooling: total_facility_kw = total_power_kw √ó PUE
- Multiplicar por 8.76 para obter MWh/ano (OpEx el√©trico)

**`total_rack_u` (por cen√°rio)**
- Espa√ßo f√≠sico em rack necess√°rio
- Dividir por 42 para obter n√∫mero de racks padr√£o
- Adicionar ~20% para switches, PDUs, ventila√ß√£o
- Define densidade de implanta√ß√£o e viabilidade f√≠sica

**`total_heat_btu_hr` (por cen√°rio, opcional)**
- Dissipa√ß√£o t√©rmica total
- Dividir por 12,000 para obter tons de refrigera√ß√£o
- Dimensiona capacidade de HVAC e COP do datacenter

**`sessions_per_node`**
- Capacidade efetiva de cada n√≥
- Se = 0, **erro cr√≠tico**: n√£o cabe nem 1 sess√£o
  - A√ß√µes: reduzir contexto, usar fp8, aumentar overhead, ou servidor maior

**`kv_per_session_gib`**
- Mem√≥ria por sess√£o ativa
- Dobra se usar fp16 em vez de fp8
- Cresce linearmente com contexto

### Alertas Cr√≠ticos

**"effective_context excede max_position_embeddings"**
- Contexto solicitado maior que limite do modelo
- Script clampar√° automaticamente, mas indica configura√ß√£o errada

**"kv_precision=fp16/bf16 usa 2x mem√≥ria"**
- Considerar fp8 ou int8 (qualidade equivalente na maioria dos casos)
- Impacto direto: dobro de n√≥s necess√°rios

**"kv_budget_ratio > 0.75"**
- Aloca√ß√£o agressiva de HBM aumenta risco de instabilidade
- Reduzir para 0.70 ou menos

**"N√£o cabe nem 1 sess√£o por n√≥"**
- **Erro fatal de dimensionamento**
- Ajustar: contexto, precis√£o, overhead, ou usar servidor maior

### Sinais de Subdimensionamento

- `sessions_per_node` muito baixo (< 50): contexto muito longo ou precis√£o ineficiente
- `nodes_final` muito alto (> 20): revisar NFRs ou considerar modelo menor
- Diferen√ßa pequena entre M√çNIMO e RECOMENDADO (< 20%): carga leve, considerar otimiza√ß√µes

---

## Limita√ß√µes Conhecidas

### O Que o Script N√ÉO Calcula

**Lat√™ncia e Throughput:**
- N√£o estima tokens/s, TTFT (Time To First Token), ou TBT (Time Between Tokens)
- N√£o considera FLOPs ou utiliza√ß√£o de compute
- **Por qu√™:** Lat√™ncia depende de implementa√ß√£o (vLLM, TRT-LLM), kernels, batching din√¢mico

**Network e I/O:**
- N√£o dimensiona bandwidth de rede entre n√≥s
- N√£o calcula IOPS necess√°rio para checkpoint/restore
- **Por qu√™:** Storage profile √© usado apenas para alertas, n√£o sizing

**Custos Operacionais:**
- N√£o calcula TCO (energia, cooling, manuten√ß√£o)
- N√£o estima custo por sess√£o ou por token
- **Por qu√™:** Custos variam por regi√£o, fornecedor, contrato

**Batching e Otimiza√ß√µes:**
- Assume sess√µes independentes (1 sess√£o = 1 KV cache)
- N√£o considera continuous batching, PagedAttention, ou t√©cnicas de compress√£o
- **Por qu√™:** Ganhos dependem de implementa√ß√£o espec√≠fica

### Premissas Assumidas

1. **KV cache permanece em HBM durante toda a sess√£o**
   - Offload para CPU n√£o √© considerado (degradaria lat√™ncia)

2. **Overhead fixo por n√≥ (default: 120 GiB)**
   - V√°lido para modelos 20B‚Äì120B quantizados
   - Ajustar `--runtime-overhead-gib` se necess√°rio

3. **Sess√µes t√™m contexto uniforme**
   - Na pr√°tica, varia por usu√°rio
   - Budget deve acomodar percentil alto (P95/P99)

4. **Budget ratio conservador (70%)**
   - Evita fragmenta√ß√£o de mem√≥ria ao longo do tempo
   - Valores >75% aumentam risco operacional

5. **Servidor opera com todas as GPUs funcionais**
   - Falhas parciais (1‚Äì2 GPUs) reduzem capacidade
   - HA (N+1/N+2) mitiga, mas n√£o elimina completamente

### Depend√™ncia de Precis√£o dos Dados de Entrada

**Impacto de erros nos JSONs:**

| Par√¢metro Errado | Impacto |
|------------------|---------|
| `num_layers` (incorreto) | KV calculado errado, sizing inv√°lido |
| `total_hbm_gb` (incorreto) | Capacidade superestimada ou subestimada |
| `max_position_embeddings` (incorreto) | Valida√ß√£o de contexto falha |
| `attention_pattern` (incorreto) | KV pode ser 2‚Äì5x maior que o real |

**Recomenda√ß√£o:** Sempre validar par√¢metros contra documenta√ß√£o oficial do modelo e especifica√ß√µes do hardware.

---

## P√∫blico-Alvo e Casos de Uso

### 1. Planejamento de Capacidade Anual

**Contexto:** Estimar crescimento de infraestrutura para os pr√≥ximos 12 meses.

**Como usar:**
- Rodar sizing para proje√ß√µes Q1, Q2, Q3, Q4 (concorr√™ncia crescente)
- Comparar `nodes_final` por trimestre
- Planejar procurement escalonado

**Exemplo:**
```bash
# Q1: 1k sess√µes ‚Üí 3 n√≥s
python3 sizing.py --concurrency 1000 ...

# Q4: 5k sess√µes ‚Üí 12 n√≥s
python3 sizing.py --concurrency 5000 ...

# Procurement: 3 n√≥s agora, +3 em Q2, +3 em Q3, +3 em Q4
```

### 2. Avalia√ß√£o de Investimento (CapEx)

**Contexto:** CFO pede justificativa para compra de n√≥s DGX.

**Como usar:**
- Gerar relat√≥rio executivo (`--executive-report`)
- Mostrar diferen√ßa entre M√çNIMO, RECOMENDADO, IDEAL
- Apresentar CapEx relativo (+30%, +80%) e risco operacional

**Exemplo:**
```bash
python3 sizing.py ... --executive-report --output-markdown-file proposal.md

# proposal.md cont√©m:
# - Sum√°rio executivo para CFO
# - Tabela comparativa de cen√°rios
# - Recomenda√ß√£o: RECOMENDADO (N+1, SLA 99.9%)
```

### 3. Compara√ß√£o de Arquiteturas

**Contexto:** Decidir entre DGX B300 vs H200 vs cloud.

**Como usar:**
- Rodar sizing para cada servidor
- Comparar `nodes_final` e `sessions_per_node`
- Calcular TCO: `nodes_final √ó custo_unit√°rio √ó 3 anos`

**Exemplo:**
```bash
# DGX B300: 3 n√≥s √ó $500k = $1.5M
python3 sizing.py --server dgx300 ...

# DGX H200: 5 n√≥s √ó $300k = $1.5M (mesma capacidade, custo similar)
python3 sizing.py --server dgx200 ...
```

### 4. Discuss√£o com Fornecedores

**Contexto:** Negociar contrato com NVIDIA, AWS, Azure.

**Como usar:**
- Apresentar c√°lculos de sizing como baseline t√©cnico
- Validar se proposta do fornecedor atende NFRs
- Usar JSON para comparar m√∫ltiplas propostas

**Exemplo:**
```bash
# Gerar JSON para cada proposta
python3 sizing.py ... --output-json-file proposta_a.json
python3 sizing.py ... --output-json-file proposta_b.json

# Comparar nodes_final, sessions_per_node, alertas
```

### 5. Resposta a Incidentes de Capacidade

**Contexto:** Sistema atingiu limite, filas de espera crescendo.

**Como usar:**
- Rodar sizing com carga atual
- Identificar se est√° em cen√°rio M√çNIMO (sem folga)
- Mostrar necessidade de escala para RECOMENDADO

**Exemplo:**
```bash
# Diagn√≥stico: operando com 2 n√≥s (M√çNIMO), picos causam degrada√ß√£o
python3 sizing.py --concurrency 1000 ...

# Output mostra:
# M√çNIMO: 2 n√≥s (voc√™ est√° aqui) ‚Üí Risco: Alto
# RECOMENDADO: 3 n√≥s ‚Üí Adicionar 1 n√≥ resolve picos
```

---

## Instala√ß√£o e Requisitos

### Pr√©-requisitos

- Python 3.8 ou superior
- Nenhuma depend√™ncia externa (usa apenas stdlib)

### Instala√ß√£o

Nenhuma instala√ß√£o necess√°ria. Basta clonar o reposit√≥rio:

```bash
git clone <repo>
cd calculadoraSizingInfraIA
```

### Estrutura de Arquivos

```
calculadoraSizingInfraIA/
‚îú‚îÄ‚îÄ README.md          # Este arquivo (documenta√ß√£o completa)
‚îú‚îÄ‚îÄ QUICKSTART.md      # Guia de uso r√°pido
‚îú‚îÄ‚îÄ sizing.py          # Script principal
‚îú‚îÄ‚îÄ models.json        # Par√¢metros de modelos LLM
‚îú‚îÄ‚îÄ servers.json       # Especifica√ß√µes de servidores DGX
‚îî‚îÄ‚îÄ storage.json       # Perfis de storage (para alertas)
```

---

## Contribuindo e Extens√µes

### Adicionar Novo Modelo

Editar `models.json`:

```json
{
  "name": "seu-modelo-200b",
  "num_layers": 48,
  "num_key_value_heads": 16,
  "head_dim": 128,
  "max_position_embeddings": 200000,
  "attention_pattern": "full",
  "default_kv_precision": "fp8",
  "notes": "Seu modelo customizado"
}
```

### Adicionar Novo Servidor

Editar `servers.json`:

```json
{
  "name": "seu-servidor",
  "gpus": 8,
  "hbm_per_gpu_gb": 320,
  "total_hbm_gb": 2560,
  "notes": "Especifica√ß√µes do seu servidor"
}
```

### Validar JSONs

```bash
python3 -m json.tool models.json
python3 -m json.tool servers.json
python3 -m json.tool storage.json
```

---

## Licen√ßa e Autoria

Este projeto foi desenvolvido como ferramenta interna de sizing de infraestrutura para infer√™ncia de LLMs, com foco em capacity planning, resili√™ncia operacional e otimiza√ß√£o de custo.

**Vers√£o:** 2.0  
**Data:** 2026-02-08  
**Linguagem:** Python 3.8+ (stdlib only)
