# Calculadora de Sizing de InferÃªncia LLM em GPU NVIDIA

Sistema de dimensionamento de infraestrutura para inferÃªncia de Large Language Models (LLMs) em GPUs NVIDIA DGX-class.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto calcula o dimensionamento baseado em **memÃ³ria (KV cache)** para inferÃªncia de LLMs, considerando:

- KV cache por sessÃ£o e total
- Budget de HBM por nÃ³
- NÃºmero de sessÃµes simultÃ¢neas por nÃ³
- NÃºmero de nÃ³s necessÃ¡rios (com headroom e HA)
- Perfis de storage para cold-start e checkpoints

## ğŸ—‚ï¸ Estrutura do Projeto

```
calculadoraSizingInfraIA/
â”œâ”€â”€ sizing.py          # Script principal de dimensionamento
â”œâ”€â”€ models.json        # Tabela de modelos LLM e parÃ¢metros
â”œâ”€â”€ servers.json       # Tabela de servidores GPU (DGX)
â”œâ”€â”€ storage.json       # Perfis de storage e mÃ©tricas I/O
â””â”€â”€ README.md          # Este arquivo
```

## ğŸ“¦ Requisitos

- Python 3.8+
- Somente bibliotecas padrÃ£o (stdlib)

## ğŸš€ Uso

### Sintaxe BÃ¡sica

```bash
python3 sizing.py \
  --model <nome_modelo> \
  --server <nome_servidor> \
  --storage <perfil_storage> \
  --concurrency <num_sessoes> \
  --effective-context <tamanho_contexto> \
  [opÃ§Ãµes adicionais]
```

### ParÃ¢metros ObrigatÃ³rios

| ParÃ¢metro | DescriÃ§Ã£o |
|-----------|-----------|
| `--model` | Nome do modelo (ex: `opt-oss-120b`, `opt-oss-20b`) |
| `--server` | Nome do servidor (ex: `dgx300`, `dgx200`) |
| `--storage` | Perfil de storage (ex: `profile_default`) |
| `--concurrency` | NÃºmero de sessÃµes simultÃ¢neas alvo |
| `--effective-context` | Tamanho do contexto efetivo em tokens |

### ParÃ¢metros Opcionais

| ParÃ¢metro | PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------|-----------|
| `--kv-precision` | `fp8` | PrecisÃ£o do KV cache: `fp8`, `fp16`, `bf16`, `int8` |
| `--kv-budget-ratio` | `0.70` | FraÃ§Ã£o da HBM alocada para KV (0.0-1.0) |
| `--runtime-overhead-gib` | `120` | Overhead de runtime em GiB (modelo + ativaÃ§Ãµes) |
| `--peak-headroom-ratio` | `0.20` | Headroom para picos de trÃ¡fego (0.20 = 20%) |
| `--ha` | `none` | Modo HA: `none` ou `n+1` |
| `--json-only` | - | Imprimir apenas JSON (sem relatÃ³rio texto) |

## ğŸ“ Exemplos

### Exemplo 1: Modelo 120B + DGX B300 + N+1 HA

```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 131072 \
  --kv-precision fp8 \
  --kv-budget-ratio 0.70 \
  --runtime-overhead-gib 120 \
  --peak-headroom-ratio 0.20 \
  --ha n+1
```

**Resultado:**
- KV por sessÃ£o: 2.25 GiB
- KV total: 2.20 TiB
- SessÃµes por nÃ³: 613
- NÃ³s finais: **3** (2 + N+1)

### Exemplo 2: Modelo 20B + DGX H200 + Sem HA

```bash
python3 sizing.py \
  --model opt-oss-20b \
  --server dgx200 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 32768 \
  --kv-precision fp8 \
  --kv-budget-ratio 0.70 \
  --runtime-overhead-gib 80 \
  --peak-headroom-ratio 0.20 \
  --ha none
```

**Resultado:**
- KV por sessÃ£o: 0.38 GiB
- KV total: 0.37 TiB
- SessÃµes por nÃ³: 1740
- NÃ³s finais: **1**

### Exemplo 3: Alta PrecisÃ£o (FP16) vs FP8

```bash
# Com FP8 (1 byte por elemento)
python3 sizing.py --model opt-oss-20b --server dgx200 \
  --storage profile_default --concurrency 500 \
  --effective-context 65536 --kv-precision fp8

# Com FP16 (2 bytes por elemento - dobra a memÃ³ria)
python3 sizing.py --model opt-oss-20b --server dgx200 \
  --storage profile_default --concurrency 500 \
  --effective-context 65536 --kv-precision fp16
```

## ğŸ§® Metodologia de CÃ¡lculo

### 1. KV Cache por SessÃ£o

A fÃ³rmula base por camada Ã©:

```
KV_size = 2 Ã— seq_length Ã— num_kv_heads Ã— head_dim Ã— bytes_per_element
```

Onde:
- `2` = key + value tensors
- `seq_length` depende do padrÃ£o de atenÃ§Ã£o
- `bytes_per_element`: fp8/int8=1, fp16/bf16=2

#### PadrÃµes de AtenÃ§Ã£o

1. **Full Attention**: Todas as camadas usam `effective_context`
2. **Sliding Window**: Todas as camadas usam `sliding_window`
3. **Hybrid**: Camadas full usam `effective_context`, camadas sliding usam `sliding_window`

### 2. SessÃµes por NÃ³

```
Budget_KV = (Total_HBM_GiB Ã— kv_budget_ratio) - runtime_overhead_gib
SessÃµes_por_nÃ³ = floor(Budget_KV / KV_per_session)
```

### 3. NÃ³s NecessÃ¡rios

```
NÃ³s_mÃ­nimos = ceil(concurrency / sessÃµes_por_nÃ³)
NÃ³s_com_headroom = ceil(concurrency Ã— (1 + peak_headroom_ratio) / sessÃµes_por_nÃ³)
NÃ³s_finais = NÃ³s_com_headroom + (1 se HA=n+1, senÃ£o 0)
```

## ğŸ“Š Arquivos de Dados

### models.json

Define modelos LLM com parÃ¢metros de arquitetura:

```json
{
  "models": [
    {
      "name": "opt-oss-120b",
      "num_layers": 36,
      "num_key_value_heads": 8,
      "head_dim": 64,
      "max_position_embeddings": 131072,
      "attention_pattern": "hybrid",
      "hybrid_full_layers": 18,
      "hybrid_sliding_layers": 18,
      "sliding_window": 128,
      "default_kv_precision": "fp8"
    }
  ]
}
```

### servers.json

Define servidores GPU com especificaÃ§Ãµes de hardware:

```json
{
  "servers": [
    {
      "name": "dgx300",
      "gpus": 8,
      "hbm_per_gpu_gb": 288,
      "total_hbm_gb": 2304,
      "nvlink_bandwidth_tbps": 14.4,
      "system_memory_tb": 2
    }
  ]
}
```

### storage.json

Define perfis de storage com mÃ©tricas de I/O:

```json
{
  "profiles": [
    {
      "name": "profile_default",
      "type": "nvme_local",
      "iops_read": 1000000,
      "iops_write": 800000,
      "throughput_read_gbps": 28,
      "throughput_write_gbps": 25,
      "latency_read_ms_p50": 0.08,
      "latency_read_ms_p99": 0.15
    }
  ]
}
```

## âš ï¸ ValidaÃ§Ãµes e Avisos

O sistema gera avisos automÃ¡ticos para:

- **Context overflow**: Se `effective_context > max_position_embeddings`, clamp e avisa
- **PrecisÃ£o alta**: Se usar fp16/bf16, avisa que memÃ³ria dobra vs fp8
- **Storage I/O**: Contextos longos (>128k) podem pressionar I/O no cold-start
- **Capacidade zero**: Se budget HBM insuficiente para uma sessÃ£o

## ğŸ“¤ SaÃ­das

### RelatÃ³rio em Texto

Imprime no stdout um relatÃ³rio detalhado com:
- ParÃ¢metros do modelo, servidor e storage
- Resultados do dimensionamento
- Avisos e alertas

### JSON

SaÃ­da estruturada em JSON para integraÃ§Ã£o com outras ferramentas:

```json
{
  "model": {...},
  "server": {...},
  "storage": {...},
  "parameters": {...},
  "results": {
    "kv_per_session_gib": 2.25,
    "kv_total_tib": 2.2,
    "sessions_per_node": 613,
    "nodes_minimum": 2,
    "nodes_with_headroom": 2,
    "nodes_final": 3
  },
  "warnings": [...]
}
```

## ğŸ”§ CustomizaÃ§Ã£o

### Adicionar Novo Modelo

Edite `models.json` e adicione entrada com todos os campos necessÃ¡rios.

### Adicionar Novo Servidor

Edite `servers.json` e adicione entrada com especificaÃ§Ãµes de HBM.

### Adicionar Perfil de Storage

Edite `storage.json` e adicione perfil com mÃ©tricas de I/O.

## ğŸ“ˆ Casos de Uso

1. **Planejamento de Capacidade**: Dimensionar cluster para trÃ¡fego alvo
2. **AnÃ¡lise de TCO**: Comparar diferentes configuraÃ§Ãµes de hardware
3. **Sizing de PoC**: Validar requisitos antes de procurement
4. **OtimizaÃ§Ã£o**: Avaliar impacto de fp8 vs fp16, contexto, etc.

## ğŸ¯ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

- **Foco em memÃ³ria**: CÃ¡lculo baseado em KV cache (nÃ£o considera latÃªncia, throughput)
- **Storage passivo**: Perfis de storage sÃ£o informativos, nÃ£o dimensionam storage automaticamente
- **Modelo simplificado**: NÃ£o considera fragmentaÃ§Ã£o de memÃ³ria, variaÃ§Ãµes de batching, etc.
- **HBM como limite**: Assume que HBM Ã© o bottleneck (geralmente verdadeiro para inferÃªncia de LLMs)

## ğŸ“„ LicenÃ§a

Este projeto foi criado para uso interno de engenharia de infraestrutura.

## ğŸ‘¤ Autor

Sistema de Sizing de Infraestrutura IA
Data: 2026-02-07
