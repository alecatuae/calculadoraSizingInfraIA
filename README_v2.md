# ğŸ“Š Calculadora de Sizing de InferÃªncia LLM - VersÃ£o 2.0

## Sistema AvanÃ§ado de Dimensionamento com Racional de CÃ¡lculo

Sistema profissional de dimensionamento de infraestrutura para inferÃªncia de Large Language Models (LLMs) em GPUs NVIDIA DGX-class, com foco em **capacity planning** e **SRE** (SLO, p95/p99, HA e headroom).

### ğŸ†• Novidades da VersÃ£o 2.0

- âœ… **Racional de CÃ¡lculo Detalhado**: Cada resultado inclui fÃ³rmula, inputs e explicaÃ§Ã£o
- âœ… **DicionÃ¡rio de ParÃ¢metros**: ExplicaÃ§Ã£o completa de cada parÃ¢metro usado
- âœ… **3 CenÃ¡rios ObrigatÃ³rios**: MÃNIMO, RECOMENDADO e IDEAL
- âœ… **Alertas e Riscos Automatizados**: ValidaÃ§Ãµes operacionais
- âœ… **JSON Estruturado**: SaÃ­da completa com rationale para integraÃ§Ã£o

---

## ğŸ¯ Os 3 CenÃ¡rios

### 1. MÃNIMO (Bare Minimum)
- **Objetivo**: Atender requisitos no limite, sem folga
- **CaracterÃ­sticas**:
  - `peak_headroom_ratio = 0%` (sem headroom)
  - `ha_mode = none` (sem redundÃ¢ncia)
  - `kv_budget_ratio = configurado` (default 70%)
- **Uso**: Estimativa de custo mÃ­nimo, PoC, ambientes de teste

### 2. RECOMENDADO (Production Ready)
- **Objetivo**: ProduÃ§Ã£o com HA e headroom para picos
- **CaracterÃ­sticas**:
  - `peak_headroom_ratio = configurado` (default 20%)
  - `ha_mode = n+1` (tolera falha de 1 nÃ³)
  - `kv_budget_ratio = configurado` (default 70%)
- **Uso**: **Recomendado para produÃ§Ã£o**, SLA 99.9%+

### 3. IDEAL (Enterprise Grade)
- **Objetivo**: MÃ¡xima disponibilidade e performance
- **CaracterÃ­sticas**:
  - `peak_headroom_ratio = max(configurado, 30%)` (mÃ­nimo 30%)
  - `ha_mode = n+2` (tolera falha de 2 nÃ³s)
  - `kv_budget_ratio = min(configurado, 65%)` (mais conservador)
- **Uso**: ProduÃ§Ã£o crÃ­tica, SLA 99.99%+, cargas imprevisÃ­veis

---

## ğŸ“ Estrutura do Projeto

```
calculadoraSizingInfraIA/
â”œâ”€â”€ sizing.py          # Script principal v2.0 (~1200 linhas)
â”œâ”€â”€ models.json        # 2 modelos LLM (120B, 20B)
â”œâ”€â”€ servers.json       # 2 servidores DGX (B300, H200)
â”œâ”€â”€ storage.json       # 3 perfis de storage
â”œâ”€â”€ test_sizing.py     # Testes automatizados
â”œâ”€â”€ examples.sh        # Exemplos prÃ¡ticos
â””â”€â”€ docs/              # DocumentaÃ§Ã£o completa
    â”œâ”€â”€ README.md
    â”œâ”€â”€ QUICKREF.md
    â”œâ”€â”€ USE_CASES.md
    â”œâ”€â”€ FLOWCHART.md
    â””â”€â”€ PROJECT_SUMMARY.md
```

---

## ğŸš€ Quick Start

### Uso BÃ¡sico (3 CenÃ¡rios AutomÃ¡ticos)

```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 131072

# Output:
# MÃNIMO: 2 nÃ³s (sem HA, sem headroom)
# RECOMENDADO: 3 nÃ³s (N+1, 20% headroom)  â† PRODUÃ‡ÃƒO
# IDEAL: 5 nÃ³s (N+2, 30% headroom, 65% budget)
```

### ParÃ¢metros Principais

| ParÃ¢metro | DescriÃ§Ã£o | Default | Exemplo |
|-----------|-----------|---------|---------|
| `--model` | Nome do modelo | - | `opt-oss-120b` |
| `--server` | Nome do servidor | - | `dgx300` |
| `--storage` | Perfil de storage | - | `profile_default` |
| `--concurrency` | SessÃµes simultÃ¢neas | - | `1000` |
| `--effective-context` | Tamanho do contexto (tokens) | - | `131072` |
| `--kv-precision` | PrecisÃ£o KV cache | `fp8` | `fp8`, `fp16` |
| `--kv-budget-ratio` | % HBM para KV | `0.70` | `0.65-0.75` |
| `--runtime-overhead-gib` | Overhead (GiB) | `120` | `80-150` |
| `--peak-headroom-ratio` | Headroom para picos | `0.20` | `0.10-0.40` |

---

## ğŸ“Š Formato de SaÃ­da

### RelatÃ³rio em Texto (stdout)

```
====================================================================================================
RELATÃ“RIO DE DIMENSIONAMENTO AVANÃ‡ADO DE INFERÃŠNCIA LLM
====================================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEÃ‡ÃƒO 1: ENTRADAS (Modelo / Servidor / Storage / NFR)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MODELO: opt-oss-120b, 36 camadas, 8 KV heads, hybrid attention...

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEÃ‡ÃƒO 2: DICIONÃRIO DE PARÃ‚METROS (ExplicaÃ§Ã£o e ImportÃ¢ncia)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€num_layersã€‘
  O que Ã©: NÃºmero total de camadas do transformer...
  Origem: ParÃ¢metro fixo da arquitetura...
  ImportÃ¢ncia: Impacta linearmente o tamanho do KV cache...
  Erro comum: Confundir num_layers com num_hidden_layers...

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEÃ‡ÃƒO 3: RESULTADOS POR CENÃRIO (MÃNIMO / RECOMENDADO / IDEAL)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

====================================================================================================
CENÃRIO: MÃNIMO
====================================================================================================
  â€¢ Peak Headroom: 0%
  â€¢ HA Mode: none
  â€¢ KV Budget Ratio: 70%

â–¸ Kv Per Session Gib: 2.25 GiB

  Racional:
    FÃ³rmula:
      Hybrid attention: 18 full + 18 sliding
      Full: 2 Ã— 131072 Ã— 8 Ã— 64 Ã— 1 Ã— 18
      Sliding: 2 Ã— 128 Ã— 8 Ã— 64 Ã— 1 Ã— 18
      total = full + sliding
    Inputs:
      â€¢ model: opt-oss-120b
      â€¢ num_layers: 36
      â€¢ num_kv_heads: 8
      â€¢ effective_context: 131072
      â€¢ kv_precision: fp8
      â€¢ bytes_per_element: 1
    InterpretaÃ§Ã£o:
      KV cache armazena tensores Key e Value de todas as camadas para o contexto
      da sessÃ£o. Modelo com attention_pattern='hybrid' usa contexto efetivo
      diferente por camada. Total de 2.25 GiB por sessÃ£o ativa.

â–¸ Nodes Final: 2 nÃ³s

  Racional:
    FÃ³rmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      â€¢ nodes_with_headroom: 2
      â€¢ ha_extra_nodes: 0
      â€¢ ha_mode: none
    InterpretaÃ§Ã£o:
      Sem HA: qualquer falha de nÃ³ causa degradaÃ§Ã£o imediata.

[... RECOMENDADO e IDEAL seguem o mesmo formato ...]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEÃ‡ÃƒO 4: ALERTAS E RISCOS OPERACIONAIS                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] ALERTA: Contexto longo (131,072 tokens) aumenta TTFT...
[2] AVISO: kv_precision=fp16 usa 2 bytes/elemento. Considere fp8...
```

### JSON Estruturado (stdout final)

```json
{
  "inputs": {
    "model": {...},
    "server": {...},
    "storage": {...},
    "nfr": {...}
  },
  "parameter_dictionary": {
    "num_layers": {
      "description": "...",
      "source": "...",
      "importance": "...",
      "common_errors": "..."
    }
  },
  "scenarios": {
    "minimum": {
      "name": "MÃNIMO",
      "configuration": {...},
      "results": {
        "kv_per_session_gib": 2.25,
        "nodes_final": 2,
        ...
      },
      "rationale": {
        "kv_per_session_gib": {
          "formula": "...",
          "inputs": {...},
          "explanation": "..."
        }
      },
      "warnings": [...]
    },
    "recommended": {...},
    "ideal": {...}
  },
  "alerts": [...]
}
```

---

## ğŸ“ Exemplos PrÃ¡ticos

### Exemplo 1: ProduÃ§Ã£o com FP8

```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 131072 \
  --kv-precision fp8
```

**Resultado:**
- **MÃNIMO:** 2 nÃ³s
- **RECOMENDADO:** 3 nÃ³s (N+1) â† **Usar este**
- **IDEAL:** 5 nÃ³s (N+2)

### Exemplo 2: Alta PrecisÃ£o com FP16

```bash
python3 sizing.py \
  --model opt-oss-120b \
  --server dgx300 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 131072 \
  --kv-precision fp16
```

**Resultado:**
- **MÃNIMO:** 4 nÃ³s (fp16 dobra memÃ³ria)
- **RECOMENDADO:** 5 nÃ³s (N+1)
- **IDEAL:** 7 nÃ³s (N+2)

**Insight:** FP16 vs FP8 aumenta custos em ~67% (3â†’5 nÃ³s no cenÃ¡rio recomendado).

### Exemplo 3: Modelo Menor, Contexto Menor

```bash
python3 sizing.py \
  --model opt-oss-20b \
  --server dgx200 \
  --storage profile_default \
  --concurrency 1000 \
  --effective-context 32768 \
  --kv-precision fp8
```

**Resultado:**
- **MÃNIMO:** 1 nÃ³
- **RECOMENDADO:** 2 nÃ³s (N+1)
- **IDEAL:** 3 nÃ³s (N+2)

---

## ğŸ§® Metodologia de CÃ¡lculo

### KV Cache por SessÃ£o

```
Para cada camada:
  - Full attention: seq = effective_context
  - Sliding attention: seq = sliding_window
  - Hybrid: mix de full e sliding

KV_bytes = 2 Ã— sum(seq_por_camada) Ã— num_kv_heads Ã— head_dim Ã— bytes_per_elem
KV_gib = KV_bytes / (1024^3)
```

### SessÃµes por NÃ³

```
HBM_total_gib = total_hbm_gb Ã— (10^9 / 2^30)
Budget_KV_gib = (HBM_total_gib - runtime_overhead_gib) Ã— kv_budget_ratio
Sessions_per_node = floor(Budget_KV_gib / KV_per_session_gib)
```

### NÃ³s por CenÃ¡rio

```
Nodes_capacity = ceil(concurrency / sessions_per_node)
Nodes_with_headroom = ceil(concurrency Ã— (1 + headroom) / sessions_per_node)
Nodes_final = Nodes_with_headroom + ha_extra_nodes
```

**Onde:**
- **MÃNIMO:** headroom=0%, ha_extra_nodes=0
- **RECOMENDADO:** headroom=20% (configurÃ¡vel), ha_extra_nodes=1
- **IDEAL:** headroom=max(30%, configurado), ha_extra_nodes=2, budget_ratio=min(65%, configurado)

---

## ğŸ“š DicionÃ¡rio de ParÃ¢metros (Resumo)

<details>
<summary><b>num_layers</b> (Modelo)</summary>

- **O que Ã©:** NÃºmero de camadas do transformer
- **Impacto:** Linear no KV cache (36 camadas = 1.5x mais memÃ³ria que 24)
- **Erro comum:** Confundir com num_hidden_layers ou contar sÃ³ encoder/decoder
</details>

<details>
<summary><b>num_key_value_heads</b> (Modelo)</summary>

- **O que Ã©:** NÃºmero de KV heads (GQA pode ter menos que query heads)
- **Impacto:** Direto no KV cache (8 heads vs 32 = 4x menos memÃ³ria)
- **Erro comum:** Usar num_attention_heads causando superestimaÃ§Ã£o de 4-8x
</details>

<details>
<summary><b>effective_context</b> (NFR)</summary>

- **O que Ã©:** Tamanho de contexto que sua aplicaÃ§Ã£o usarÃ¡
- **Impacto:** QuadrÃ¡tico para full attention, linear para sliding
- **Erro comum:** Usar max_position_embeddings sem necessidade
</details>

<details>
<summary><b>kv_precision</b> (Runtime)</summary>

- **O que Ã©:** PrecisÃ£o numÃ©rica (fp8=1 byte, fp16=2 bytes)
- **Impacto:** 2x na memÃ³ria (fp16 vs fp8)
- **Erro comum:** Usar fp16 por default sem validar se fp8 atende
</details>

<details>
<summary><b>kv_budget_ratio</b> (Tuning)</summary>

- **O que Ã©:** % da HBM alocada para KV cache
- **Impacto:** Quanto maior, mais sessÃµes/nÃ³, mas mais risco de fragmentaÃ§Ã£o
- **Erro comum:** Alocar 100% ignorando overhead do modelo
</details>

Veja relatÃ³rio completo ou JSON para dicionÃ¡rio detalhado de **todos** os parÃ¢metros.

---

## âš ï¸ Alertas Automatizados

O sistema gera avisos automÃ¡ticos para:

| CondiÃ§Ã£o | Alerta |
|----------|--------|
| `effective_context > max_position_embeddings` | Clamp automÃ¡tico + aviso |
| `kv_precision = fp16/bf16` | Aviso que dobra memÃ³ria vs fp8 |
| `effective_context > 128k` | Alerta de pressÃ£o em I/O de storage |
| `kv_budget_ratio > 0.75` | Risco de fragmentaÃ§Ã£o/instabilidade |
| `runtime_overhead_gib < 50` | Provavelmente subestimado |
| `sessions_per_node = 0` | Erro crÃ­tico: nÃ£o cabe nem 1 sessÃ£o |

---

## ğŸ¯ RecomendaÃ§Ãµes por Use Case

### Startup / PoC
- **CenÃ¡rio:** MÃNIMO
- **Motivo:** Custo mÃ­nimo, sem HA
- **Risco:** Qualquer falha causa downtime

### ProduÃ§Ã£o (SLA 99.9%)
- **CenÃ¡rio:** RECOMENDADO âœ…
- **Motivo:** N+1 + headroom balanceado
- **TCO:** Ideal para maioria dos casos

### MissÃ£o CrÃ­tica (SLA 99.99%)
- **CenÃ¡rio:** IDEAL
- **Motivo:** N+2, headroom 30%+, budget conservador
- **TCO:** +40-60% vs RECOMENDADO, mas mÃ¡xima resiliÃªncia

---

## ğŸ”§ OpÃ§Ãµes de CLI

```bash
# ObrigatÃ³rios
--model MODEL                    # Nome do modelo (models.json)
--server SERVER                  # Nome do servidor (servers.json)
--storage STORAGE                # Perfil de storage (storage.json)
--concurrency N                  # SessÃµes simultÃ¢neas
--effective-context N            # Contexto em tokens

# Opcionais
--kv-precision {fp8,fp16,bf16,int8}  # Default: fp8
--kv-budget-ratio RATIO              # Default: 0.70
--runtime-overhead-gib GIB           # Default: 120
--peak-headroom-ratio RATIO          # Default: 0.20

# Arquivos
--models-file FILE               # Default: models.json
--servers-file FILE              # Default: servers.json
--storage-file FILE              # Default: storage.json

# Output
--output-json-file FILE          # Salvar JSON em arquivo
--json-only                      # Apenas JSON, sem relatÃ³rio texto
--verbose                        # Mais detalhes
```

---

## ğŸ“Š Casos de Uso Validados

1. **Startup SaaS** (1k concurrent, 32k context): 1â†’2â†’3 nÃ³s
2. **Enterprise** (500 concurrent, 131k context, fp16, N+1): 4 nÃ³s
3. **API Provider** (5k concurrent, 131k context, N+1): 12 nÃ³s
4. **Pesquisa** (50 concurrent, 131k context, fp16): 1 nÃ³
5. **Cloud Serverless** (2k concurrent/regiÃ£o, 32k, N+1): 3 nÃ³s/regiÃ£o

Veja `USE_CASES.md` para anÃ¡lise detalhada.

---

## ğŸ§ª Testes

```bash
# Executar bateria de testes
python3 test_sizing.py

# Output esperado:
# âœ… 8 testes passados (100%)
```

---

## ğŸ“„ Requisitos

- **Python:** 3.8+
- **DependÃªncias:** Nenhuma (stdlib only)
- **Plataforma:** Linux, macOS, Windows

---

## ğŸ†š ComparaÃ§Ã£o v1.0 â†’ v2.0

| Feature | v1.0 | v2.0 |
|---------|------|------|
| CÃ¡lculo de KV cache | âœ… | âœ… |
| Dimensionamento de nÃ³s | âœ… | âœ… |
| Racional de cÃ¡lculo | âŒ | âœ… |
| DicionÃ¡rio de parÃ¢metros | âŒ | âœ… |
| 3 cenÃ¡rios (MIN/REC/IDEAL) | âŒ | âœ… |
| Alertas automatizados | BÃ¡sico | âœ… AvanÃ§ado |
| JSON com rationale | âŒ | âœ… |
| ExplicaÃ§Ã£o operacional | âŒ | âœ… |

---

## ğŸ“ Suporte

Para adicionar modelos, servidores ou perfis de storage:
1. Edite o respectivo arquivo JSON
2. Siga o formato existente
3. Execute `python3 -m json.tool <file>.json` para validar

---

## ğŸ“– DocumentaÃ§Ã£o Adicional

- **QUICKREF.md** - ReferÃªncia rÃ¡pida de comandos
- **USE_CASES.md** - 5 casos de uso reais detalhados
- **FLOWCHART.md** - Fluxogramas e diagramas
- **PROJECT_SUMMARY.md** - SumÃ¡rio tÃ©cnico completo

---

**VersÃ£o:** 2.0  
**Data:** 2026-02-08  
**Autor:** Sistema de Sizing de Infraestrutura IA  
**Python:** 3.8+  
**LicenÃ§a:** Interno
