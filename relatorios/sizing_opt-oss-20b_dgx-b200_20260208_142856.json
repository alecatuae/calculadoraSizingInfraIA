{
  "inputs": {
    "model": {
      "name": "opt-oss-20b",
      "num_layers": 24,
      "num_key_value_heads": 8,
      "head_dim": 64,
      "max_position_embeddings": 131072,
      "attention_pattern": "hybrid",
      "hybrid_full_layers": 12,
      "hybrid_sliding_layers": 12,
      "sliding_window": 128,
      "default_kv_precision": "fp8"
    },
    "server": {
      "name": "dgx-b200",
      "gpus": 8,
      "hbm_per_gpu_gb": 180,
      "total_hbm_gb": 1440,
      "total_hbm_gib": 1341.1,
      "nvlink_bandwidth_tbps": null,
      "system_memory_tb": 2
    },
    "storage": {
      "name": "profile_default",
      "type": "nvme_local",
      "iops_read": 1000000,
      "iops_write": 800000,
      "throughput_read_gbps": 28,
      "throughput_write_gbps": 25,
      "latency_read_ms_p99": 0.15,
      "latency_write_ms_p99": 0.2
    },
    "nfr": {
      "concurrency": 500,
      "effective_context": 65536,
      "kv_precision": "fp8",
      "kv_budget_ratio": 0.7,
      "runtime_overhead_gib": 120,
      "peak_headroom_ratio": 0.2
    }
  },
  "parameter_dictionary": {
    "num_layers": {
      "description": "Número total de camadas (layers) do transformer no modelo LLM. Cada camada possui seu próprio conjunto de tensores Key e Value no KV cache.",
      "source": "Parâmetro fixo da arquitetura do modelo, definido em models.json. Não pode ser alterado em runtime.",
      "importance": "Impacta linearmente o tamanho do KV cache. Modelos com mais camadas (ex: 36 vs 24) consomem proporcionalmente mais memória GPU para armazenar o histórico de atenção.",
      "common_errors": "Erro comum: Confundir num_layers com num_hidden_layers ou contar apenas encoder/decoder. Deve ser o total de camadas que mantêm KV cache."
    },
    "num_key_value_heads": {
      "description": "Número de cabeças (heads) de atenção para Key e Value. Em GQA (Grouped Query Attention), este valor pode ser menor que o número de query heads.",
      "source": "Parâmetro fixo da arquitetura do modelo (models.json). Modelos modernos usam GQA para reduzir KV cache.",
      "importance": "Impacta diretamente o tamanho do KV cache. Menos KV heads = menos memória. GQA com 8 KV heads vs 32 representa redução de 4x na memória de KV.",
      "common_errors": "Erro comum: Usar num_attention_heads (query heads) em vez de num_key_value_heads. Em GQA esses valores são diferentes e isso causa superestimação de 4-8x na memória."
    },
    "head_dim": {
      "description": "Dimensionalidade de cada cabeça de atenção (ex: 64, 128). Tamanho do vetor de embedding por head.",
      "source": "Parâmetro fixo da arquitetura do modelo (models.json). Geralmente 64 ou 128.",
      "importance": "Multiplica linearmente o tamanho do KV cache. head_dim=128 vs 64 dobra a memória necessária por head.",
      "common_errors": "Erro comum: Confundir head_dim com hidden_size. hidden_size = num_attention_heads × head_dim. Usar hidden_size diretamente causa erro massivo."
    },
    "max_position_embeddings": {
      "description": "Comprimento máximo de contexto (em tokens) que o modelo foi treinado para suportar. Limite arquitetural do positional embedding.",
      "source": "Parâmetro fixo da arquitetura do modelo (models.json). Definido no training.",
      "importance": "Define o limite superior para effective_context. Tentar usar contextos maiores causa comportamento indefinido (extrapolação de posições).",
      "common_errors": "Erro comum: Ignorar este limite e usar effective_context > max_position_embeddings. Isso leva a resultados incorretos ou crashes em runtime."
    },
    "attention_pattern": {
      "description": "Padrão de atenção usado pelo modelo: 'full' (todas camadas atendem contexto completo), 'sliding' (janela deslizante), ou 'hybrid' (mix de full e sliding).",
      "source": "Parâmetro fixo da arquitetura do modelo (models.json). Define como o modelo processa contexto longo.",
      "importance": "Crítico para cálculo correto de KV cache. Sliding window pode reduzir KV cache drasticamente (ex: 128k context com window=128 usa 1000x menos memória que full attention).",
      "common_errors": "Erro comum: Assumir 'full' para todos os modelos. Modelos modernos usam hybrid/sliding. Usar 'full' quando modelo é 'sliding' superestima memória em ordens de magnitude."
    },
    "sliding_window": {
      "description": "Tamanho da janela de atenção deslizante (em tokens) para camadas com sliding attention. Apenas os últimos N tokens são atendidos.",
      "source": "Parâmetro fixo da arquitetura do modelo (models.json), aplicável apenas se attention_pattern='sliding' ou 'hybrid'.",
      "importance": "Controla o tamanho do KV cache para camadas sliding. Sliding window pequeno (128) vs contexto longo (128k) reduz memória por camada em 1000x.",
      "common_errors": "Erro comum: Não usar sliding_window para camadas sliding, assumindo contexto completo. Isso causa overestimation massiva de memória e sizing incorreto."
    },
    "effective_context": {
      "description": "Tamanho de contexto (em tokens) que sua aplicação efetivamente usará em runtime. Diferente de max_position_embeddings (limite do modelo).",
      "source": "NFR (Non-Functional Requirement) do produto/aplicação. Você define baseado no use case (ex: 4k para chat, 128k para análise de documentos).",
      "importance": "Impacta diretamente o tamanho do KV cache por sessão. Contexto maior = mais memória = menos sessões por nó. Definir incorretamente causa over/under-provisioning.",
      "common_errors": "Erro comum: Usar max_position_embeddings como effective_context. Isso superestima memória se aplicação usa contextos menores, ou causa problemas se excede o limite do modelo."
    },
    "kv_precision": {
      "description": "Precisão numérica usada para armazenar tensores Key e Value: fp8/int8 (1 byte/elemento) ou fp16/bf16 (2 bytes/elemento).",
      "source": "Parâmetro de runtime configurável. fp8 é recomendado para economia de memória com mínima perda de qualidade.",
      "importance": "Impacta diretamente (2x) o tamanho do KV cache. fp16 vs fp8 dobra a memória necessária e reduz pela metade o número de sessões por nó.",
      "common_errors": "Erro comum: Usar fp16 por default sem testar fp8. Muitos casos fp8 tem qualidade equivalente, mas fp16 dobra o custo de infraestrutura desnecessariamente."
    },
    "concurrency": {
      "description": "Número de sessões/requisições simultâneas (concurrent users) que o sistema deve suportar. Métrica de throughput.",
      "source": "NFR do produto, baseado em projeções de tráfego e SLA. Pode vir de análise de uso, teste de carga, ou requisitos de negócio.",
      "importance": "Define quantos nós você precisa. Concurrency mal estimada causa: subdimensionamento (SLA quebrado, throttling) ou superdimensionamento (desperdício de capex).",
      "common_errors": "Erro comum: Confundir concurrency (sessões simultâneas) com RPS (requests per second). Concurrency = sessões ativas ao mesmo tempo. RPS considera latência."
    },
    "kv_budget_ratio": {
      "description": "Fração da HBM total alocada para KV cache (ex: 0.70 = 70%). O restante é para modelo, ativações, overhead de runtime.",
      "source": "Parâmetro de tuning/configuração. Default 0.70 é conservador. Pode ser ajustado baseado em profiling real.",
      "importance": "Define quantas sessões cabem por nó. Budget muito alto (>0.80) causa fragmentação e instabilidade. Budget muito baixo (<0.50) desperdiça HBM.",
      "common_errors": "Erro comum: Alocar 100% da HBM para KV cache, ignorando overhead do modelo, ativações, e buffers do runtime. Isso causa OOM (Out of Memory) em produção."
    },
    "runtime_overhead_gib": {
      "description": "Memória GPU (GiB) reservada para modelo (pesos), ativações de computação, e buffers do runtime de inferência.",
      "source": "Estimativa baseada em tamanho do modelo e framework. Pode ser medido via profiling. Default conservador: 80-150 GiB para modelos grandes.",
      "importance": "Subtrai da HBM disponível antes de calcular budget de KV. Subestimar causa OOM. Superestimar desperdiça capacidade.",
      "common_errors": "Erro comum: Usar overhead muito baixo (<50 GiB) para modelos grandes (>100B parâmetros). Modelo 120B em fp16 sozinho já ocupa ~240 GiB."
    },
    "peak_headroom_ratio": {
      "description": "Fração adicional de capacidade reservada para picos de tráfego (ex: 0.20 = 20% acima da concurrency nominal).",
      "source": "NFR de SRE, baseado em análise de sazonalidade e requisitos de SLO. Típico: 10-30%.",
      "importance": "Garante que sistema aguenta picos sem degradação de SLO. Sem headroom, qualquer pico causa throttling ou violação de SLA.",
      "common_errors": "Erro comum: Não ter headroom (0%) em produção. Tráfego sempre tem variação. Outro erro: headroom excessivo (>50%) que desperdiça capex."
    },
    "ha_mode": {
      "description": "Modo de alta disponibilidade: 'none' (sem redundância), 'n+1' (tolera falha de 1 nó), 'n+2' (tolera 2 nós).",
      "source": "NFR de disponibilidade, baseado em SLA. Produção crítica geralmente requer no mínimo N+1.",
      "importance": "Define quantos nós extras alocar para redundância. N+1 garante que falha de 1 nó não quebra SLA. Sem HA, falha de nó causa degradação imediata.",
      "common_errors": "Erro comum: Não ter HA (none) em produção com SLA > 99%. Falha de hardware é inevitável. Outro erro: N+2 quando N+1 já atende, desperdiçando capex."
    }
  },
  "scenarios": {
    "minimum": {
      "name": "MÍNIMO",
      "configuration": {
        "peak_headroom_ratio": 0.0,
        "ha_mode": "none",
        "ha_extra_nodes": 0,
        "kv_budget_ratio": 0.7
      },
      "results": {
        "kv_per_session_gib": 0.7515,
        "kv_total_gib": 375.73,
        "kv_total_tib": 0.3669,
        "hbm_total_gib": 1341.1,
        "kv_budget_gib": 854.77,
        "sessions_per_node": 1137,
        "nodes_capacity": 1,
        "nodes_with_headroom": 1,
        "nodes_final": 1
      },
      "rationale": {
        "kv_per_session_gib": {
          "formula": "Hybrid attention: 12 full + 12 sliding\nFull: 2 × 65536 × 8 × 64 × 1 × 12\nSliding: 2 × 128 × 8 × 64 × 1 × 12\ntotal = full + sliding",
          "inputs": {
            "model": "opt-oss-20b",
            "num_layers": 24,
            "num_kv_heads": 8,
            "head_dim": 64,
            "attention_pattern": "hybrid",
            "effective_context": 65536,
            "original_context": null,
            "sliding_window": 128,
            "kv_precision": "fp8",
            "bytes_per_element": 1,
            "total_bytes": 806879232
          },
          "explanation": "KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão. Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo diferente por camada. Total de 0.75 GiB por sessão ativa."
        },
        "kv_total_gib": {
          "formula": "kv_total_gib = kv_per_session_gib × concurrency",
          "inputs": {
            "kv_per_session_gib": 0.7515,
            "concurrency": 500
          },
          "explanation": "Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster."
        },
        "hbm_total_gib": {
          "formula": "hbm_total_gib = total_hbm_gb × (10^9 / 2^30)",
          "inputs": {
            "server": "dgx-b200",
            "gpus": 8,
            "hbm_per_gpu_gb": 180,
            "total_hbm_gb": 1440,
            "gb_to_gib_factor": 0.9313225746154785
          },
          "explanation": "Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário): 1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e buffers."
        },
        "kv_budget_gib": {
          "formula": "kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)",
          "inputs": {
            "hbm_total_gib": 1341.1,
            "runtime_overhead_gib": 120,
            "kv_budget_ratio": 0.7,
            "available_after_overhead_gib": 1221.1
          },
          "explanation": "De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes, alocamos 70% (854.8 GiB) para KV cache. O resto (30%) fica como buffer para fragmentação e overhead de runtime."
        },
        "sessions_per_node": {
          "formula": "sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)",
          "inputs": {
            "kv_budget_gib": 854.77,
            "kv_per_session_gib": 0.7515
          },
          "explanation": "Com 854.8 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode suportar 1137 sessões simultâneas. Este é o limite de capacidade por nó baseado exclusivamente em memória de KV cache."
        },
        "nodes_capacity": {
          "formula": "nodes_capacity = ceil(concurrency / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "sessions_per_node": 1137
          },
          "explanation": "Para atender 500 sessões simultâneas com 1137 sessões/nó, precisamos de no mínimo 1 nós. Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou redundância para HA."
        },
        "nodes_with_headroom": {
          "formula": "nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "peak_headroom_ratio": 0.0,
            "concurrency_with_headroom": 500.0,
            "sessions_per_node": 1137
          },
          "explanation": "Adicionando 0% de headroom para picos de tráfego, precisamos suportar 500 sessões simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de carga sem degradação de SLO."
        },
        "nodes_final": {
          "formula": "nodes_final = nodes_with_headroom + ha_extra_nodes",
          "inputs": {
            "nodes_with_headroom": 1,
            "ha_extra_nodes": 0,
            "ha_mode": "none"
          },
          "explanation": "Adicionando 0 nó(s) para alta disponibilidade, total final é 1 nós. Sem HA: qualquer falha de nó causa degradação imediata."
        },
        "total_power_kw": {
          "formula": "total_power_kw = nodes_final × power_kw_max",
          "inputs": {
            "nodes_final": 1,
            "power_kw_max": 14.3,
            "server": "dgx-b200"
          },
          "explanation": "Consumo total de energia para 1 nós × 14.3 kW/nó = 14.3 kW. Este é o dimensionamento de energia máxima do sistema, impactando PDU (Power Distribution Unit), capacidade de UPS, e contrato de energia do data center. Considere também eficiência de cooling (PUE ~1.3-1.5x)."
        },
        "total_rack_u": {
          "formula": "total_rack_u = nodes_final × rack_units_u",
          "inputs": {
            "nodes_final": 1,
            "rack_units_u": 10,
            "server": "dgx-b200"
          },
          "explanation": "Espaço total de rack necessário: 1 nós × 10U/nó = 10U. Considerando racks padrão de 42U, isto equivale a 0.2 racks. Impacta densidade de implantação e capacidade física do data center. Adicione ~20% para switches, PDUs e espaço de ventilação."
        }
      },
      "warnings": []
    },
    "recommended": {
      "name": "RECOMENDADO",
      "configuration": {
        "peak_headroom_ratio": 0.2,
        "ha_mode": "n+1",
        "ha_extra_nodes": 1,
        "kv_budget_ratio": 0.7
      },
      "results": {
        "kv_per_session_gib": 0.7515,
        "kv_total_gib": 375.73,
        "kv_total_tib": 0.3669,
        "hbm_total_gib": 1341.1,
        "kv_budget_gib": 854.77,
        "sessions_per_node": 1137,
        "nodes_capacity": 1,
        "nodes_with_headroom": 1,
        "nodes_final": 2
      },
      "rationale": {
        "kv_per_session_gib": {
          "formula": "Hybrid attention: 12 full + 12 sliding\nFull: 2 × 65536 × 8 × 64 × 1 × 12\nSliding: 2 × 128 × 8 × 64 × 1 × 12\ntotal = full + sliding",
          "inputs": {
            "model": "opt-oss-20b",
            "num_layers": 24,
            "num_kv_heads": 8,
            "head_dim": 64,
            "attention_pattern": "hybrid",
            "effective_context": 65536,
            "original_context": null,
            "sliding_window": 128,
            "kv_precision": "fp8",
            "bytes_per_element": 1,
            "total_bytes": 806879232
          },
          "explanation": "KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão. Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo diferente por camada. Total de 0.75 GiB por sessão ativa."
        },
        "kv_total_gib": {
          "formula": "kv_total_gib = kv_per_session_gib × concurrency",
          "inputs": {
            "kv_per_session_gib": 0.7515,
            "concurrency": 500
          },
          "explanation": "Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster."
        },
        "hbm_total_gib": {
          "formula": "hbm_total_gib = total_hbm_gb × (10^9 / 2^30)",
          "inputs": {
            "server": "dgx-b200",
            "gpus": 8,
            "hbm_per_gpu_gb": 180,
            "total_hbm_gb": 1440,
            "gb_to_gib_factor": 0.9313225746154785
          },
          "explanation": "Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário): 1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e buffers."
        },
        "kv_budget_gib": {
          "formula": "kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)",
          "inputs": {
            "hbm_total_gib": 1341.1,
            "runtime_overhead_gib": 120,
            "kv_budget_ratio": 0.7,
            "available_after_overhead_gib": 1221.1
          },
          "explanation": "De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes, alocamos 70% (854.8 GiB) para KV cache. O resto (30%) fica como buffer para fragmentação e overhead de runtime."
        },
        "sessions_per_node": {
          "formula": "sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)",
          "inputs": {
            "kv_budget_gib": 854.77,
            "kv_per_session_gib": 0.7515
          },
          "explanation": "Com 854.8 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode suportar 1137 sessões simultâneas. Este é o limite de capacidade por nó baseado exclusivamente em memória de KV cache."
        },
        "nodes_capacity": {
          "formula": "nodes_capacity = ceil(concurrency / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "sessions_per_node": 1137
          },
          "explanation": "Para atender 500 sessões simultâneas com 1137 sessões/nó, precisamos de no mínimo 1 nós. Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou redundância para HA."
        },
        "nodes_with_headroom": {
          "formula": "nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "peak_headroom_ratio": 0.2,
            "concurrency_with_headroom": 600.0,
            "sessions_per_node": 1137
          },
          "explanation": "Adicionando 20% de headroom para picos de tráfego, precisamos suportar 600 sessões simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de carga sem degradação de SLO."
        },
        "nodes_final": {
          "formula": "nodes_final = nodes_with_headroom + ha_extra_nodes",
          "inputs": {
            "nodes_with_headroom": 1,
            "ha_extra_nodes": 1,
            "ha_mode": "n+1"
          },
          "explanation": "Adicionando 1 nó(s) para alta disponibilidade, total final é 2 nós. Com N+1: sistema tolera falha de 1 nó mantendo SLO."
        },
        "total_power_kw": {
          "formula": "total_power_kw = nodes_final × power_kw_max",
          "inputs": {
            "nodes_final": 2,
            "power_kw_max": 14.3,
            "server": "dgx-b200"
          },
          "explanation": "Consumo total de energia para 2 nós × 14.3 kW/nó = 28.6 kW. Este é o dimensionamento de energia máxima do sistema, impactando PDU (Power Distribution Unit), capacidade de UPS, e contrato de energia do data center. Considere também eficiência de cooling (PUE ~1.3-1.5x)."
        },
        "total_rack_u": {
          "formula": "total_rack_u = nodes_final × rack_units_u",
          "inputs": {
            "nodes_final": 2,
            "rack_units_u": 10,
            "server": "dgx-b200"
          },
          "explanation": "Espaço total de rack necessário: 2 nós × 10U/nó = 20U. Considerando racks padrão de 42U, isto equivale a 0.5 racks. Impacta densidade de implantação e capacidade física do data center. Adicione ~20% para switches, PDUs e espaço de ventilação."
        }
      },
      "warnings": []
    },
    "ideal": {
      "name": "IDEAL",
      "configuration": {
        "peak_headroom_ratio": 0.3,
        "ha_mode": "n+2",
        "ha_extra_nodes": 2,
        "kv_budget_ratio": 0.65
      },
      "results": {
        "kv_per_session_gib": 0.7515,
        "kv_total_gib": 375.73,
        "kv_total_tib": 0.3669,
        "hbm_total_gib": 1341.1,
        "kv_budget_gib": 793.72,
        "sessions_per_node": 1056,
        "nodes_capacity": 1,
        "nodes_with_headroom": 1,
        "nodes_final": 3
      },
      "rationale": {
        "kv_per_session_gib": {
          "formula": "Hybrid attention: 12 full + 12 sliding\nFull: 2 × 65536 × 8 × 64 × 1 × 12\nSliding: 2 × 128 × 8 × 64 × 1 × 12\ntotal = full + sliding",
          "inputs": {
            "model": "opt-oss-20b",
            "num_layers": 24,
            "num_kv_heads": 8,
            "head_dim": 64,
            "attention_pattern": "hybrid",
            "effective_context": 65536,
            "original_context": null,
            "sliding_window": 128,
            "kv_precision": "fp8",
            "bytes_per_element": 1,
            "total_bytes": 806879232
          },
          "explanation": "KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão. Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo diferente por camada. Total de 0.75 GiB por sessão ativa."
        },
        "kv_total_gib": {
          "formula": "kv_total_gib = kv_per_session_gib × concurrency",
          "inputs": {
            "kv_per_session_gib": 0.7515,
            "concurrency": 500
          },
          "explanation": "Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster."
        },
        "hbm_total_gib": {
          "formula": "hbm_total_gib = total_hbm_gb × (10^9 / 2^30)",
          "inputs": {
            "server": "dgx-b200",
            "gpus": 8,
            "hbm_per_gpu_gb": 180,
            "total_hbm_gb": 1440,
            "gb_to_gib_factor": 0.9313225746154785
          },
          "explanation": "Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário): 1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e buffers."
        },
        "kv_budget_gib": {
          "formula": "kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)",
          "inputs": {
            "hbm_total_gib": 1341.1,
            "runtime_overhead_gib": 120,
            "kv_budget_ratio": 0.65,
            "available_after_overhead_gib": 1221.1
          },
          "explanation": "De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes, alocamos 65% (793.7 GiB) para KV cache. O resto (35%) fica como buffer para fragmentação e overhead de runtime."
        },
        "sessions_per_node": {
          "formula": "sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)",
          "inputs": {
            "kv_budget_gib": 793.72,
            "kv_per_session_gib": 0.7515
          },
          "explanation": "Com 793.7 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode suportar 1056 sessões simultâneas. Este é o limite de capacidade por nó baseado exclusivamente em memória de KV cache."
        },
        "nodes_capacity": {
          "formula": "nodes_capacity = ceil(concurrency / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "sessions_per_node": 1056
          },
          "explanation": "Para atender 500 sessões simultâneas com 1056 sessões/nó, precisamos de no mínimo 1 nós. Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou redundância para HA."
        },
        "nodes_with_headroom": {
          "formula": "nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)",
          "inputs": {
            "concurrency": 500,
            "peak_headroom_ratio": 0.3,
            "concurrency_with_headroom": 650.0,
            "sessions_per_node": 1056
          },
          "explanation": "Adicionando 30% de headroom para picos de tráfego, precisamos suportar 650 sessões simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de carga sem degradação de SLO."
        },
        "nodes_final": {
          "formula": "nodes_final = nodes_with_headroom + ha_extra_nodes",
          "inputs": {
            "nodes_with_headroom": 1,
            "ha_extra_nodes": 2,
            "ha_mode": "n+2"
          },
          "explanation": "Adicionando 2 nó(s) para alta disponibilidade, total final é 3 nós. Com N+2: sistema tolera falha de 2 nós mantendo SLO."
        },
        "total_power_kw": {
          "formula": "total_power_kw = nodes_final × power_kw_max",
          "inputs": {
            "nodes_final": 3,
            "power_kw_max": 14.3,
            "server": "dgx-b200"
          },
          "explanation": "Consumo total de energia para 3 nós × 14.3 kW/nó = 42.900000000000006 kW. Este é o dimensionamento de energia máxima do sistema, impactando PDU (Power Distribution Unit), capacidade de UPS, e contrato de energia do data center. Considere também eficiência de cooling (PUE ~1.3-1.5x)."
        },
        "total_rack_u": {
          "formula": "total_rack_u = nodes_final × rack_units_u",
          "inputs": {
            "nodes_final": 3,
            "rack_units_u": 10,
            "server": "dgx-b200"
          },
          "explanation": "Espaço total de rack necessário: 3 nós × 10U/nó = 30U. Considerando racks padrão de 42U, isto equivale a 0.7 racks. Impacta densidade de implantação e capacidade física do data center. Adicione ~20% para switches, PDUs e espaço de ventilação."
        }
      },
      "warnings": []
    }
  },
  "alerts": []
}