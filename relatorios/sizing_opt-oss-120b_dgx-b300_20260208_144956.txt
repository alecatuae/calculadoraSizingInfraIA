====================================================================================================
RELATÓRIO DE DIMENSIONAMENTO AVANÇADO DE INFERÊNCIA LLM
Sistema de Sizing com Racional de Cálculo e Análise de Cenários
====================================================================================================

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 1: ENTRADAS (Modelo / Servidor / Storage / NFR)                                            │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

MODELO:
  Nome: opt-oss-120b
  Camadas: 36
  KV Heads: 8
  Head Dim: 64
  Max Position Embeddings: 131,072
  Padrão de Atenção: hybrid
    • Full Layers: 18
    • Sliding Layers: 18
    • Sliding Window: 128
  Precisão KV Padrão: fp8

SERVIDOR:
  Nome: dgx-b300
  GPUs: 8
  HBM por GPU: 288 GB
  HBM Total: 2304 GB (2145.8 GiB)
  NVLink Bandwidth: 14.4 TB/s

STORAGE:
  Perfil: profile_default
  Tipo: nvme_local
  IOPS: 1,000,000 read / 800,000 write
  Throughput: 28 GB/s read / 25 GB/s write
  Latência P99: 0.15 ms read / 0.2 ms write

NFR (Non-Functional Requirements):
  Concorrência Alvo: 1,000 sessões simultâneas
  Contexto Efetivo: 131,072 tokens
  Precisão KV: fp8

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 2: DICIONÁRIO DE PARÂMETROS (Explicação e Importância)                                     │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

【num_layers】
  O que é: Número total de camadas (layers) do transformer no modelo LLM. Cada camada possui seu próprio conjunto de tensores Key e Value no KV cache.
  Origem: Parâmetro fixo da arquitetura do modelo, definido em models.json. Não pode ser alterado em runtime.
  Importância: Impacta linearmente o tamanho do KV cache. Modelos com mais camadas (ex: 36 vs 24) consomem proporcionalmente mais memória GPU para armazenar o histórico de atenção.
  Erro comum: Erro comum: Confundir num_layers com num_hidden_layers ou contar apenas encoder/decoder. Deve ser o total de camadas que mantêm KV cache.

【num_key_value_heads】
  O que é: Número de cabeças (heads) de atenção para Key e Value. Em GQA (Grouped Query Attention), este valor pode ser menor que o número de query heads.
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Modelos modernos usam GQA para reduzir KV cache.
  Importância: Impacta diretamente o tamanho do KV cache. Menos KV heads = menos memória. GQA com 8 KV heads vs 32 representa redução de 4x na memória de KV.
  Erro comum: Erro comum: Usar num_attention_heads (query heads) em vez de num_key_value_heads. Em GQA esses valores são diferentes e isso causa superestimação de 4-8x na memória.

【head_dim】
  O que é: Dimensionalidade de cada cabeça de atenção (ex: 64, 128). Tamanho do vetor de embedding por head.
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Geralmente 64 ou 128.
  Importância: Multiplica linearmente o tamanho do KV cache. head_dim=128 vs 64 dobra a memória necessária por head.
  Erro comum: Erro comum: Confundir head_dim com hidden_size. hidden_size = num_attention_heads × head_dim. Usar hidden_size diretamente causa erro massivo.

【attention_pattern】
  O que é: Padrão de atenção usado pelo modelo: 'full' (todas camadas atendem contexto completo), 'sliding' (janela deslizante), ou 'hybrid' (mix de full e sliding).
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Define como o modelo processa contexto longo.
  Importância: Crítico para cálculo correto de KV cache. Sliding window pode reduzir KV cache drasticamente (ex: 128k context com window=128 usa 1000x menos memória que full attention).
  Erro comum: Erro comum: Assumir 'full' para todos os modelos. Modelos modernos usam hybrid/sliding. Usar 'full' quando modelo é 'sliding' superestima memória em ordens de magnitude.

【effective_context】
  O que é: Tamanho de contexto (em tokens) que sua aplicação efetivamente usará em runtime. Diferente de max_position_embeddings (limite do modelo).
  Origem: NFR (Non-Functional Requirement) do produto/aplicação. Você define baseado no use case (ex: 4k para chat, 128k para análise de documentos).
  Importância: Impacta diretamente o tamanho do KV cache por sessão. Contexto maior = mais memória = menos sessões por nó. Definir incorretamente causa over/under-provisioning.
  Erro comum: Erro comum: Usar max_position_embeddings como effective_context. Isso superestima memória se aplicação usa contextos menores, ou causa problemas se excede o limite do modelo.

【kv_precision】
  O que é: Precisão numérica usada para armazenar tensores Key e Value: fp8/int8 (1 byte/elemento) ou fp16/bf16 (2 bytes/elemento).
  Origem: Parâmetro de runtime configurável. fp8 é recomendado para economia de memória com mínima perda de qualidade.
  Importância: Impacta diretamente (2x) o tamanho do KV cache. fp16 vs fp8 dobra a memória necessária e reduz pela metade o número de sessões por nó.
  Erro comum: Erro comum: Usar fp16 por default sem testar fp8. Muitos casos fp8 tem qualidade equivalente, mas fp16 dobra o custo de infraestrutura desnecessariamente.

【concurrency】
  O que é: Número de sessões/requisições simultâneas (concurrent users) que o sistema deve suportar. Métrica de throughput.
  Origem: NFR do produto, baseado em projeções de tráfego e SLA. Pode vir de análise de uso, teste de carga, ou requisitos de negócio.
  Importância: Define quantos nós você precisa. Concurrency mal estimada causa: subdimensionamento (SLA quebrado, throttling) ou superdimensionamento (desperdício de capex).
  Erro comum: Erro comum: Confundir concurrency (sessões simultâneas) com RPS (requests per second). Concurrency = sessões ativas ao mesmo tempo. RPS considera latência.

【kv_budget_ratio】
  O que é: Fração da HBM total alocada para KV cache (ex: 0.70 = 70%). O restante é para modelo, ativações, overhead de runtime.
  Origem: Parâmetro de tuning/configuração. Default 0.70 é conservador. Pode ser ajustado baseado em profiling real.
  Importância: Define quantas sessões cabem por nó. Budget muito alto (>0.80) causa fragmentação e instabilidade. Budget muito baixo (<0.50) desperdiça HBM.
  Erro comum: Erro comum: Alocar 100% da HBM para KV cache, ignorando overhead do modelo, ativações, e buffers do runtime. Isso causa OOM (Out of Memory) em produção.

【runtime_overhead_gib】
  O que é: Memória GPU (GiB) reservada para modelo (pesos), ativações de computação, e buffers do runtime de inferência.
  Origem: Estimativa baseada em tamanho do modelo e framework. Pode ser medido via profiling. Default conservador: 80-150 GiB para modelos grandes.
  Importância: Subtrai da HBM disponível antes de calcular budget de KV. Subestimar causa OOM. Superestimar desperdiça capacidade.
  Erro comum: Erro comum: Usar overhead muito baixo (<50 GiB) para modelos grandes (>100B parâmetros). Modelo 120B em fp16 sozinho já ocupa ~240 GiB.

【peak_headroom_ratio】
  O que é: Fração adicional de capacidade reservada para picos de tráfego (ex: 0.20 = 20% acima da concurrency nominal).
  Origem: NFR de SRE, baseado em análise de sazonalidade e requisitos de SLO. Típico: 10-30%.
  Importância: Garante que sistema aguenta picos sem degradação de SLO. Sem headroom, qualquer pico causa throttling ou violação de SLA.
  Erro comum: Erro comum: Não ter headroom (0%) em produção. Tráfego sempre tem variação. Outro erro: headroom excessivo (>50%) que desperdiça capex.

【ha_mode】
  O que é: Modo de alta disponibilidade: 'none' (sem redundância), 'n+1' (tolera falha de 1 nó), 'n+2' (tolera 2 nós).
  Origem: NFR de disponibilidade, baseado em SLA. Produção crítica geralmente requer no mínimo N+1.
  Importância: Define quantos nós extras alocar para redundância. N+1 garante que falha de 1 nó não quebra SLA. Sem HA, falha de nó causa degradação imediata.
  Erro comum: Erro comum: Não ter HA (none) em produção com SLA > 99%. Falha de hardware é inevitável. Outro erro: N+2 quando N+1 já atende, desperdiçando capex.

(Veja JSON para dicionário completo de todos os parâmetros)

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 2.5: CONSUMO REAL DE VRAM (Pesos + KV Cache + Overhead)                                    │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

CONSUMO UNITÁRIO (por sessão e por nó):

┌─────────────────────────────────────────┬──────────────────┬────────────────────────────────────────┐
│ Item                                    │ VRAM (GiB)       │ Observação                             │
├─────────────────────────────────────────┼──────────────────┼────────────────────────────────────────┤
│ Pesos do modelo (por réplica)          │            15.00 │ Real + precisão weights │
│ Overhead do runtime (por nó)           │           120.00 │ Buffers, ativações, fragmentação       │
│ KV cache (por sessão)                  │             2.25 │ Contexto=131,072, KV precision=fp8 │
└─────────────────────────────────────────┴──────────────────┴────────────────────────────────────────┘

BUDGET E CAPACIDADE POR NÓ:

┌─────────────────────────────────────────┬──────────────────┐
│ Métrica                                 │ Valor            │
├─────────────────────────────────────────┼──────────────────┤
│ HBM total do nó                        │        2145.8 GiB │
│ VRAM fixa (pesos)                      │          15.0 GiB │
│ Overhead runtime                       │         120.0 GiB │
│ Budget bruto para sessões              │        2010.8 GiB │
│ Budget operacional (70%)             │        1407.5 GiB │
│ Sessões suportadas por nó              │              624 │
│ VRAM total operando (efetiva)          │         887.2 GiB │
│ Utilização de HBM (efetiva)            │           41.3 % │
└─────────────────────────────────────────┴──────────────────┘

INTERPRETAÇÃO:
  • Cada nó carrega 15.0 GiB de pesos (fixo) + 120 GiB de overhead
  • Sobram 2010.8 GiB para sessões; aplicando ratio 70% → 1407.5 GiB operacional
  • Cada sessão consome 2.25 GiB → máximo de 624 sessões/nó
  • Operando com 334 sessões/nó → 887.2 GiB VRAM total (41.3% HBM)

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 3: RESULTADOS POR CENÁRIO (MÍNIMO / RECOMENDADO / IDEAL)                                   │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

====================================================================================================
CENÁRIO: MÍNIMO
====================================================================================================
  • Peak Headroom: 0%
  • HA Mode: none
  • KV Budget Ratio: 70%

▸ Fixed Model Gib: 15.00 GiB

  Racional:
    Fórmula:
      fixed_model_gib = (weights_gib / (TP × PP)) × replicas_per_node
    Inputs:
      • weights_gib: 120.0
      • weights_precision: fp8
      • replicas_per_node: 1
      • tensor_parallel: 8
      • pipeline_parallel: 1
      • estimated: False
    Interpretação:
      Memória dos pesos do modelo: 120.0 GiB (real) em precisão fp8. Com TP=8 e PP=1, pesos são
      distribuídos. Cada nó carrega 1 réplica(s), resultando em 15.0 GiB de memória fixa por
      nó.

▸ Vram Per Session Gib: 2.25 GiB

  Racional:
    Fórmula:
      vram_per_session_gib = kv_per_session_gib
    Inputs:
      • kv_per_session_gib: 2.2522
      • kv_precision: fp8
    Interpretação:
      VRAM consumida por cada sessão ativa: 2.25 GiB de KV cache. Esta memória é variável e
      escala linearmente com o número de sessões simultâneas.

▸ Sessions Budget Gib: 1407.5 GiB

  Racional:
    Fórmula:
      sessions_budget_gib = budget_for_sessions_gib × kv_budget_ratio
    Inputs:
      • budget_for_sessions_gib: 2010.77
      • kv_budget_ratio: 0.7
    Interpretação:
      Budget operacional para sessões: 2010.8 GiB × 70% = 1407.5 GiB. Os restantes 30% (603.2
      GiB) ficam livres para fragmentação, picos de memória e estabilidade.

▸ Sessions Per Node: 624 sessões (capacidade máxima)

  Racional:
    Fórmula:
      sessions_per_node = floor(sessions_budget_gib / vram_per_session_gib)
    Inputs:
      • sessions_budget_gib: 1407.54
      • vram_per_session_gib: 2.2522
    Interpretação:
      Capacidade de sessões por nó: 1407.5 GiB / 2.25 GiB/sessão = 624 sessões. Este é o limite
      máximo de concorrência por servidor, determinado puramente por memória disponível para KV
      cache.

▸ Sessions Per Node Effective: 500 sessões (operando)
▸ Vram Total Node Effective Gib: 1261.1 GiB (58.8% HBM)

  Racional:
    Fórmula:
      vram_total = fixed_model_gib + runtime_overhead_gib + (sessions_effective × vram_per_session)
    Inputs:
      • fixed_model_gib: 15.0
      • runtime_overhead_gib: 120
      • sessions_per_node_effective: 500
      • vram_per_session_gib: 2.2522
    Interpretação:
      VRAM total por nó operando: 15.0 GiB (pesos) + 120 GiB (overhead) + (500 sessões × 2.25
      GiB) = 1261.1 GiB. Utilização de HBM: 58.8%.

▸ Nodes Capacity: 2 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • sessions_per_node: 624
    Interpretação:
      Nós necessários para capacidade pura: ceil(1,000 / 624) = 2 nós.

▸ Nodes With Headroom: 2 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • peak_headroom_ratio: 0.0
      • concurrency_with_headroom: 1000.0
      • sessions_per_node: 624
    Interpretação:
      Nós com headroom de 0% para picos: 2 nós.

▸ Nodes Final: 2 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 2
      • ha_extra_nodes: 0
      • ha_mode: none
    Interpretação:
      Nós finais com HA: 2 + 0 = 2 nós.

▸ Total Power Kw: 29.0 kW

  Racional:
    Fórmula:
      total_power_kw = nodes_final × power_kw_max
    Inputs:
      • nodes_final: 2
      • power_kw_max: 14.5
    Interpretação:
      Energia total: 2 nós × 14.5 kW = 29.0 kW. Dimensiona PDU, UPS e contrato de energia.
      Considere PUE ~1.4x para cooling.

▸ Total Rack U: 20U

  Racional:
    Fórmula:
      total_rack_u = nodes_final × rack_units_u
    Inputs:
      • nodes_final: 2
      • rack_units_u: 10
    Interpretação:
      Rack total: 2 nós × 10U = 20U (0.5 racks padrão). Adicione ~20% para infra.

  ⚠️  AVISOS DESTE CENÁRIO:
    [1] ALERTA: Contexto longo (131,072 tokens) aumenta TTFT e pressiona I/O.

====================================================================================================
CENÁRIO: RECOMENDADO
====================================================================================================
  • Peak Headroom: 20%
  • HA Mode: n+1
  • KV Budget Ratio: 70%

▸ Fixed Model Gib: 15.00 GiB

  Racional:
    Fórmula:
      fixed_model_gib = (weights_gib / (TP × PP)) × replicas_per_node
    Inputs:
      • weights_gib: 120.0
      • weights_precision: fp8
      • replicas_per_node: 1
      • tensor_parallel: 8
      • pipeline_parallel: 1
      • estimated: False
    Interpretação:
      Memória dos pesos do modelo: 120.0 GiB (real) em precisão fp8. Com TP=8 e PP=1, pesos são
      distribuídos. Cada nó carrega 1 réplica(s), resultando em 15.0 GiB de memória fixa por
      nó.

▸ Vram Per Session Gib: 2.25 GiB

  Racional:
    Fórmula:
      vram_per_session_gib = kv_per_session_gib
    Inputs:
      • kv_per_session_gib: 2.2522
      • kv_precision: fp8
    Interpretação:
      VRAM consumida por cada sessão ativa: 2.25 GiB de KV cache. Esta memória é variável e
      escala linearmente com o número de sessões simultâneas.

▸ Sessions Budget Gib: 1407.5 GiB

  Racional:
    Fórmula:
      sessions_budget_gib = budget_for_sessions_gib × kv_budget_ratio
    Inputs:
      • budget_for_sessions_gib: 2010.77
      • kv_budget_ratio: 0.7
    Interpretação:
      Budget operacional para sessões: 2010.8 GiB × 70% = 1407.5 GiB. Os restantes 30% (603.2
      GiB) ficam livres para fragmentação, picos de memória e estabilidade.

▸ Sessions Per Node: 624 sessões (capacidade máxima)

  Racional:
    Fórmula:
      sessions_per_node = floor(sessions_budget_gib / vram_per_session_gib)
    Inputs:
      • sessions_budget_gib: 1407.54
      • vram_per_session_gib: 2.2522
    Interpretação:
      Capacidade de sessões por nó: 1407.5 GiB / 2.25 GiB/sessão = 624 sessões. Este é o limite
      máximo de concorrência por servidor, determinado puramente por memória disponível para KV
      cache.

▸ Sessions Per Node Effective: 334 sessões (operando)
▸ Vram Total Node Effective Gib: 887.2 GiB (41.3% HBM)

  Racional:
    Fórmula:
      vram_total = fixed_model_gib + runtime_overhead_gib + (sessions_effective × vram_per_session)
    Inputs:
      • fixed_model_gib: 15.0
      • runtime_overhead_gib: 120
      • sessions_per_node_effective: 334
      • vram_per_session_gib: 2.2522
    Interpretação:
      VRAM total por nó operando: 15.0 GiB (pesos) + 120 GiB (overhead) + (334 sessões × 2.25
      GiB) = 887.2 GiB. Utilização de HBM: 41.3%.

▸ Nodes Capacity: 2 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • sessions_per_node: 624
    Interpretação:
      Nós necessários para capacidade pura: ceil(1,000 / 624) = 2 nós.

▸ Nodes With Headroom: 2 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • peak_headroom_ratio: 0.2
      • concurrency_with_headroom: 1200.0
      • sessions_per_node: 624
    Interpretação:
      Nós com headroom de 20% para picos: 2 nós.

▸ Nodes Final: 3 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 2
      • ha_extra_nodes: 1
      • ha_mode: n+1
    Interpretação:
      Nós finais com HA: 2 + 1 = 3 nós.

▸ Total Power Kw: 43.5 kW

  Racional:
    Fórmula:
      total_power_kw = nodes_final × power_kw_max
    Inputs:
      • nodes_final: 3
      • power_kw_max: 14.5
    Interpretação:
      Energia total: 3 nós × 14.5 kW = 43.5 kW. Dimensiona PDU, UPS e contrato de energia.
      Considere PUE ~1.4x para cooling.

▸ Total Rack U: 30U

  Racional:
    Fórmula:
      total_rack_u = nodes_final × rack_units_u
    Inputs:
      • nodes_final: 3
      • rack_units_u: 10
    Interpretação:
      Rack total: 3 nós × 10U = 30U (0.7 racks padrão). Adicione ~20% para infra.

  ⚠️  AVISOS DESTE CENÁRIO:
    [1] ALERTA: Contexto longo (131,072 tokens) aumenta TTFT e pressiona I/O.

====================================================================================================
CENÁRIO: IDEAL
====================================================================================================
  • Peak Headroom: 30%
  • HA Mode: n+2
  • KV Budget Ratio: 65%

▸ Fixed Model Gib: 15.00 GiB

  Racional:
    Fórmula:
      fixed_model_gib = (weights_gib / (TP × PP)) × replicas_per_node
    Inputs:
      • weights_gib: 120.0
      • weights_precision: fp8
      • replicas_per_node: 1
      • tensor_parallel: 8
      • pipeline_parallel: 1
      • estimated: False
    Interpretação:
      Memória dos pesos do modelo: 120.0 GiB (real) em precisão fp8. Com TP=8 e PP=1, pesos são
      distribuídos. Cada nó carrega 1 réplica(s), resultando em 15.0 GiB de memória fixa por
      nó.

▸ Vram Per Session Gib: 2.25 GiB

  Racional:
    Fórmula:
      vram_per_session_gib = kv_per_session_gib
    Inputs:
      • kv_per_session_gib: 2.2522
      • kv_precision: fp8
    Interpretação:
      VRAM consumida por cada sessão ativa: 2.25 GiB de KV cache. Esta memória é variável e
      escala linearmente com o número de sessões simultâneas.

▸ Sessions Budget Gib: 1307.0 GiB

  Racional:
    Fórmula:
      sessions_budget_gib = budget_for_sessions_gib × kv_budget_ratio
    Inputs:
      • budget_for_sessions_gib: 2010.77
      • kv_budget_ratio: 0.65
    Interpretação:
      Budget operacional para sessões: 2010.8 GiB × 65% = 1307.0 GiB. Os restantes 35% (703.8
      GiB) ficam livres para fragmentação, picos de memória e estabilidade.

▸ Sessions Per Node: 580 sessões (capacidade máxima)

  Racional:
    Fórmula:
      sessions_per_node = floor(sessions_budget_gib / vram_per_session_gib)
    Inputs:
      • sessions_budget_gib: 1307.0
      • vram_per_session_gib: 2.2522
    Interpretação:
      Capacidade de sessões por nó: 1307.0 GiB / 2.25 GiB/sessão = 580 sessões. Este é o limite
      máximo de concorrência por servidor, determinado puramente por memória disponível para KV
      cache.

▸ Sessions Per Node Effective: 200 sessões (operando)
▸ Vram Total Node Effective Gib: 585.4 GiB (27.3% HBM)

  Racional:
    Fórmula:
      vram_total = fixed_model_gib + runtime_overhead_gib + (sessions_effective × vram_per_session)
    Inputs:
      • fixed_model_gib: 15.0
      • runtime_overhead_gib: 120
      • sessions_per_node_effective: 200
      • vram_per_session_gib: 2.2522
    Interpretação:
      VRAM total por nó operando: 15.0 GiB (pesos) + 120 GiB (overhead) + (200 sessões × 2.25
      GiB) = 585.4 GiB. Utilização de HBM: 27.3%.

▸ Nodes Capacity: 2 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • sessions_per_node: 580
    Interpretação:
      Nós necessários para capacidade pura: ceil(1,000 / 580) = 2 nós.

▸ Nodes With Headroom: 3 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 1000
      • peak_headroom_ratio: 0.3
      • concurrency_with_headroom: 1300.0
      • sessions_per_node: 580
    Interpretação:
      Nós com headroom de 30% para picos: 3 nós.

▸ Nodes Final: 5 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 3
      • ha_extra_nodes: 2
      • ha_mode: n+2
    Interpretação:
      Nós finais com HA: 3 + 2 = 5 nós.

▸ Total Power Kw: 72.5 kW

  Racional:
    Fórmula:
      total_power_kw = nodes_final × power_kw_max
    Inputs:
      • nodes_final: 5
      • power_kw_max: 14.5
    Interpretação:
      Energia total: 5 nós × 14.5 kW = 72.5 kW. Dimensiona PDU, UPS e contrato de energia.
      Considere PUE ~1.4x para cooling.

▸ Total Rack U: 50U

  Racional:
    Fórmula:
      total_rack_u = nodes_final × rack_units_u
    Inputs:
      • nodes_final: 5
      • rack_units_u: 10
    Interpretação:
      Rack total: 5 nós × 10U = 50U (1.2 racks padrão). Adicione ~20% para infra.

  ⚠️  AVISOS DESTE CENÁRIO:
    [1] ALERTA: Contexto longo (131,072 tokens) aumenta TTFT e pressiona I/O.

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 4: ALERTAS E RISCOS OPERACIONAIS                                                           │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

[1] ALERTA: Contexto longo (131,072 tokens) aumenta TTFT e pressiona I/O.

====================================================================================================
FIM DO RELATÓRIO
====================================================================================================