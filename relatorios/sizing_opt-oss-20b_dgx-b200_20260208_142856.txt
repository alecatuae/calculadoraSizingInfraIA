====================================================================================================
RELATÓRIO DE DIMENSIONAMENTO AVANÇADO DE INFERÊNCIA LLM
Sistema de Sizing com Racional de Cálculo e Análise de Cenários
====================================================================================================

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 1: ENTRADAS (Modelo / Servidor / Storage / NFR)                                            │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

MODELO:
  Nome: opt-oss-20b
  Camadas: 24
  KV Heads: 8
  Head Dim: 64
  Max Position Embeddings: 131,072
  Padrão de Atenção: hybrid
    • Full Layers: 12
    • Sliding Layers: 12
    • Sliding Window: 128
  Precisão KV Padrão: fp8

SERVIDOR:
  Nome: dgx-b200
  GPUs: 8
  HBM por GPU: 180 GB
  HBM Total: 1440 GB (1341.1 GiB)

STORAGE:
  Perfil: profile_default
  Tipo: nvme_local
  IOPS: 1,000,000 read / 800,000 write
  Throughput: 28 GB/s read / 25 GB/s write
  Latência P99: 0.15 ms read / 0.2 ms write

NFR (Non-Functional Requirements):
  Concorrência Alvo: 500 sessões simultâneas
  Contexto Efetivo: 65,536 tokens
  Precisão KV: fp8

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 2: DICIONÁRIO DE PARÂMETROS (Explicação e Importância)                                     │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

【num_layers】
  O que é: Número total de camadas (layers) do transformer no modelo LLM. Cada camada possui seu próprio conjunto de tensores Key e Value no KV cache.
  Origem: Parâmetro fixo da arquitetura do modelo, definido em models.json. Não pode ser alterado em runtime.
  Importância: Impacta linearmente o tamanho do KV cache. Modelos com mais camadas (ex: 36 vs 24) consomem proporcionalmente mais memória GPU para armazenar o histórico de atenção.
  Erro comum: Erro comum: Confundir num_layers com num_hidden_layers ou contar apenas encoder/decoder. Deve ser o total de camadas que mantêm KV cache.

【num_key_value_heads】
  O que é: Número de cabeças (heads) de atenção para Key e Value. Em GQA (Grouped Query Attention), este valor pode ser menor que o número de query heads.
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Modelos modernos usam GQA para reduzir KV cache.
  Importância: Impacta diretamente o tamanho do KV cache. Menos KV heads = menos memória. GQA com 8 KV heads vs 32 representa redução de 4x na memória de KV.
  Erro comum: Erro comum: Usar num_attention_heads (query heads) em vez de num_key_value_heads. Em GQA esses valores são diferentes e isso causa superestimação de 4-8x na memória.

【head_dim】
  O que é: Dimensionalidade de cada cabeça de atenção (ex: 64, 128). Tamanho do vetor de embedding por head.
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Geralmente 64 ou 128.
  Importância: Multiplica linearmente o tamanho do KV cache. head_dim=128 vs 64 dobra a memória necessária por head.
  Erro comum: Erro comum: Confundir head_dim com hidden_size. hidden_size = num_attention_heads × head_dim. Usar hidden_size diretamente causa erro massivo.

【attention_pattern】
  O que é: Padrão de atenção usado pelo modelo: 'full' (todas camadas atendem contexto completo), 'sliding' (janela deslizante), ou 'hybrid' (mix de full e sliding).
  Origem: Parâmetro fixo da arquitetura do modelo (models.json). Define como o modelo processa contexto longo.
  Importância: Crítico para cálculo correto de KV cache. Sliding window pode reduzir KV cache drasticamente (ex: 128k context com window=128 usa 1000x menos memória que full attention).
  Erro comum: Erro comum: Assumir 'full' para todos os modelos. Modelos modernos usam hybrid/sliding. Usar 'full' quando modelo é 'sliding' superestima memória em ordens de magnitude.

【effective_context】
  O que é: Tamanho de contexto (em tokens) que sua aplicação efetivamente usará em runtime. Diferente de max_position_embeddings (limite do modelo).
  Origem: NFR (Non-Functional Requirement) do produto/aplicação. Você define baseado no use case (ex: 4k para chat, 128k para análise de documentos).
  Importância: Impacta diretamente o tamanho do KV cache por sessão. Contexto maior = mais memória = menos sessões por nó. Definir incorretamente causa over/under-provisioning.
  Erro comum: Erro comum: Usar max_position_embeddings como effective_context. Isso superestima memória se aplicação usa contextos menores, ou causa problemas se excede o limite do modelo.

【kv_precision】
  O que é: Precisão numérica usada para armazenar tensores Key e Value: fp8/int8 (1 byte/elemento) ou fp16/bf16 (2 bytes/elemento).
  Origem: Parâmetro de runtime configurável. fp8 é recomendado para economia de memória com mínima perda de qualidade.
  Importância: Impacta diretamente (2x) o tamanho do KV cache. fp16 vs fp8 dobra a memória necessária e reduz pela metade o número de sessões por nó.
  Erro comum: Erro comum: Usar fp16 por default sem testar fp8. Muitos casos fp8 tem qualidade equivalente, mas fp16 dobra o custo de infraestrutura desnecessariamente.

【concurrency】
  O que é: Número de sessões/requisições simultâneas (concurrent users) que o sistema deve suportar. Métrica de throughput.
  Origem: NFR do produto, baseado em projeções de tráfego e SLA. Pode vir de análise de uso, teste de carga, ou requisitos de negócio.
  Importância: Define quantos nós você precisa. Concurrency mal estimada causa: subdimensionamento (SLA quebrado, throttling) ou superdimensionamento (desperdício de capex).
  Erro comum: Erro comum: Confundir concurrency (sessões simultâneas) com RPS (requests per second). Concurrency = sessões ativas ao mesmo tempo. RPS considera latência.

【kv_budget_ratio】
  O que é: Fração da HBM total alocada para KV cache (ex: 0.70 = 70%). O restante é para modelo, ativações, overhead de runtime.
  Origem: Parâmetro de tuning/configuração. Default 0.70 é conservador. Pode ser ajustado baseado em profiling real.
  Importância: Define quantas sessões cabem por nó. Budget muito alto (>0.80) causa fragmentação e instabilidade. Budget muito baixo (<0.50) desperdiça HBM.
  Erro comum: Erro comum: Alocar 100% da HBM para KV cache, ignorando overhead do modelo, ativações, e buffers do runtime. Isso causa OOM (Out of Memory) em produção.

【runtime_overhead_gib】
  O que é: Memória GPU (GiB) reservada para modelo (pesos), ativações de computação, e buffers do runtime de inferência.
  Origem: Estimativa baseada em tamanho do modelo e framework. Pode ser medido via profiling. Default conservador: 80-150 GiB para modelos grandes.
  Importância: Subtrai da HBM disponível antes de calcular budget de KV. Subestimar causa OOM. Superestimar desperdiça capacidade.
  Erro comum: Erro comum: Usar overhead muito baixo (<50 GiB) para modelos grandes (>100B parâmetros). Modelo 120B em fp16 sozinho já ocupa ~240 GiB.

【peak_headroom_ratio】
  O que é: Fração adicional de capacidade reservada para picos de tráfego (ex: 0.20 = 20% acima da concurrency nominal).
  Origem: NFR de SRE, baseado em análise de sazonalidade e requisitos de SLO. Típico: 10-30%.
  Importância: Garante que sistema aguenta picos sem degradação de SLO. Sem headroom, qualquer pico causa throttling ou violação de SLA.
  Erro comum: Erro comum: Não ter headroom (0%) em produção. Tráfego sempre tem variação. Outro erro: headroom excessivo (>50%) que desperdiça capex.

【ha_mode】
  O que é: Modo de alta disponibilidade: 'none' (sem redundância), 'n+1' (tolera falha de 1 nó), 'n+2' (tolera 2 nós).
  Origem: NFR de disponibilidade, baseado em SLA. Produção crítica geralmente requer no mínimo N+1.
  Importância: Define quantos nós extras alocar para redundância. N+1 garante que falha de 1 nó não quebra SLA. Sem HA, falha de nó causa degradação imediata.
  Erro comum: Erro comum: Não ter HA (none) em produção com SLA > 99%. Falha de hardware é inevitável. Outro erro: N+2 quando N+1 já atende, desperdiçando capex.

(Veja JSON para dicionário completo de todos os parâmetros)

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 3: RESULTADOS POR CENÁRIO (MÍNIMO / RECOMENDADO / IDEAL)                                   │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

====================================================================================================
CENÁRIO: MÍNIMO
====================================================================================================
  • Peak Headroom: 0%
  • HA Mode: none
  • KV Budget Ratio: 70%

▸ Kv Per Session Gib: 0.75 GiB

  Racional:
    Fórmula:
      Hybrid attention: 12 full + 12 sliding
      Full: 2 × 65536 × 8 × 64 × 1 × 12
      Sliding: 2 × 128 × 8 × 64 × 1 × 12
      total = full + sliding
    Inputs:
      • model: opt-oss-20b
      • num_layers: 24
      • num_kv_heads: 8
      • head_dim: 64
      • attention_pattern: hybrid
      • effective_context: 65536
      • sliding_window: 128
      • kv_precision: fp8
      • bytes_per_element: 1
      • total_bytes: 806879232
    Interpretação:
      KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão.
      Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição
      (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo
      diferente por camada. Total de 0.75 GiB por sessão ativa.

▸ Kv Total Gib: 0.37 TiB (375.73 GiB)

  Racional:
    Fórmula:
      kv_total_gib = kv_per_session_gib × concurrency
    Inputs:
      • kv_per_session_gib: 0.7515
      • concurrency: 500
    Interpretação:
      Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão
      precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster.

▸ Hbm Total Gib: 1341.1 GiB

  Racional:
    Fórmula:
      hbm_total_gib = total_hbm_gb × (10^9 / 2^30)
    Inputs:
      • server: dgx-b200
      • gpus: 8
      • hbm_per_gpu_gb: 180
      • total_hbm_gb: 1440
      • gb_to_gib_factor: 0.9313225746154785
    Interpretação:
      Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário):
      1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e
      buffers.

▸ Kv Budget Gib: 854.8 GiB

  Racional:
    Fórmula:
      kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)
    Inputs:
      • hbm_total_gib: 1341.1
      • runtime_overhead_gib: 120
      • kv_budget_ratio: 0.7
      • available_after_overhead_gib: 1221.1
    Interpretação:
      De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes,
      alocamos 70% (854.8 GiB) para KV cache. O resto (30%) fica como buffer para fragmentação
      e overhead de runtime.

▸ Sessions Per Node: 1,137 sessões

  Racional:
    Fórmula:
      sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)
    Inputs:
      • kv_budget_gib: 854.77
      • kv_per_session_gib: 0.7515
    Interpretação:
      Com 854.8 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode
      suportar 1137 sessões simultâneas. Este é o limite de capacidade por nó baseado
      exclusivamente em memória de KV cache.

▸ Nodes Capacity: 1 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 500
      • sessions_per_node: 1137
    Interpretação:
      Para atender 500 sessões simultâneas com 1137 sessões/nó, precisamos de no mínimo 1 nós.
      Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou
      redundância para HA.

▸ Nodes With Headroom: 1 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 500
      • peak_headroom_ratio: 0.0
      • concurrency_with_headroom: 500.0
      • sessions_per_node: 1137
    Interpretação:
      Adicionando 0% de headroom para picos de tráfego, precisamos suportar 500 sessões
      simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de
      carga sem degradação de SLO.

▸ Nodes Final: 1 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 1
      • ha_extra_nodes: 0
      • ha_mode: none
    Interpretação:
      Adicionando 0 nó(s) para alta disponibilidade, total final é 1 nós. Sem HA: qualquer
      falha de nó causa degradação imediata.

====================================================================================================
CENÁRIO: RECOMENDADO
====================================================================================================
  • Peak Headroom: 20%
  • HA Mode: n+1
  • KV Budget Ratio: 70%

▸ Kv Per Session Gib: 0.75 GiB

  Racional:
    Fórmula:
      Hybrid attention: 12 full + 12 sliding
      Full: 2 × 65536 × 8 × 64 × 1 × 12
      Sliding: 2 × 128 × 8 × 64 × 1 × 12
      total = full + sliding
    Inputs:
      • model: opt-oss-20b
      • num_layers: 24
      • num_kv_heads: 8
      • head_dim: 64
      • attention_pattern: hybrid
      • effective_context: 65536
      • sliding_window: 128
      • kv_precision: fp8
      • bytes_per_element: 1
      • total_bytes: 806879232
    Interpretação:
      KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão.
      Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição
      (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo
      diferente por camada. Total de 0.75 GiB por sessão ativa.

▸ Kv Total Gib: 0.37 TiB (375.73 GiB)

  Racional:
    Fórmula:
      kv_total_gib = kv_per_session_gib × concurrency
    Inputs:
      • kv_per_session_gib: 0.7515
      • concurrency: 500
    Interpretação:
      Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão
      precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster.

▸ Hbm Total Gib: 1341.1 GiB

  Racional:
    Fórmula:
      hbm_total_gib = total_hbm_gb × (10^9 / 2^30)
    Inputs:
      • server: dgx-b200
      • gpus: 8
      • hbm_per_gpu_gb: 180
      • total_hbm_gb: 1440
      • gb_to_gib_factor: 0.9313225746154785
    Interpretação:
      Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário):
      1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e
      buffers.

▸ Kv Budget Gib: 854.8 GiB

  Racional:
    Fórmula:
      kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)
    Inputs:
      • hbm_total_gib: 1341.1
      • runtime_overhead_gib: 120
      • kv_budget_ratio: 0.7
      • available_after_overhead_gib: 1221.1
    Interpretação:
      De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes,
      alocamos 70% (854.8 GiB) para KV cache. O resto (30%) fica como buffer para fragmentação
      e overhead de runtime.

▸ Sessions Per Node: 1,137 sessões

  Racional:
    Fórmula:
      sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)
    Inputs:
      • kv_budget_gib: 854.77
      • kv_per_session_gib: 0.7515
    Interpretação:
      Com 854.8 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode
      suportar 1137 sessões simultâneas. Este é o limite de capacidade por nó baseado
      exclusivamente em memória de KV cache.

▸ Nodes Capacity: 1 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 500
      • sessions_per_node: 1137
    Interpretação:
      Para atender 500 sessões simultâneas com 1137 sessões/nó, precisamos de no mínimo 1 nós.
      Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou
      redundância para HA.

▸ Nodes With Headroom: 1 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 500
      • peak_headroom_ratio: 0.2
      • concurrency_with_headroom: 600.0
      • sessions_per_node: 1137
    Interpretação:
      Adicionando 20% de headroom para picos de tráfego, precisamos suportar 600 sessões
      simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de
      carga sem degradação de SLO.

▸ Nodes Final: 2 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 1
      • ha_extra_nodes: 1
      • ha_mode: n+1
    Interpretação:
      Adicionando 1 nó(s) para alta disponibilidade, total final é 2 nós. Com N+1: sistema
      tolera falha de 1 nó mantendo SLO.

====================================================================================================
CENÁRIO: IDEAL
====================================================================================================
  • Peak Headroom: 30%
  • HA Mode: n+2
  • KV Budget Ratio: 65%

▸ Kv Per Session Gib: 0.75 GiB

  Racional:
    Fórmula:
      Hybrid attention: 12 full + 12 sliding
      Full: 2 × 65536 × 8 × 64 × 1 × 12
      Sliding: 2 × 128 × 8 × 64 × 1 × 12
      total = full + sliding
    Inputs:
      • model: opt-oss-20b
      • num_layers: 24
      • num_kv_heads: 8
      • head_dim: 64
      • attention_pattern: hybrid
      • effective_context: 65536
      • sliding_window: 128
      • kv_precision: fp8
      • bytes_per_element: 1
      • total_bytes: 806879232
    Interpretação:
      KV cache armazena tensores Key e Value de todas as camadas para o contexto da sessão.
      Cada posição no contexto mantém 8 heads × 64 dims × 1 bytes/elem = 512 bytes por posição
      (K+V separados, daí fator 2). Modelo com attention_pattern='hybrid' usa contexto efetivo
      diferente por camada. Total de 0.75 GiB por sessão ativa.

▸ Kv Total Gib: 0.37 TiB (375.73 GiB)

  Racional:
    Fórmula:
      kv_total_gib = kv_per_session_gib × concurrency
    Inputs:
      • kv_per_session_gib: 0.7515
      • concurrency: 500
    Interpretação:
      Memória total de KV cache necessária para suportar 500 sessões simultâneas. Cada sessão
      precisa de 0.75 GiB, totalizando 0.37 TiB distribuídos entre os nós do cluster.

▸ Hbm Total Gib: 1341.1 GiB

  Racional:
    Fórmula:
      hbm_total_gib = total_hbm_gb × (10^9 / 2^30)
    Inputs:
      • server: dgx-b200
      • gpus: 8
      • hbm_per_gpu_gb: 180
      • total_hbm_gb: 1440
      • gb_to_gib_factor: 0.9313225746154785
    Interpretação:
      Servidor dgx-b200 tem 8 GPUs × 180 GB/GPU = 1440 GB total. Convertido para GiB (binário):
      1341.1 GiB. Esta é a memória total disponível por nó para modelo, KV cache, ativações e
      buffers.

▸ Kv Budget Gib: 793.7 GiB

  Racional:
    Fórmula:
      kv_budget_gib = max(0, (hbm_total_gib - runtime_overhead_gib) × kv_budget_ratio)
    Inputs:
      • hbm_total_gib: 1341.1
      • runtime_overhead_gib: 120
      • kv_budget_ratio: 0.65
      • available_after_overhead_gib: 1221.1
    Interpretação:
      De 1341.1 GiB de HBM, reservamos 120 GiB para modelo+ativações. Dos 1221.1 GiB restantes,
      alocamos 65% (793.7 GiB) para KV cache. O resto (35%) fica como buffer para fragmentação
      e overhead de runtime.

▸ Sessions Per Node: 1,056 sessões

  Racional:
    Fórmula:
      sessions_per_node = floor(kv_budget_gib / kv_per_session_gib)
    Inputs:
      • kv_budget_gib: 793.72
      • kv_per_session_gib: 0.7515
    Interpretação:
      Com 793.7 GiB disponíveis para KV e cada sessão consumindo 0.75 GiB, cada nó pode
      suportar 1056 sessões simultâneas. Este é o limite de capacidade por nó baseado
      exclusivamente em memória de KV cache.

▸ Nodes Capacity: 1 nós

  Racional:
    Fórmula:
      nodes_capacity = ceil(concurrency / sessions_per_node)
    Inputs:
      • concurrency: 500
      • sessions_per_node: 1056
    Interpretação:
      Para atender 500 sessões simultâneas com 1056 sessões/nó, precisamos de no mínimo 1 nós.
      Este é o dimensionamento de capacidade pura, sem considerar headroom para picos ou
      redundância para HA.

▸ Nodes With Headroom: 1 nós

  Racional:
    Fórmula:
      nodes_with_headroom = ceil(concurrency × (1 + peak_headroom_ratio) / sessions_per_node)
    Inputs:
      • concurrency: 500
      • peak_headroom_ratio: 0.3
      • concurrency_with_headroom: 650.0
      • sessions_per_node: 1056
    Interpretação:
      Adicionando 30% de headroom para picos de tráfego, precisamos suportar 650 sessões
      simultâneas, resultando em 1 nós. Headroom garante que o sistema aguenta variações de
      carga sem degradação de SLO.

▸ Nodes Final: 3 nós

  Racional:
    Fórmula:
      nodes_final = nodes_with_headroom + ha_extra_nodes
    Inputs:
      • nodes_with_headroom: 1
      • ha_extra_nodes: 2
      • ha_mode: n+2
    Interpretação:
      Adicionando 2 nó(s) para alta disponibilidade, total final é 3 nós. Com N+2: sistema
      tolera falha de 2 nós mantendo SLO.

┌──────────────────────────────────────────────────────────────────────────────────────────────────┐
│ SEÇÃO 4: ALERTAS E RISCOS OPERACIONAIS                                                           │
└──────────────────────────────────────────────────────────────────────────────────────────────────┘

Nenhum alerta crítico detectado.

====================================================================================================
FIM DO RELATÓRIO
====================================================================================================