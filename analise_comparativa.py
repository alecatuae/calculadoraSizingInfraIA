#!/usr/bin/env python3
"""
An√°lise Comparativa de Sizing de Modelos LLM

Script para comparar m√∫ltiplos relat√≥rios de sizing e identificar o modelo
mais eficiente em diferentes dimens√µes (KV cache, infraestrutura, custo, VRAM).

Uso:
    python analise_comparativa.py
    python analise_comparativa.py --models "DeepSeek-V3.2,opt-oss-120b"
    python analise_comparativa.py --scenario ideal --format json
"""

import json
import os
import sys
import argparse
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict


@dataclass
class ComparisonMetrics:
    """M√©tricas extra√≠das de um relat√≥rio para compara√ß√£o."""
    model: str
    server: str
    concurrency: int
    effective_context: int
    kv_precision: str
    
    # KV Cache Efficiency
    vram_per_session_gib: float
    sessions_per_node_capacity: int
    sessions_per_node_effective: int
    
    # Infrastructure
    nodes_final: int
    hbm_utilization_ratio: float
    
    # VRAM Breakdown
    fixed_model_gib: float
    vram_total_node_gib: float
    vram_model_percent: float
    vram_kv_percent: float
    
    # Physical Resources
    total_power_kw: float
    total_rack_u: int
    storage_total_tb: float
    
    # Efficiency Metrics
    sessions_per_kw: float
    cost_per_session_month: float


def load_sizing_reports(directory: str, filters: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Carrega todos os JSONs de sizing do diret√≥rio com filtros opcionais."""
    reports = []
    directory_path = Path(directory)
    
    if not directory_path.exists():
        print(f"‚ùå ERRO: Diret√≥rio n√£o encontrado: {directory}")
        sys.exit(1)
    
    json_files = list(directory_path.glob("sizing_*.json"))
    
    if not json_files:
        print(f"‚ùå ERRO: Nenhum arquivo sizing_*.json encontrado em {directory}")
        sys.exit(1)
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
                
            # Aplicar filtros
            if filters.get('models'):
                model_list = [m.strip().lower() for m in filters['models'].split(',')]
                if report['inputs']['model'].lower() not in model_list:
                    continue
            
            if filters.get('server'):
                if report['inputs']['server'].lower() != filters['server'].lower():
                    continue
            
            report['_filename'] = json_file.name
            reports.append(report)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Aviso: Erro ao carregar {json_file.name}: {e}")
            continue
    
    if not reports:
        print(f"‚ùå ERRO: Nenhum relat√≥rio v√°lido encontrado ap√≥s aplicar filtros")
        sys.exit(1)
    
    return reports


def validate_report_structure(report: Dict[str, Any]) -> bool:
    """Valida presen√ßa de campos obrigat√≥rios."""
    required_fields = [
        'inputs', 'scenarios'
    ]
    
    for field in required_fields:
        if field not in report:
            return False
    
    required_inputs = ['model', 'server', 'concurrency', 'effective_context']
    for field in required_inputs:
        if field not in report['inputs']:
            return False
    
    return True


def extract_metrics(report: Dict[str, Any], scenario: str = "recommended") -> Optional[ComparisonMetrics]:
    """Extrai m√©tricas-chave de um relat√≥rio para um cen√°rio espec√≠fico."""
    try:
        if not validate_report_structure(report):
            return None
        
        inputs = report['inputs']
        scenario_data = report['scenarios'].get(scenario, {}).get('results', {})
        
        if not scenario_data:
            return None
        
        # C√°lculos derivados
        fixed_model_gib = scenario_data.get('fixed_model_gib', 0)
        vram_total = scenario_data.get('vram_total_node_effective_gib', 0)
        vram_per_session = scenario_data.get('vram_per_session_gib', 0)
        sessions_effective = scenario_data.get('sessions_per_node_effective', 1)
        
        vram_kv_total = vram_per_session * sessions_effective
        vram_overhead = max(0, vram_total - fixed_model_gib - vram_kv_total)
        
        vram_model_pct = (fixed_model_gib / vram_total * 100) if vram_total > 0 else 0
        vram_kv_pct = (vram_kv_total / vram_total * 100) if vram_total > 0 else 0
        
        # Efici√™ncia energ√©tica
        total_power = scenario_data.get('total_power_kw_with_storage', scenario_data.get('total_power_kw', 0))
        nodes = scenario_data.get('nodes_final', 1)
        total_sessions = sessions_effective * nodes
        sessions_per_kw = total_sessions / total_power if total_power > 0 else 0
        
        # Custo estimado (premissas do prompt)
        dgx_cost = 500000  # $500k por DGX
        storage = scenario_data.get('storage', {})
        storage_tb = storage.get('storage_total_recommended_tb', 0)
        storage_cost = storage_tb * 200  # $200/TB
        
        capex = (nodes * dgx_cost) + storage_cost
        opex_energy_year = total_power * 8760 * 0.15  # $0.15/kWh, 8760h/ano
        opex_maintenance_year = capex * 0.10  # 10% CapEx/ano
        tco_3years = capex + (opex_energy_year * 3) + (opex_maintenance_year * 3)
        cost_per_session_month = (tco_3years / 36) / total_sessions if total_sessions > 0 else 0
        
        return ComparisonMetrics(
            model=inputs['model'],
            server=inputs['server'],
            concurrency=inputs['concurrency'],
            effective_context=inputs['effective_context'],
            kv_precision=inputs.get('kv_precision', 'N/A'),
            
            vram_per_session_gib=vram_per_session,
            sessions_per_node_capacity=scenario_data.get('sessions_per_node', 0),
            sessions_per_node_effective=sessions_effective,
            
            nodes_final=nodes,
            hbm_utilization_ratio=scenario_data.get('hbm_utilization_ratio_effective', 0),
            
            fixed_model_gib=fixed_model_gib,
            vram_total_node_gib=vram_total,
            vram_model_percent=vram_model_pct,
            vram_kv_percent=vram_kv_pct,
            
            total_power_kw=total_power,
            total_rack_u=scenario_data.get('total_rack_u_with_storage', scenario_data.get('total_rack_u', 0)),
            storage_total_tb=storage_tb,
            
            sessions_per_kw=sessions_per_kw,
            cost_per_session_month=cost_per_session_month
        )
        
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao extrair m√©tricas: {e}")
        return None


def format_markdown_table(headers: List[str], rows: List[List[Any]]) -> str:
    """Formata dados como tabela Markdown."""
    lines = []
    
    # Header
    lines.append("| " + " | ".join(headers) + " |")
    lines.append("|" + "|".join(["---" for _ in headers]) + "|")
    
    # Rows
    for row in rows:
        formatted_row = []
        for cell in row:
            if isinstance(cell, float):
                formatted_row.append(f"{cell:.2f}")
            else:
                formatted_row.append(str(cell))
        lines.append("| " + " | ".join(formatted_row) + " |")
    
    return "\n".join(lines)


def generate_rankings(metrics_list: List[ComparisonMetrics]) -> Dict[str, List[Tuple[str, float]]]:
    """Gera rankings por m√©trica."""
    rankings = {}
    
    # KV Efficiency (menor √© melhor)
    kv_sorted = sorted(metrics_list, key=lambda m: m.vram_per_session_gib)
    rankings['kv_efficiency'] = [(m.model, m.vram_per_session_gib) for m in kv_sorted]
    
    # Infrastructure Efficiency (menor n√∫mero de n√≥s √© melhor)
    infra_sorted = sorted(metrics_list, key=lambda m: m.nodes_final)
    rankings['infrastructure'] = [(m.model, m.nodes_final) for m in infra_sorted]
    
    # Cost Efficiency (menor custo por sess√£o)
    cost_sorted = sorted(metrics_list, key=lambda m: m.cost_per_session_month)
    rankings['cost'] = [(m.model, m.cost_per_session_month) for m in cost_sorted]
    
    # Energy Efficiency (maior sess√µes/kW)
    energy_sorted = sorted(metrics_list, key=lambda m: m.sessions_per_kw, reverse=True)
    rankings['energy'] = [(m.model, m.sessions_per_kw) for m in energy_sorted]
    
    return rankings


def generate_markdown_report(metrics_list: List[ComparisonMetrics], scenario: str, output_path: str):
    """Gera relat√≥rio Markdown completo."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    lines = []
    lines.append(f"# An√°lise Comparativa de Sizing de Modelos - {timestamp}")
    lines.append("")
    lines.append("## Resumo Executivo")
    lines.append("")
    
    # Resumo
    model_names = [m.model for m in metrics_list]
    servers = list(set([m.server for m in metrics_list]))
    concurrency = metrics_list[0].concurrency if metrics_list else 0
    context = metrics_list[0].effective_context if metrics_list else 0
    kv_prec = metrics_list[0].kv_precision if metrics_list else "N/A"
    
    lines.append(f"- **Modelos analisados**: {len(metrics_list)} ({', '.join(model_names)})")
    lines.append(f"- **Servidor(es)**: {', '.join(servers)}")
    lines.append(f"- **Concorr√™ncia**: {concurrency:,} sess√µes simult√¢neas")
    lines.append(f"- **Contexto efetivo**: {context:,} tokens")
    lines.append(f"- **Precis√£o KV**: {kv_prec}")
    lines.append(f"- **Cen√°rio de refer√™ncia**: {scenario.upper()}")
    lines.append("")
    
    # Rankings
    rankings = generate_rankings(metrics_list)
    
    lines.append("## üèÜ Rankings de Efici√™ncia")
    lines.append("")
    
    # Ranking KV
    lines.append("### 1. Efici√™ncia de KV Cache (menor √© melhor)")
    lines.append("")
    headers = ["Posi√ß√£o", "Modelo", "KV/Sess√£o (GB)", "Sess√µes/N√≥ (Capacidade)", "Observa√ß√£o"]
    rows = []
    medals = ["ü•á 1¬∫", "ü•à 2¬∫", "ü•â 3¬∫"]
    
    for i, m in enumerate(metrics_list[:3]):
        obs = ""
        if i == 0 and len(metrics_list) > 1:
            improvement = ((metrics_list[1].vram_per_session_gib - m.vram_per_session_gib) / 
                          metrics_list[1].vram_per_session_gib * 100)
            obs = f"{improvement:.0f}% mais eficiente"
        
        rows.append([
            medals[i] if i < 3 else f"{i+1}¬∫",
            m.model,
            f"{m.vram_per_session_gib:.3f}",
            m.sessions_per_node_capacity,
            obs
        ])
    
    lines.append(format_markdown_table(headers, rows))
    lines.append("")
    
    # Ranking Infraestrutura
    lines.append("### 2. Efici√™ncia de Infraestrutura")
    lines.append("")
    headers = ["Posi√ß√£o", "Modelo", "N√≥s DGX", "Sess√µes/N√≥", "Utiliza√ß√£o HBM", "Storage (TB)"]
    rows = []
    
    infra_sorted = sorted(metrics_list, key=lambda m: m.nodes_final)
    for i, m in enumerate(infra_sorted[:3]):
        rows.append([
            medals[i] if i < 3 else f"{i+1}¬∫",
            m.model,
            m.nodes_final,
            m.sessions_per_node_effective,
            f"{m.hbm_utilization_ratio*100:.1f}%",
            f"{m.storage_total_tb:.2f}"
        ])
    
    lines.append(format_markdown_table(headers, rows))
    lines.append("")
    
    # Comparativo de VRAM
    lines.append("### 3. Breakdown de VRAM por N√≥")
    lines.append("")
    headers = ["Modelo", "Peso Fixo (GB)", "KV Total (GB)", "VRAM Total (GB)", "% Modelo", "% KV"]
    rows = []
    
    for m in metrics_list:
        kv_total = m.vram_per_session_gib * m.sessions_per_node_effective
        rows.append([
            m.model,
            f"{m.fixed_model_gib:.1f}",
            f"{kv_total:.1f}",
            f"{m.vram_total_node_gib:.1f}",
            f"{m.vram_model_percent:.1f}%",
            f"{m.vram_kv_percent:.1f}%"
        ])
    
    lines.append(format_markdown_table(headers, rows))
    lines.append("")
    
    # Recursos F√≠sicos
    lines.append("### 4. Recursos F√≠sicos")
    lines.append("")
    headers = ["Modelo", "N√≥s", "Energia (kW)", "Rack (U)", "Storage (TB)", "kW/Sess√£o"]
    rows = []
    
    for m in metrics_list:
        total_sessions = m.sessions_per_node_effective * m.nodes_final
        kw_per_session = m.total_power_kw / total_sessions if total_sessions > 0 else 0
        rows.append([
            m.model,
            m.nodes_final,
            f"{m.total_power_kw:.1f}",
            m.total_rack_u,
            f"{m.storage_total_tb:.2f}",
            f"{kw_per_session:.3f}"
        ])
    
    lines.append(format_markdown_table(headers, rows))
    lines.append("")
    
    # TCO
    lines.append("### 5. An√°lise de Custo (TCO 3 anos)")
    lines.append("")
    lines.append("**Premissas:**")
    lines.append("- Custo por DGX-B300: $500k USD")
    lines.append("- Energia: $0.15/kWh, 24x7")
    lines.append("- Storage NVMe: $200/TB")
    lines.append("- Manuten√ß√£o: 10% CapEx/ano")
    lines.append("")
    
    headers = ["Modelo", "N√≥s", "TCO Total (3 anos)", "Custo/Sess√£o/M√™s", "Efici√™ncia Energ√©tica"]
    rows = []
    
    cost_sorted = sorted(metrics_list, key=lambda m: m.cost_per_session_month)
    for m in cost_sorted:
        total_sessions = m.sessions_per_node_effective * m.nodes_final
        tco = m.cost_per_session_month * total_sessions * 36
        rows.append([
            m.model,
            m.nodes_final,
            f"${tco/1e6:.2f}M",
            f"${m.cost_per_session_month:.0f}",
            f"{m.sessions_per_kw:.2f} sess/kW"
        ])
    
    lines.append(format_markdown_table(headers, rows))
    lines.append("")
    
    # Recomenda√ß√£o
    lines.append("## üí° Recomenda√ß√£o Executiva")
    lines.append("")
    
    best_kv = rankings['kv_efficiency'][0][0]
    best_cost = rankings['cost'][0][0]
    best_energy = rankings['energy'][0][0]
    
    lines.append("### Para Produ√ß√£o Cr√≠tica (SLA > 99.9%)")
    lines.append(f"**Modelo recomendado**: {best_kv}")
    lines.append(f"**Justificativa**: Melhor efici√™ncia de KV cache, permitindo maior densidade de sess√µes por n√≥.")
    lines.append("")
    
    lines.append("### Para Custo Otimizado")
    lines.append(f"**Modelo recomendado**: {best_cost}")
    lines.append(f"**Justificativa**: Menor TCO por sess√£o simult√¢nea.")
    lines.append("")
    
    lines.append("### Para Efici√™ncia Energ√©tica")
    lines.append(f"**Modelo recomendado**: {best_energy}")
    lines.append(f"**Justificativa**: M√°ximo aproveitamento de energia (sess√µes por kW).")
    lines.append("")
    
    # Footer
    lines.append("---")
    lines.append("")
    lines.append("*Relat√≥rio gerado automaticamente pela Calculadora de Sizing de Infraestrutura para Infer√™ncia, desenvolvido pelo time de InfraCore de CLOUD.*")
    
    # Salvar
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))


def generate_json_report(metrics_list: List[ComparisonMetrics], scenario: str, output_path: str):
    """Gera relat√≥rio JSON para automa√ß√£o."""
    rankings = generate_rankings(metrics_list)
    
    output = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "script_version": "1.0.0",
            "reports_analyzed": len(metrics_list),
            "scenario": scenario
        },
        "rankings": {
            "kv_efficiency": [
                {"rank": i+1, "model": model, "kv_per_session_gib": value}
                for i, (model, value) in enumerate(rankings['kv_efficiency'])
            ],
            "infrastructure": [
                {"rank": i+1, "model": model, "nodes": value}
                for i, (model, value) in enumerate(rankings['infrastructure'])
            ],
            "cost": [
                {"rank": i+1, "model": model, "cost_per_session_month": value}
                for i, (model, value) in enumerate(rankings['cost'])
            ],
            "energy": [
                {"rank": i+1, "model": model, "sessions_per_kw": value}
                for i, (model, value) in enumerate(rankings['energy'])
            ]
        },
        "metrics": [asdict(m) for m in metrics_list]
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)


def print_terminal_summary(metrics_list: List[ComparisonMetrics]):
    """Imprime sum√°rio executivo no terminal."""
    rankings = generate_rankings(metrics_list)
    
    print("=" * 80)
    print("AN√ÅLISE COMPARATIVA DE SIZING - " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 80)
    print()
    print(f"üìä Relat√≥rios encontrados: {len(metrics_list)}")
    for m in metrics_list:
        print(f"   ‚úì {m.model} ({m.server}, {m.concurrency} sess√µes, {m.kv_precision})")
    print()
    
    print("üèÜ TOP 3 RANKINGS")
    print()
    
    print("1Ô∏è‚É£  Efici√™ncia de KV Cache:")
    medals = ["ü•á", "ü•à", "ü•â"]
    for i, (model, value) in enumerate(rankings['kv_efficiency'][:3]):
        print(f"    {medals[i]} {model}: {value:.2f} GB/sess√£o")
    print()
    
    print("2Ô∏è‚É£  Custo por Sess√£o (TCO 3 anos):")
    for i, (model, value) in enumerate(rankings['cost'][:3]):
        print(f"    {medals[i]} {model}: ${value:.0f}/sess√£o/m√™s")
    print()
    
    print("3Ô∏è‚É£  Efici√™ncia Energ√©tica (sess√µes/kW):")
    for i, (model, value) in enumerate(rankings['energy'][:3]):
        print(f"    {medals[i]} {model}: {value:.2f} sess√µes/kW")
    print()


def main():
    parser = argparse.ArgumentParser(
        description="An√°lise Comparativa de Sizing de Modelos LLM",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument("--directory", default="./relatorios", 
                       help="Diret√≥rio com arquivos JSON (default: ./relatorios)")
    parser.add_argument("--models", 
                       help="Filtrar modelos espec√≠ficos (comma-separated)")
    parser.add_argument("--server", 
                       help="Filtrar por servidor espec√≠fico")
    parser.add_argument("--scenario", default="recommended", 
                       choices=["minimum", "recommended", "ideal"],
                       help="Cen√°rio de refer√™ncia (default: recommended)")
    parser.add_argument("--output", default="./relatorios", 
                       help="Diret√≥rio de sa√≠da (default: ./relatorios)")
    parser.add_argument("--format", default="both", 
                       choices=["markdown", "json", "both"],
                       help="Formato de sa√≠da (default: both)")
    parser.add_argument("--verbose", action="store_true",
                       help="Modo verboso")
    
    args = parser.parse_args()
    
    # Carregar relat√≥rios
    filters = {
        'models': args.models,
        'server': args.server
    }
    
    if args.verbose:
        print(f"Carregando relat√≥rios de {args.directory}...")
    
    reports = load_sizing_reports(args.directory, filters)
    
    # Extrair m√©tricas
    metrics_list = []
    for report in reports:
        metrics = extract_metrics(report, args.scenario)
        if metrics:
            metrics_list.append(metrics)
        elif args.verbose:
            print(f"‚ö†Ô∏è  N√£o foi poss√≠vel extrair m√©tricas de {report.get('_filename', 'unknown')}")
    
    if not metrics_list:
        print("‚ùå ERRO: Nenhuma m√©trica extra√≠da dos relat√≥rios")
        sys.exit(1)
    
    # Ordenar por KV efficiency
    metrics_list.sort(key=lambda m: m.vram_per_session_gib)
    
    # Sum√°rio no terminal
    print_terminal_summary(metrics_list)
    
    # Gerar relat√≥rios
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if args.format in ["markdown", "both"]:
        md_path = output_dir / f"analise_comparativa_{timestamp}.md"
        generate_markdown_report(metrics_list, args.scenario, str(md_path))
        print(f"‚úÖ Relat√≥rio Markdown gerado: {md_path}")
    
    if args.format in ["json", "both"]:
        json_path = output_dir / f"analise_comparativa_{timestamp}.json"
        generate_json_report(metrics_list, args.scenario, str(json_path))
        print(f"‚úÖ Relat√≥rio JSON gerado: {json_path}")
    
    print()
    print("=" * 80)


if __name__ == "__main__":
    main()
